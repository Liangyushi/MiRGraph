{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1051e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "#import rpy2.robjects as robjects\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from torchvision import transforms as tfs\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import HGTConv, Linear\n",
    "#from torch_geometric.loader import HGTLoader\n",
    "from torch.cuda.amp import autocast\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torchsummary import summary\n",
    "import random\n",
    "from sklearn.metrics import roc_curve, auc, f1_score, precision_recall_curve, average_precision_score\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "import math\n",
    "from einops import rearrange, reduce\n",
    "from einops.layers.torch import Rearrange\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(2022)\n",
    "\n",
    "class eca_layer(nn.Module):\n",
    "    \"\"\"Constructs a ECA module.\n",
    "    Args:\n",
    "        channel: Number of channels of the input feature map\n",
    "        k_size: Adaptive selection of kernel size\n",
    "    \"\"\"\n",
    "    def __init__(self, channel, k_size=3):\n",
    "        super(eca_layer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # feature descriptor on the global spatial information\n",
    "        #print(x.size())\n",
    "        y = self.avg_pool(x)\n",
    "        #print(y.size())\n",
    "        # Two different branches of ECA module\n",
    "        y = self.conv(y.squeeze(-1).transpose(-1, -2)).transpose(-1, -2).unsqueeze(-1)\n",
    "        #print(y.size())\n",
    "        # Multi-scale information fusion\n",
    "        y = self.sigmoid(y)\n",
    "        #print(y.size())\n",
    "        out=x * y.expand_as(x)\n",
    "        #print(out.size())\n",
    "        return out\n",
    "\n",
    "\n",
    "def default(val, d):\n",
    "    return val if exists(val) else d\n",
    "\n",
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def conv_kx1(in_channels, out_channels, kernel_size, stride=1):\n",
    "    layers = []\n",
    "    padding = kernel_size - 1\n",
    "    padding_left = padding // 2\n",
    "    padding_right = padding - padding_left\n",
    "    layers.append(nn.ConstantPad1d((padding_left, padding_right), 0))\n",
    "    layers.append(nn.Conv1d(in_channels, out_channels, kernel_size, stride))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "def conv_kx2(in_channels, out_channels, kernel_size, stride=1):\n",
    "    layers = []\n",
    "    layers.append(nn.Conv2d(in_channels, out_channels, kernel_size, stride))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "class Conv2_Layer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(Conv2_Layer, self).__init__()\n",
    "        #self.relu = nn.ReLU()\n",
    "        #self.eca1=eca_layer(in_channels,3)\n",
    "        self.conv1 = conv_kx2(in_channels, out_channels[0], kernel_size)\n",
    "        self.norm1=nn.BatchNorm2d(out_channels[0])\n",
    "        self.eca2=eca_layer(out_channels[0],3)\n",
    "        self.conv2 = conv_kx2(out_channels[0], out_channels[1], kernel_size)\n",
    "        self.norm2=nn.BatchNorm2d(out_channels[1])\n",
    "        self.eca3=eca_layer(out_channels[1],3)\n",
    "        self.relu=nn.GELU()\n",
    "    def forward(self, x):\n",
    "        #out = self.eca1(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.eca2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out)\n",
    "        out = self.eca3(out)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "def ConvBlock(dim, dim_out = None, kernel_size = 1):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm1d(dim),\n",
    "        nn.GELU(),\n",
    "        conv_kx1(dim, default(dim_out, dim), kernel_size))\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, fn):\n",
    "        super().__init__()\n",
    "        self.fn = fn\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(x, **kwargs) + x\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout = 0.3, max_len=35526):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0., max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0., d_model, 2) * (-(math.log(10000.0) / d_model)))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)],requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "\n",
    "class gCNN(nn.Module):\n",
    "    def __init__(self,max_len=2500,dim=128,nhead=4,num_layers=2,pool_size=[(3,1),3,11],out_channels=[7,1],stem_kernel_size=[(7,1),7],dropout_rate=0.3):\n",
    "        super(gCNN, self).__init__()\n",
    "        self.stem1 = nn.Sequential(\n",
    "            Conv2_Layer(15,out_channels,stem_kernel_size[0]),\n",
    "            nn.MaxPool2d(pool_size[0])\n",
    "        )\n",
    "        out_length = np.floor((((max_len-(stem_kernel_size[0][0]*2)+2) - pool_size[0][0]) / pool_size[0][0]) + 1)\n",
    "        print(out_length)\n",
    "        self.stem2 = nn.Sequential(\n",
    "            conv_kx1(4, dim, stem_kernel_size[1]),\n",
    "            Residual(ConvBlock(dim,dim,stem_kernel_size[1])),\n",
    "            nn.MaxPool1d(pool_size[1])\n",
    "        )\n",
    "        out_length = np.floor(((out_length - pool_size[1]) / pool_size[1]) + 1)\n",
    "        print(out_length)\n",
    "        self.stem3 = nn.Sequential(\n",
    "            #conv_kx1(64, dim, stem_kernel_size[1]),\n",
    "            Residual(ConvBlock(dim,dim,stem_kernel_size[1])),\n",
    "            nn.MaxPool1d(pool_size[2])\n",
    "        )\n",
    "        out_length = np.floor(((out_length - pool_size[2]) / pool_size[2]) + 1)\n",
    "        print(out_length)\n",
    "        self.position = PositionalEncoding(d_model=dim,max_len=int(out_length))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=nhead,batch_first=True,dim_feedforward=256,activation='gelu',dropout=dropout_rate)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        # self.linear = nn.Linear(int(dim * out_length), 1024)\n",
    "        # self.relu = nn.GELU()\n",
    "        # self.dropout = nn.Dropout(p=dropout_rate if dropout_rate is not None else 0)\n",
    "    def forward(self, x):\n",
    "        #print(x.size())\n",
    "        x = self.stem1(x)\n",
    "        #print(x.size())\n",
    "        x=x.view(x.size()[0],x.size()[2],x.size()[3])\n",
    "        #print(x.size())\n",
    "        x=x.permute(0,2,1)\n",
    "        #print(x.size())\n",
    "        x=self.stem2(x)\n",
    "        #print(x.size())\n",
    "        x=self.stem3(x)\n",
    "        #print(x.size())\n",
    "        x=x.permute(0, 2, 1)\n",
    "        #print(x.size())\n",
    "        x = self.position(x)\n",
    "        #print(x.size())\n",
    "        x = self.transformer_encoder(x)\n",
    "        #print(x.size())\n",
    "        x = x.reshape(len(x), -1)\n",
    "        #print(x.size())\n",
    "        # x = self.linear(x)\n",
    "        # x = self.relu(x)\n",
    "        # x = self.dropout(x)\n",
    "        #print(x.size())\n",
    "        return x\n",
    "\n",
    "class mCNN(nn.Module):\n",
    "    def __init__(self,max_len=25,dim=128,nhead=8,num_layers=2,stem_kernel_size=7,dropout_rate=0.3):\n",
    "        super(mCNN, self).__init__()\n",
    "        self.stem = nn.Sequential(\n",
    "            #nn.Conv1d(4, dim, 7),\n",
    "            conv_kx1(4, dim, stem_kernel_size),\n",
    "            Residual(ConvBlock(dim,dim,stem_kernel_size))\n",
    "            #AttentionPool(dim, pool_size = 2)\n",
    "        )\n",
    "        self.position = PositionalEncoding(d_model=dim,max_len=max_len)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=dim, nhead=nhead,batch_first=True,dim_feedforward=256,activation='gelu',dropout=dropout_rate)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        # self.linear = nn.Linear(int(dim * max_len), 1024)\n",
    "        # self.relu = nn.GELU()\n",
    "        # self.dropout = nn.Dropout(p=dropout_rate if dropout_rate is not None else 0)\n",
    "    def forward(self, x):\n",
    "        #print(x.size())\n",
    "        x=x.permute(0, 2, 1)\n",
    "        #print(x.size())\n",
    "        x = self.stem(x)\n",
    "        #print(x.size())\n",
    "        #x = self.conv_tower(x)\n",
    "        #print(x.size())\n",
    "        x=x.permute(0, 2, 1)\n",
    "        #print(x.size())\n",
    "        x = self.position(x)\n",
    "        #print(x.size())\n",
    "        x = self.transformer_encoder(x)\n",
    "        #print(x.size())\n",
    "        x = x.reshape(len(x), -1)\n",
    "        #print(x.size())\n",
    "        # x = self.linear(x)\n",
    "        # x = self.relu(x)\n",
    "        # x = self.dropout(x)\n",
    "        #print(x.size())\n",
    "        return x\n",
    "\n",
    "class HGT(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, out_channels, num_heads, num_layers,node_types,metadata):\n",
    "        super().__init__()\n",
    "        self.lin_dict = torch.nn.ModuleDict()\n",
    "        for node_type in node_types:\n",
    "            self.lin_dict[node_type] = Linear(-1, hidden_channels[0])\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            conv = HGTConv(hidden_channels[i], hidden_channels[i+1], metadata,num_heads, group='sum')\n",
    "            self.convs.append(conv)\n",
    "    def forward(self, x_dict, edge_index_dict):\n",
    "        for node_type, x in x_dict.items():\n",
    "            x_dict[node_type] = self.lin_dict[node_type](x).relu_()\n",
    "        for conv in self.convs:\n",
    "            x_dict = conv(x_dict, edge_index_dict)\n",
    "        # xm=self.relu(self.lin1(x_dict['miRNA']))\n",
    "        # xg=self.relu(self.lin2(x_dict['gene']))\n",
    "        xm=x_dict['miRNA']\n",
    "        xg=x_dict['gene']\n",
    "        return (xm,xg)\n",
    "\n",
    "\n",
    "class MLPBilPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, num_layers, dropout_rate=0.3):\n",
    "        super(MLPBilPredictor, self).__init__()\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels[0]))\n",
    "        for i in range(num_layers - 1):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels[i], hidden_channels[i+1]))\n",
    "        self.bilin = torch.nn.Linear(hidden_channels[-1], hidden_channels[-1], bias=False)\n",
    "        self.dropout = nn.Dropout(p=dropout_rate if dropout_rate is not None else 0)\n",
    "        self.relu = nn.GELU()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "        self.bilin.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        for lin in self.lins:\n",
    "            x_i, x_j = lin(x_i), lin(x_j)\n",
    "            x_i, x_j = self.dropout(self.relu(x_i)), self.dropout(self.relu(x_j))\n",
    "        x = torch.sum(self.bilin(x_i) * x_j, dim=-1)\n",
    "        # x1 = torch.sum(self.bilin(x_i) * x_j, dim=-1)\n",
    "        # x2 = torch.sum(self.bilin(x_j) * x_i, dim=-1)\n",
    "        # x = x1+x2\n",
    "        # x = torch.sum(x_i * x_j, dim=-1)\n",
    "        return x,x_i,x_j\n",
    "\n",
    "# class MLPBilPredictor(torch.nn.Module):\n",
    "#     def __init__(self, in_channels, hidden_channels, num_layers, dropout_rate=0.3):\n",
    "#         super(MLPBilPredictor, self).__init__()\n",
    "#         self.lins = torch.nn.ModuleList()\n",
    "#         self.lins.append(torch.nn.Linear(in_channels, hidden_channels[0]))\n",
    "#         for i in range(num_layers - 1):\n",
    "#             self.lins.append(torch.nn.Linear(hidden_channels[i], hidden_channels[i+1]))\n",
    "#         # self.bilin = torch.nn.Linear(hidden_channels, hidden_channels, bias=False)\n",
    "#         # self.bilin = torch.nn.Linear(in_channels,in_channels, bias=False)\n",
    "#         self.pre = torch.nn.Linear(hidden_channels[-1],1)\n",
    "#         self.relu = nn.GELU()\n",
    "#         self.dropout = nn.Dropout(p=dropout_rate if dropout_rate is not None else 0)\n",
    "#\n",
    "#     def reset_parameters(self):\n",
    "#         for lin in self.lins:\n",
    "#             lin.reset_parameters()\n",
    "#         self.lin.reset_parameters()\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         for lin in self.lins:\n",
    "#             x= lin(x)\n",
    "#             x= self.dropout(self.relu(x))\n",
    "#         x = self.pre(x)\n",
    "#         # x1 = torch.sum(self.bilin(x_i) * x_j, dim=-1)\n",
    "#         # x2 = torch.sum(self.bilin(x_j) * x_i, dim=-1)\n",
    "#         # x = x1+x2\n",
    "#         # x = torch.sum(x_i * x_j, dim=-1)\n",
    "#         return x\n",
    "\n",
    "class HerGraph(torch.nn.Module):\n",
    "    def __init__(self,hidden_channels, hgtout_channels, num_heads, hgtnum_layers,node_types,metadata, \\\n",
    "                 max_len=[25,2500],dim=[128,128],nhead=[4,4],num_layers=[2,2],pool_size=[(3,1),3], \\\n",
    "                 out_channels=[7,1],stem_kernel_size=[(7,1),7],herout_channels=128,dropout_rate=0.3):\n",
    "        super(HerGraph, self).__init__()\n",
    "        self.mcnn = mCNN(max_len[0],dim[0],nhead[0],num_layers[0],stem_kernel_size[1],dropout_rate)\n",
    "        self.gcnn = gCNN(max_len[1],dim[1],nhead[1],num_layers[1],pool_size,out_channels,stem_kernel_size,dropout_rate)\n",
    "        self.hgt=HGT(hidden_channels, hgtout_channels, num_heads, hgtnum_layers,node_types,metadata)\n",
    "        self.pre=MLPBilPredictor(3200+128, [1024], 1, 0.3)\n",
    "        self.relu = nn.GELU()\n",
    "        #self.ZeroPad = nn.ZeroPad2d(padding=(0, 1024-128, 0, 0))\n",
    "        self.dropout = nn.Dropout(p=dropout_rate if dropout_rate is not None else 0)\n",
    "    def encoder(self,seq_dict,x_dict,edge_index_dict):\n",
    "        xm1=self.mcnn(seq_dict['miRNA'])\n",
    "        #print(xm1.size())\n",
    "        xg1=self.gcnn(seq_dict['gene'])\n",
    "        #print(xg1.size())\n",
    "        xm2,xg2=self.hgt(x_dict,edge_index_dict)\n",
    "        # torch.nn.ZeroPad2d(padding=(0, 2, 0, 2))\n",
    "        # xm2 = self.ZeroPad(xm2)\n",
    "        # xg2 = self.ZeroPad(xg2)\n",
    "        #xm2=self.relu(self.embhgt(xm2))\n",
    "        #xg2=self.relu(self.embhgt(xg2))\n",
    "        xm=self.relu(torch.cat([xm1, xm2], dim=1))\n",
    "        #print(xm.size())\n",
    "        xg=self.relu(torch.cat([xg1, xg2], dim=1))\n",
    "        #print(xg.size())\n",
    "        # xm=xm1+xm2\n",
    "        # xg=xg1+xg2\n",
    "        #xm = self.dropout(xm)\n",
    "        #xg = self.dropout(xg)\n",
    "        #print(xm.size())\n",
    "        #print(xg.size())\n",
    "        return xm,xg\n",
    "    def decoderMLP(self,xm,xg,edge):\n",
    "        xm=xm[edge[0]]\n",
    "        xg=xg[edge[1]]\n",
    "        #x=torch.cat([xm, xg], dim=1)\n",
    "        #s=self.pre(x)\n",
    "        s,xm,xg=self.pre(xm,xg)\n",
    "        return s,xm,xg\n",
    "    def forward(self,seq_dict,x_dict,edge_index_dict,label_edge):\n",
    "        xm,xg=self.encoder(seq_dict,x_dict,edge_index_dict)\n",
    "        s,xm,xg=self.decoderMLP(xm,xg,label_edge)\n",
    "        return s,xm,xg\n",
    "    \n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self,alpha=0.25,gamma=2.0,reduce='mean'):\n",
    "        super(FocalLoss,self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduce = reduce\n",
    "\n",
    "    def forward(self,classifications,targets):\n",
    "        # classifcation:[N,K]\n",
    "        # targets: [N,K]的one-hot编码\n",
    "        alpha = self.alpha\n",
    "        gamma = self.gamma\n",
    "        # classifications = classifications.view(-1)  # 不经过sigmoid的classification；\n",
    "        # targets = targets.view(-1)                  # 应该是 one-hot\n",
    "        # ce_loss: 对应公式中 -log(pt),也就是普通的 交叉熵损失；--> 该函数接收未经sigmoid的函数；\n",
    "        ce_loss = F.binary_cross_entropy_with_logits(classifications, targets, reduction=\"none\")\n",
    "        #focal loss\n",
    "        p = torch.sigmoid(classifications)                # 经过sigmoid\n",
    "        p_t = p * targets + (1 - p) * (1 - targets)       #  计算pt\n",
    "        loss = ce_loss * ((1 - p_t) ** gamma)             # -log(pt) * (1-pt) ** ganmma\n",
    "        if alpha >= 0:\n",
    "            # 对应公式中alpha_t控制损失的权重\n",
    "            alpha_t = alpha * targets + (1 - alpha) * (1 - targets) # 和pt求解过程一样\n",
    "            loss = alpha_t * loss                         # 最终focal loss\n",
    "        if self.reduce=='sum':\n",
    "            loss = loss.sum()\n",
    "        elif self.reduce=='mean':\n",
    "            loss = loss.mean()\n",
    "        else:\n",
    "            raise ValueError('reduce type is wrong!')\n",
    "        return loss\n",
    "\n",
    "class BCEFocalLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, gamma=2, alpha=0.25, reduction='elementwise_mean'):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, _input, target):\n",
    "        pt = torch.sigmoid(_input)\n",
    "        loss = - self.alpha * (1 - pt) ** self.gamma * target * torch.log(pt) - \\\n",
    "               (1-self.alpha)*pt ** self.gamma * (1 - target) * torch.log(1 - pt)\n",
    "        #         loss = - self.alpha * pt ** self.gamma * target * torch.log(pt) - \\\n",
    "        #             (1-self.alpha)*(1 - pt)** self.gamma * (1 - target) * torch.log(1 - pt)\n",
    "        if self.reduction == 'elementwise_mean':\n",
    "            loss = torch.mean(loss)\n",
    "        elif self.reduction == 'sum':\n",
    "            loss = torch.sum(loss)\n",
    "        return loss\n",
    "\n",
    "def trainAll(model,train_data,lossF):\n",
    "    model.train()\n",
    "    out,_,_  = model(train_data.seq_dict,train_data.sim_dict,train_data.edge_index_dict,train_data['regulate'].edge_label_index)\n",
    "    out=out.view(-1)\n",
    "    #print('out')\n",
    "    rel=train_data['regulate'].edge_label\n",
    "    #loss = F.binary_cross_entropy_with_logits(out,rel)\n",
    "    loss=lossF(out,rel)\n",
    "    pre=torch.sigmoid(out)\n",
    "    assert torch.isnan(loss).sum() == 0, print(loss)\n",
    "    auc=roc_auc_score(rel.detach().numpy(), pre.detach().numpy())\n",
    "    aupr= average_precision_score(rel.detach().numpy(), pre.detach().numpy())\n",
    "    #     out = model(train_data.x_dict,train_data.edge_index_dict)\n",
    "    #     pre=out[train_data['regulate'].edge_label_index[0],train_data['regulate'].edge_label_index[1]]\n",
    "    #     rel=train_data['regulate'].edge_label\n",
    "    #     loss = F.binary_cross_entropy_with_logits(pre,rel)\n",
    "    #     pre=torch.sigmoid(pre)\n",
    "    #     assert torch.isnan(loss).sum() == 0, print(loss)\n",
    "    #     auc=roc_auc_score(rel.detach().numpy(), pre.detach().numpy())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return (loss.item(),auc,aupr)\n",
    "\n",
    "def evaluateAll(model,dat,lossF):\n",
    "    model.eval()\n",
    "    valloss=0\n",
    "    valauc=0\n",
    "    with torch.no_grad():\n",
    "        out,_,_  = model(dat.seq_dict,dat.sim_dict,dat.edge_index_dict,dat['regulate'].edge_label_index)\n",
    "        out=out.view(-1)\n",
    "        rel=dat['regulate'].edge_label\n",
    "        #loss = F.binary_cross_entropy_with_logits(out,rel)\n",
    "        loss=lossF(out,rel)\n",
    "        pre=torch.sigmoid(out)\n",
    "        #         out = model(dat.x_dict,dat.edge_index_dict)\n",
    "        #         pre=out[dat['regulate'].edge_label_index[0],dat['regulate'].edge_label_index[1]]\n",
    "        #         rel=dat['regulate'].edge_label\n",
    "        #         loss = F.binary_cross_entropy_with_logits(pre,rel)\n",
    "        #         pre=torch.sigmoid(pre)\n",
    "        auc=roc_auc_score(rel.detach().numpy(), pre.detach().numpy())\n",
    "        aupr= average_precision_score(rel.detach().numpy(), pre.detach().numpy())\n",
    "    return (loss.item(),auc,aupr)\n",
    "\n",
    "class EarlyStopping():\n",
    "    def __init__(self, tolerance=50, min_delta=0.1):\n",
    "        self.tolerance = tolerance\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_best_auc, val_auc):\n",
    "        if val_auc<val_best_auc:\n",
    "            self.counter +=1\n",
    "            if self.counter >= self.tolerance:\n",
    "                self.early_stop = True\n",
    "\n",
    "def transfer_model(pretrained_file, model):\n",
    "    pretrained_dict = torch.load(pretrained_file,map_location=torch.device('cpu'))  # get pretrained dict\n",
    "    model_dict = model.state_dict()  # get model dict\n",
    "    pretrained_dict = transfer_state_dict(pretrained_dict, model_dict)\n",
    "    model_dict.update(pretrained_dict)\n",
    "    model.load_state_dict(model_dict)\n",
    "    return model\n",
    "\n",
    "def transfer_state_dict(pretrained_dict, model_dict):\n",
    "    state_dict = {}\n",
    "    for k, v in pretrained_dict.items():\n",
    "        if k in model_dict.keys():\n",
    "            state_dict[k] = v\n",
    "        else:\n",
    "            print(\"Missing key(s) in state_dict :{}\".format(k))\n",
    "    return state_dict\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     with open('/lustre06/project/6050659/liupei89/Testcell/newNetData/pos_neg/newdataCombine00_newall.pkl','rb') as f:  # Python 3: open(..., 'rb')\n",
    "#         train_data,val_data,test_data,m,g = pickle.load(f)\n",
    "\n",
    "#     train_data ['miRNA'].sim = train_data ['miRNA'].mm + train_data ['miRNA'].x\n",
    "#     val_data ['miRNA'].sim = train_data ['miRNA'].mm + train_data ['miRNA'].x\n",
    "#     test_data ['miRNA'].sim = train_data ['miRNA'].mm + train_data ['miRNA'].x\n",
    "#     train_data ['gene'].sim = train_data ['gene'].gg + train_data ['gene'].x\n",
    "#     val_data ['gene'].sim = train_data ['gene'].gg + train_data ['gene'].x\n",
    "#     test_data ['gene'].sim = train_data ['gene'].gg + train_data ['gene'].x\n",
    "#     nodetypes=train_data.node_types\n",
    "#     metadata=train_data.metadata()\n",
    "    \n",
    "#     model = HerGraph(hidden_channels=[1024,256,128], hgtout_channels=128, num_heads=8, hgtnum_layers=2,node_types=nodetypes,metadata=metadata, \\\n",
    "#                  max_len=[25,2500],dim=[128,128],nhead=[8,8],num_layers=[1,1],pool_size=[(3,1),3,11], \\\n",
    "#                  out_channels=[7,1],stem_kernel_size=[(7,1),3],herout_channels=128,dropout_rate=0.3)\n",
    "    \n",
    "\n",
    "#     print(model)\n",
    "\n",
    "#     pretrained_file='/lustre06/project/6050659/liupei89/Testcell/TransCNN13_1.pth'\n",
    "#     model = transfer_model(pretrained_file, model)\n",
    "\n",
    "#     pretrained_file='/lustre06/project/6050659/liupei89/Testcell/HGT6_1.pth'\n",
    "#     model = transfer_model(pretrained_file, model)\n",
    "\n",
    "#     for i, param in enumerate(model.parameters()):\n",
    "#         if i < 50:      # 前面一些参数冻结 需要再看\n",
    "#             param.requires_grad = False\n",
    "#     #     hgt=list(map(id, model.hgt.parameters()))\n",
    "#     #     mcnn=list(map(id, model.mcnn.parameters()))\n",
    "#     #     gcnn=list(map(id, model.gcnn.parameters()))\n",
    "#     #     base_params = filter(lambda p: id(p) not in hgt,mcnn,gcnn model.parameters())\n",
    "#     # ti=[18,19]\n",
    "#     # for i, param in enumerate(model.parameters()):\n",
    "#     #     if i in ti:      # 解冻\n",
    "#     #         param.requires_grad = True\n",
    "#     #     optimizer = torch.optim.Adam([{'params': base_params},{'params': model.hgt.parameters(), 'lr': 0.0001}], lr=0.000001,weight_decay=0)\n",
    "#     optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001, weight_decay=5e-3)\n",
    "#     lossF=FocalLoss(alpha=0.65, gamma=2,reduce='mean')\n",
    "#     #lossF=BCEFocalLoss(gamma=1, alpha=0.75, reduction='elementwise_mean')\n",
    "#     early_stopping = EarlyStopping(tolerance=200, min_delta=0.15)\n",
    "\n",
    "#     import time\n",
    "#     best_val_auc= best_val_aupr= 0\n",
    "#     trainloss=[]\n",
    "#     valloss=[]\n",
    "#     valauc=[]\n",
    "#     trainauc=[]\n",
    "#     valaupr=[]\n",
    "#     trainaupr=[]\n",
    "#     lrchange=[]\n",
    "#     for epoch in range(1, 501):\n",
    "#         since = time.time()\n",
    "#         print('{} optim: {}'.format(epoch, optimizer.param_groups[0]['lr']))\n",
    "#         lrchange.append(optimizer.param_groups[0]['lr'])\n",
    "#         train_loss,train_auc,train_aupr = trainAll(model,train_data,lossF)\n",
    "#         trainloss.append(train_loss)\n",
    "#         print('train_loss:',train_loss)\n",
    "#         #time_elapsed = time.time() - since\n",
    "#         #print('Training in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "#         #since1 = time.time()\n",
    "#         val_loss,val_auc,val_aupr = evaluateAll(model,val_data,lossF)\n",
    "#         valauc.append(val_auc)\n",
    "#         valloss.append(val_loss)\n",
    "#         trainauc.append(train_auc)\n",
    "#         valaupr.append(val_aupr)\n",
    "#         trainaupr.append(train_aupr)\n",
    "#         #time_elapsed = time.time() - since1\n",
    "#         #print('Val and Testing in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "#         if val_aupr > best_val_aupr:\n",
    "#             best_val_auc = val_auc\n",
    "#             best_val_aupr=val_aupr\n",
    "#             torch.save(model, 'Modelbest.pt')\n",
    "#         #    test_auc= tmp_test_auc\n",
    "#         #scheduler.step()\n",
    "#         time_elapsed = time.time() - since\n",
    "#         log = 'Epoch: {:03d}, Epoch complete in {:.0f}m {:.0f}s, trainLoss: {:.4f}, Valloss: {:.4f}, Trainauc: {:.4f}, Valauc: {:.4f}, Valbestauc: {:.4f},Trainaupr: {:.4f}, Valaupr: {:.4f}, Valbestaupr: {:.4f}'\n",
    "#         print(log.format(epoch, time_elapsed // 60, time_elapsed % 60,train_loss, val_loss,train_auc,val_auc,best_val_auc,train_aupr,val_aupr,best_val_aupr))\n",
    "\n",
    "#         # early_stopping(train_auc, val_auc)\n",
    "#         # if early_stopping.early_stop:\n",
    "#         #     print(\"We are at epoch:\", epoch)\n",
    "#         #     break\n",
    "\n",
    "#     with open('ModelResult.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "#         pickle.dump([trainloss, trainauc,trainaupr,valloss,valauc,valaupr,lrchange], f)\n",
    "\n",
    "#     torch.save(model, 'Model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e389fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70313f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "###重头开始\n",
    "#/home/liupei89/shfolder/new/Her/4/0.001_bilinear_500\n",
    "#/home/liupei89/shfolder/new/Her/4/0.001_mlpbilinear_500\n",
    "#/home/liupei89/shfolder/new/Her/4/0.0001_bilinear_500\n",
    "#/home/liupei89/shfolder/new/Her/4/100/0.001_bilinear_100\n",
    "#/home/liupei89/shfolder/new/Her/4/100/0.001_mlpbilinear_100\n",
    "#/home/liupei89/shfolder/new/Her/4/100/0.0001_bilinear_100\n",
    "#Her = torch.load(\"/home/liupei89/shfolder/new/Her/Modelbest.pt\")\n",
    "Her = torch.load(\"/home/liupei89/shfolder/new/Her/newHer/1/Modelbest.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ad39f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HerGraph(\n",
       "  (mcnn): mCNN(\n",
       "    (stem): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): ConstantPad1d(padding=(1, 1), value=0)\n",
       "        (1): Conv1d(4, 128, kernel_size=(3,), stride=(1,))\n",
       "      )\n",
       "      (1): Residual(\n",
       "        (fn): Sequential(\n",
       "          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): ConstantPad1d(padding=(1, 1), value=0)\n",
       "            (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (position): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.3, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.3, inplace=False)\n",
       "          (dropout2): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (gcnn): gCNN(\n",
       "    (stem1): Sequential(\n",
       "      (0): Conv2_Layer(\n",
       "        (conv1): Sequential(\n",
       "          (0): Conv2d(15, 7, kernel_size=(7, 1), stride=(1, 1))\n",
       "        )\n",
       "        (norm1): BatchNorm2d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (eca2): eca_layer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (conv2): Sequential(\n",
       "          (0): Conv2d(7, 1, kernel_size=(7, 1), stride=(1, 1))\n",
       "        )\n",
       "        (norm2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (eca3): eca_layer(\n",
       "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
       "          (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "          (sigmoid): Sigmoid()\n",
       "        )\n",
       "        (relu): GELU()\n",
       "      )\n",
       "      (1): MaxPool2d(kernel_size=(3, 1), stride=(3, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (stem2): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): ConstantPad1d(padding=(1, 1), value=0)\n",
       "        (1): Conv1d(4, 128, kernel_size=(3,), stride=(1,))\n",
       "      )\n",
       "      (1): Residual(\n",
       "        (fn): Sequential(\n",
       "          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): ConstantPad1d(padding=(1, 1), value=0)\n",
       "            (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (stem3): Sequential(\n",
       "      (0): Residual(\n",
       "        (fn): Sequential(\n",
       "          (0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (1): GELU()\n",
       "          (2): Sequential(\n",
       "            (0): ConstantPad1d(padding=(1, 1), value=0)\n",
       "            (1): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): MaxPool1d(kernel_size=11, stride=11, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (position): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.3, inplace=False)\n",
       "    )\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0): TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (dropout): Dropout(p=0.3, inplace=False)\n",
       "          (linear2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.3, inplace=False)\n",
       "          (dropout2): Dropout(p=0.3, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (hgt): HGT(\n",
       "    (lin_dict): ModuleDict(\n",
       "      (miRNA): Linear(279, 1024, bias=True)\n",
       "      (gene): Linear(14676, 1024, bias=True)\n",
       "    )\n",
       "    (convs): ModuleList(\n",
       "      (0): HGTConv(-1, 256, heads=8)\n",
       "      (1): HGTConv(-1, 128, heads=8)\n",
       "    )\n",
       "  )\n",
       "  (pre): MLPBilPredictor(\n",
       "    (lins): ModuleList(\n",
       "      (0): Linear(in_features=3328, out_features=1024, bias=True)\n",
       "    )\n",
       "    (bilin): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (relu): GELU()\n",
       "  )\n",
       "  (relu): GELU()\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Her"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77800cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/lustre06/project/6050659/liupei89/Testcell/newNetData/pos_neg/newdataCombine00_newall.pkl','rb') as f:  # Python 3: open(..., 'rb')\n",
    "        train_data,val_data,test_data,m,g = pickle.load(f)\n",
    "\n",
    "train_data ['miRNA'].sim = train_data ['miRNA'].mm + train_data ['miRNA'].x\n",
    "val_data ['miRNA'].sim = train_data ['miRNA'].mm + train_data ['miRNA'].x\n",
    "test_data ['miRNA'].sim = train_data ['miRNA'].mm + train_data ['miRNA'].x\n",
    "train_data ['gene'].sim = train_data ['gene'].gg + train_data ['gene'].x\n",
    "val_data ['gene'].sim = train_data ['gene'].gg + train_data ['gene'].x\n",
    "test_data ['gene'].sim = train_data ['gene'].gg + train_data ['gene'].x\n",
    "nodetypes=train_data.node_types\n",
    "metadata=train_data.metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aade4538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmiRNA\u001b[0m={\n",
       "    x=[279, 279],\n",
       "    seq=[279, 25, 4],\n",
       "    mm=[279, 279],\n",
       "    sim=[279, 279]\n",
       "  },\n",
       "  \u001b[1mgene\u001b[0m={\n",
       "    x=[14676, 14676],\n",
       "    seq=[14676, 15, 2500, 4],\n",
       "    gg=[14676, 14676],\n",
       "    sim=[14676, 14676]\n",
       "  },\n",
       "  \u001b[1m(miRNA, regulate, gene)\u001b[0m={\n",
       "    edge_index=[2, 66514],\n",
       "    edge_label_index=[2, 66514],\n",
       "    edge_label=[66514]\n",
       "  },\n",
       "  \u001b[1m(gene, coocurrence, gene)\u001b[0m={ edge_index=[2, 2087674] },\n",
       "  \u001b[1m(miRNA, cofamily, miRNA)\u001b[0m={ edge_index=[2, 418] },\n",
       "  \u001b[1m(gene, rev_regulate, miRNA)\u001b[0m={ edge_index=[2, 66514] }\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "124aab66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmiRNA\u001b[0m={\n",
       "    x=[279, 279],\n",
       "    seq=[279, 25, 4],\n",
       "    mm=[279, 279],\n",
       "    sim=[279, 279]\n",
       "  },\n",
       "  \u001b[1mgene\u001b[0m={\n",
       "    x=[14676, 14676],\n",
       "    seq=[14676, 15, 2500, 4],\n",
       "    gg=[14676, 14676],\n",
       "    sim=[14676, 14676]\n",
       "  },\n",
       "  \u001b[1m(miRNA, regulate, gene)\u001b[0m={\n",
       "    edge_index=[2, 66514],\n",
       "    edge_label_index=[2, 7391],\n",
       "    edge_label=[7391]\n",
       "  },\n",
       "  \u001b[1m(gene, coocurrence, gene)\u001b[0m={ edge_index=[2, 2087674] },\n",
       "  \u001b[1m(miRNA, cofamily, miRNA)\u001b[0m={ edge_index=[2, 418] },\n",
       "  \u001b[1m(gene, rev_regulate, miRNA)\u001b[0m={ edge_index=[2, 66514] }\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f2f74b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  \u001b[1mmiRNA\u001b[0m={\n",
       "    x=[279, 279],\n",
       "    seq=[279, 25, 4],\n",
       "    mm=[279, 279],\n",
       "    sim=[279, 279]\n",
       "  },\n",
       "  \u001b[1mgene\u001b[0m={\n",
       "    x=[14676, 14676],\n",
       "    seq=[14676, 15, 2500, 4],\n",
       "    gg=[14676, 14676],\n",
       "    sim=[14676, 14676]\n",
       "  },\n",
       "  \u001b[1m(miRNA, regulate, gene)\u001b[0m={\n",
       "    edge_index=[2, 73905],\n",
       "    edge_label_index=[2, 8213],\n",
       "    edge_label=[8213]\n",
       "  },\n",
       "  \u001b[1m(gene, coocurrence, gene)\u001b[0m={ edge_index=[2, 2087674] },\n",
       "  \u001b[1m(miRNA, cofamily, miRNA)\u001b[0m={ edge_index=[2, 418] },\n",
       "  \u001b[1m(gene, rev_regulate, miRNA)\u001b[0m={ edge_index=[2, 73905] }\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33b9dfed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 82118])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([train_data['regulate'].edge_index,val_data['regulate'].edge_label_index,test_data['regulate'].edge_label_index],dim=1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44648458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([82118])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([train_data['regulate'].edge_label,val_data['regulate'].edge_label,test_data['regulate'].edge_label]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a062932",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/lustre06/project/6050659/liupei89/Testcell/newNetData/pos_neg/newmirtarpos.pkl','rb') as f:  # Python 3: open(..., 'rb')\n",
    "        newtestedge = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe2a0c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newtestedge[0][0:2,0:3000].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2794f5dd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'newtestedge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m valauc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     out = Her(test_data.seq_dict,test_data.x_dict,test_data.edge_index_dict,test_data['regulate'].edge_label_index)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#     pre=out[test_data['regulate'].edge_label_index[0],test_data['regulate'].edge_label_index[1]]\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#     rel=test_data['regulate'].edge_label\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#     loss = F.binary_cross_entropy_with_logits(pre,rel)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     pre=torch.sigmoid(pre)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m     out \u001b[38;5;241m=\u001b[39m Her(test_data\u001b[38;5;241m.\u001b[39mseq_dict,test_data\u001b[38;5;241m.\u001b[39msim_dict,test_data\u001b[38;5;241m.\u001b[39medge_index_dict,\u001b[43mnewtestedge\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m3000\u001b[39m])\n\u001b[1;32m     12\u001b[0m     out\u001b[38;5;241m=\u001b[39mout\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m#rel=test_data['regulate'].edge_label\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m#loss = F.binary_cross_entropy_with_logits(out,rel)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'newtestedge' is not defined"
     ]
    }
   ],
   "source": [
    "### test 余下的边 在miRTarBAse\n",
    "\n",
    "Her.eval()\n",
    "valloss=0\n",
    "valauc=0\n",
    "with torch.no_grad():\n",
    "#     out = Her(test_data.seq_dict,test_data.x_dict,test_data.edge_index_dict,test_data['regulate'].edge_label_index)\n",
    "#     pre=out[test_data['regulate'].edge_label_index[0],test_data['regulate'].edge_label_index[1]]\n",
    "#     rel=test_data['regulate'].edge_label\n",
    "#     loss = F.binary_cross_entropy_with_logits(pre,rel)\n",
    "#     pre=torch.sigmoid(pre)\n",
    "\n",
    "    out, _, _ = Her(test_data.seq_dict,test_data.sim_dict,test_data.edge_index_dict,newtestedge[0][0:2,0:3000])\n",
    "    out=out.view(-1)\n",
    "    #rel=test_data['regulate'].edge_label\n",
    "    #loss = F.binary_cross_entropy_with_logits(out,rel)\n",
    "    pre=torch.sigmoid(out) \n",
    "\n",
    "    #auc=roc_auc_score(rel.detach().numpy(), pre.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "750b9c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1=out\n",
    "pre1=pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7e220cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her.eval()\n",
    "# valloss=0\n",
    "# valauc=0\n",
    "# with torch.no_grad():\n",
    "# #     out = Her(test_data.seq_dict,test_data.x_dict,test_data.edge_index_dict,test_data['regulate'].edge_label_index)\n",
    "# #     pre=out[test_data['regulate'].edge_label_index[0],test_data['regulate'].edge_label_index[1]]\n",
    "# #     rel=test_data['regulate'].edge_label\n",
    "# #     loss = F.binary_cross_entropy_with_logits(pre,rel)\n",
    "# #     pre=torch.sigmoid(pre)\n",
    "\n",
    "#     out = Her(test_data.seq_dict,test_data.sim_dict,test_data.edge_index_dict,newtestedge[0])\n",
    "#     out=out.view(-1)\n",
    "#     #rel=test_data['regulate'].edge_label\n",
    "#     #loss = F.binary_cross_entropy_with_logits(out,rel)\n",
    "#     pre=torch.sigmoid(out) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6b425fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2106, 0.6379, 0.4640,  ..., 0.3954, 0.3909, 0.2070])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae810699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3215,  0.5663, -0.1444,  ..., -0.4245, -0.4436, -1.3428])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "295f89a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2106, 0.6379, 0.4640,  ..., 0.9347, 0.8337, 0.6267])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee3c8ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.3215,  0.5663, -0.1444,  ...,  2.6614,  1.6120,  0.5181])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a841bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_rmse(records_real, records_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b27048f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Her.eval()\n",
    "# valloss=0\n",
    "# valauc=0\n",
    "# with torch.no_grad():\n",
    "# #     out = Her(test_data.seq_dict,test_data.x_dict,test_data.edge_index_dict,test_data['regulate'].edge_label_index)\n",
    "# #     pre=out[test_data['regulate'].edge_label_index[0],test_data['regulate'].edge_label_index[1]]\n",
    "# #     rel=test_data['regulate'].edge_label\n",
    "# #     loss = F.binary_cross_entropy_with_logits(pre,rel)\n",
    "# #     pre=torch.sigmoid(pre)\n",
    "\n",
    "#     out = Her(test_data.seq_dict,test_data.sim_dict,test_data.edge_index_dict,test_data['regulate'].edge_label_index)\n",
    "#     out=out.view(-1)\n",
    "#     rel=test_data['regulate'].edge_label\n",
    "#     #loss = F.binary_cross_entropy_with_logits(out,rel)\n",
    "#     pre=torch.sigmoid(out) \n",
    "\n",
    "#     auc=roc_auc_score(rel.detach().numpy(), pre.detach().numpy())\n",
    "    \n",
    "Her.eval()\n",
    "valloss = 0\n",
    "valauc = 0\n",
    "with torch.no_grad():\n",
    "    out, _, _ = Her(test_data.seq_dict, test_data.sim_dict, test_data.edge_index_dict, test_data['regulate'].edge_label_index)\n",
    "    out = out.view(-1)\n",
    "    rel = test_data['regulate'].edge_label\n",
    "    # loss = F.binary_cross_entropy_with_logits(out,rel)\n",
    "    #loss = lossF(out, rel)\n",
    "    pre = torch.sigmoid(out)\n",
    "    auc = roc_auc_score(rel.detach().numpy(), pre.detach().numpy())\n",
    "    aupr = average_precision_score(rel.detach().numpy(), pre.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76b77b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8625718227334958 0.7954255135159227\n"
     ]
    }
   ],
   "source": [
    "print(auc,aupr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90a9e7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2223])\n",
      "torch.Size([5990])\n",
      "torch.Size([2207])\n",
      "torch.Size([6006])\n"
     ]
    }
   ],
   "source": [
    "#rel[rel==1].size()\n",
    "allrelpos=torch.nonzero(rel==1).squeeze()\n",
    "print(allrelpos.size())\n",
    "allrelneg=torch.nonzero(rel==0).squeeze()\n",
    "print(allrelneg.size())\n",
    "\n",
    "allprepos=torch.nonzero(pre>=0.5).squeeze()##从0开始\n",
    "print(allprepos.size())\n",
    "allpreneg=torch.nonzero(pre<0.5).squeeze()##从0开始\n",
    "print(allpreneg.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "010f58ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1576])\n",
      "torch.Size([631])\n",
      "torch.Size([5359])\n",
      "torch.Size([647])\n"
     ]
    }
   ],
   "source": [
    "a=set(allprepos.numpy())\n",
    "b=set(allrelpos.numpy())\n",
    "c=torch.tensor(list(a&b))\n",
    "tp=c\n",
    "print(tp.size())#1571\n",
    "\n",
    "a=set(allprepos.numpy())\n",
    "b=set(allrelneg.numpy())\n",
    "c=torch.tensor(list(a&b))\n",
    "fp=c\n",
    "print(fp.size())#797\n",
    "\n",
    "a=set(allpreneg.numpy())\n",
    "b=set(allrelneg.numpy())\n",
    "c=torch.tensor(list(a&b))\n",
    "tn=c\n",
    "print(tn.size())#5193\n",
    "\n",
    "a=set(allpreneg.numpy())\n",
    "b=set(allrelpos.numpy())\n",
    "c=torch.tensor(list(a&b))\n",
    "fn=c\n",
    "print(fn.size())#652"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c1777542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2223"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp.size(0)+fn.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c45fb2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7089518668466037\n",
      "0.7140915269596738\n",
      "0.7115124153498871\n"
     ]
    }
   ],
   "source": [
    "recall=tp.size(0)/(tp.size(0)+fn.size(0))\n",
    "print(recall)\n",
    "\n",
    "precision=tp.size(0)/(tp.size(0)+fp.size(0))\n",
    "print(precision)\n",
    "\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7d9f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('HerGraph1_result.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n",
    "    pickle.dump([tp,fp,tn,fn,rel,pre], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe435934",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('newHer4test_result.pkl','rb') as f:  # Python 3: open(..., 'rb')\n",
    "        tp,fp,tn,fn,rel,pre = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a3c9767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# v,index=torch.topk(pre1, 200, largest=True, sorted=True, out=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35fd92ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, f1_score, precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc0a0392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         ... 0.98180301 0.98180301 1.        ] [0.00000000e+00 4.49842555e-04 7.10751237e-02 ... 9.99550157e-01\n",
      " 1.00000000e+00 1.00000000e+00] 0.8717220258385358\n"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(rel.numpy(), pre.numpy(), pos_label=1)\n",
    "testauc=auc(fpr,tpr)\n",
    "print(testauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "134bfa7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8946577629382304"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnr=tn.size(0)/(tn.size(0)+fp.size(0))\n",
    "tnr #真阴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68a9294f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10534223706176962"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr=fp.size(0)/(tn.size(0)+fp.size(0))\n",
    "fpr #假阳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15645af2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8443930354316328"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc=(tp.size(0)+tn.size(0))/(tn.size(0)+fp.size(0)+fn.size(0)+tp.size(0))\n",
    "acc #准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "731c3aed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7954255135159227"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precision, recall, _ = precision_recall_curve(rel.numpy(), pre.numpy(),pos_label=1)\n",
    "testaupr= average_precision_score(rel.numpy(), pre.numpy())\n",
    "testaupr #0.8026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1aad8d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1477b891bc10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.step(fpr, tpr,color='navy',linewidth=2,label='AUC = {0:.4f})'.format(testauc))\n",
    "#plt.plot([0, 0], [1, 1], color='navy',linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc=4)\n",
    "#plt.savefig(\"auc_curve.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d946aaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1477b88377c0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.step(recall,precision,color='navy',linewidth=2,label='AUPR = {0:.4f})'.format(testaupr))\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('PR Curve')\n",
    "plt.legend(loc=4)\n",
    "#plt.savefig(\"pr_curve.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3555f6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8213\n",
      "2223\n",
      "2099\n"
     ]
    }
   ],
   "source": [
    "t1=rel.numpy()\n",
    "print(len(t1))\n",
    "print(len(t1[t1==1]))\n",
    "s1=pre.numpy()\n",
    "s1[s1>0.5]=1\n",
    "s1[s1<=0.5]=0\n",
    "print(len(s1[s1==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "651ba50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7417818008575512\n",
      "0.7004048582995951\n",
      "0.7204997686256362\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(t1, s1,pos_label=1)\n",
    "print(precision)\n",
    "recall = recall_score(t1, s1,pos_label=1)\n",
    "print(recall)\n",
    "f1 = f1_score(t1, s1,pos_label=1)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9255bfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/home/liupei89/shfolder/new/Her/3/0.001/0.001_bilinear_500\n",
    "#/home/liupei89/shfolder/new/Her/4/0.001_bilinear_500\n",
    "#/home/liupei89/shfolder/new/Her/4/100/0.001_bilinear_100\n",
    "#/home/liupei89/shfolder/new/Her/4/100/0.0001_bilinear_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ca74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#/home/liupei89/shfolder/new/Her/4/0.0001_bilinear_500\n",
    "#/home/liupei89/shfolder/new/Her/3/0.0001_bilinear_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8aeab956",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/home/liupei89/shfolder/new/Her/newHer/1/ModelResult.pkl','rb') as f:  # Python 3: open(..., 'rb')\n",
    "        trainloss, trainauc,trainaupr,valloss,valauc,valaupr,lrchange = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5a56f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1471cc059820>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(trainloss)\n",
    "plt.figure()\n",
    "plt.plot(trainloss,label='trainloss')\n",
    "plt.plot(valloss,label='valloss')\n",
    "plt.plot(trainauc,label='trainauc')\n",
    "plt.plot(valauc,label='valauc')\n",
    "plt.plot(trainaupr,label='trainaupr')\n",
    "plt.plot(valaupr,label='valaupr')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('The Loss Trendency of HerGraph')\n",
    "plt.legend(loc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5fdeef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1477b872b6d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(trainloss)\n",
    "plt.figure()\n",
    "plt.plot(trainloss,label='trainloss',color='navy')\n",
    "plt.plot(valloss,label='valloss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "#plt.ylim([0.0, 1.0])\n",
    "#plt.xlim([0.0, 1.0])\n",
    "plt.title('The Loss Trendency of HerGraph')\n",
    "plt.legend(loc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "deec92d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1471c5155fd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(trainloss)\n",
    "plt.figure()\n",
    "plt.plot(trainauc,label='trainauc',color='navy')\n",
    "plt.plot(valauc,label='valauc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUC')\n",
    "plt.title('The AUC Trendency of HerGraph')\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "321aef68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1471c50c90d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.plot(trainloss)\n",
    "plt.figure()\n",
    "plt.plot(trainaupr,label='trainaupr')\n",
    "plt.plot(valaupr,label='valaupr')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('AUPR')\n",
    "#plt.ylim([0.5, 0.71])\n",
    "plt.title('The AUPR Trendency of HerGraph')\n",
    "plt.legend(loc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76bc36b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcnn.stem.0.1.weight : torch.Size([128, 4, 7])\n",
      "mcnn.stem.0.1.bias : torch.Size([128])\n",
      "mcnn.stem.1.fn.0.weight : torch.Size([128])\n",
      "mcnn.stem.1.fn.0.bias : torch.Size([128])\n",
      "mcnn.stem.1.fn.2.1.weight : torch.Size([128, 128, 7])\n",
      "mcnn.stem.1.fn.2.1.bias : torch.Size([128])\n",
      "mcnn.transformer_encoder.layers.0.self_attn.in_proj_weight : torch.Size([384, 128])\n",
      "mcnn.transformer_encoder.layers.0.self_attn.in_proj_bias : torch.Size([384])\n",
      "mcnn.transformer_encoder.layers.0.self_attn.out_proj.weight : torch.Size([128, 128])\n",
      "mcnn.transformer_encoder.layers.0.self_attn.out_proj.bias : torch.Size([128])\n",
      "mcnn.transformer_encoder.layers.0.linear1.weight : torch.Size([256, 128])\n",
      "mcnn.transformer_encoder.layers.0.linear1.bias : torch.Size([256])\n",
      "mcnn.transformer_encoder.layers.0.linear2.weight : torch.Size([128, 256])\n",
      "mcnn.transformer_encoder.layers.0.linear2.bias : torch.Size([128])\n",
      "mcnn.transformer_encoder.layers.0.norm1.weight : torch.Size([128])\n",
      "mcnn.transformer_encoder.layers.0.norm1.bias : torch.Size([128])\n",
      "mcnn.transformer_encoder.layers.0.norm2.weight : torch.Size([128])\n",
      "mcnn.transformer_encoder.layers.0.norm2.bias : torch.Size([128])\n",
      "mcnn.linear.weight : torch.Size([1024, 3200])\n",
      "mcnn.linear.bias : torch.Size([1024])\n",
      "gcnn.stem1.0.conv1.0.weight : torch.Size([7, 15, 7, 1])\n",
      "gcnn.stem1.0.conv1.0.bias : torch.Size([7])\n",
      "gcnn.stem1.0.norm1.weight : torch.Size([7])\n",
      "gcnn.stem1.0.norm1.bias : torch.Size([7])\n",
      "gcnn.stem1.0.eca2.conv.weight : torch.Size([1, 1, 3])\n",
      "gcnn.stem1.0.conv2.0.weight : torch.Size([1, 7, 7, 1])\n",
      "gcnn.stem1.0.conv2.0.bias : torch.Size([1])\n",
      "gcnn.stem1.0.norm2.weight : torch.Size([1])\n",
      "gcnn.stem1.0.norm2.bias : torch.Size([1])\n",
      "gcnn.stem1.0.eca3.conv.weight : torch.Size([1, 1, 3])\n",
      "gcnn.stem2.0.1.weight : torch.Size([128, 4, 7])\n",
      "gcnn.stem2.0.1.bias : torch.Size([128])\n",
      "gcnn.stem2.1.fn.0.weight : torch.Size([128])\n",
      "gcnn.stem2.1.fn.0.bias : torch.Size([128])\n",
      "gcnn.stem2.1.fn.2.1.weight : torch.Size([128, 128, 7])\n",
      "gcnn.stem2.1.fn.2.1.bias : torch.Size([128])\n",
      "gcnn.transformer_encoder.layers.0.self_attn.in_proj_weight : torch.Size([384, 128])\n",
      "gcnn.transformer_encoder.layers.0.self_attn.in_proj_bias : torch.Size([384])\n",
      "gcnn.transformer_encoder.layers.0.self_attn.out_proj.weight : torch.Size([128, 128])\n",
      "gcnn.transformer_encoder.layers.0.self_attn.out_proj.bias : torch.Size([128])\n",
      "gcnn.transformer_encoder.layers.0.linear1.weight : torch.Size([256, 128])\n",
      "gcnn.transformer_encoder.layers.0.linear1.bias : torch.Size([256])\n",
      "gcnn.transformer_encoder.layers.0.linear2.weight : torch.Size([128, 256])\n",
      "gcnn.transformer_encoder.layers.0.linear2.bias : torch.Size([128])\n",
      "gcnn.transformer_encoder.layers.0.norm1.weight : torch.Size([128])\n",
      "gcnn.transformer_encoder.layers.0.norm1.bias : torch.Size([128])\n",
      "gcnn.transformer_encoder.layers.0.norm2.weight : torch.Size([128])\n",
      "gcnn.transformer_encoder.layers.0.norm2.bias : torch.Size([128])\n",
      "gcnn.linear.weight : torch.Size([1024, 35328])\n",
      "gcnn.linear.bias : torch.Size([1024])\n",
      "hgt.lin_dict.miRNA.weight : torch.Size([1024, 279])\n",
      "hgt.lin_dict.miRNA.bias : torch.Size([1024])\n",
      "hgt.lin_dict.gene.weight : torch.Size([1024, 14676])\n",
      "hgt.lin_dict.gene.bias : torch.Size([1024])\n",
      "hgt.convs.0.k_lin.miRNA.weight : torch.Size([256, 1024])\n",
      "hgt.convs.0.k_lin.miRNA.bias : torch.Size([256])\n",
      "hgt.convs.0.k_lin.gene.weight : torch.Size([256, 1024])\n",
      "hgt.convs.0.k_lin.gene.bias : torch.Size([256])\n",
      "hgt.convs.0.q_lin.miRNA.weight : torch.Size([256, 1024])\n",
      "hgt.convs.0.q_lin.miRNA.bias : torch.Size([256])\n",
      "hgt.convs.0.q_lin.gene.weight : torch.Size([256, 1024])\n",
      "hgt.convs.0.q_lin.gene.bias : torch.Size([256])\n",
      "hgt.convs.0.v_lin.miRNA.weight : torch.Size([256, 1024])\n",
      "hgt.convs.0.v_lin.miRNA.bias : torch.Size([256])\n",
      "hgt.convs.0.v_lin.gene.weight : torch.Size([256, 1024])\n",
      "hgt.convs.0.v_lin.gene.bias : torch.Size([256])\n",
      "hgt.convs.0.a_lin.miRNA.weight : torch.Size([256, 256])\n",
      "hgt.convs.0.a_lin.miRNA.bias : torch.Size([256])\n",
      "hgt.convs.0.a_lin.gene.weight : torch.Size([256, 256])\n",
      "hgt.convs.0.a_lin.gene.bias : torch.Size([256])\n",
      "hgt.convs.0.skip.miRNA : torch.Size([1])\n",
      "hgt.convs.0.skip.gene : torch.Size([1])\n",
      "hgt.convs.0.a_rel.miRNA__regulate__gene : torch.Size([8, 32, 32])\n",
      "hgt.convs.0.a_rel.gene__coocurrence__gene : torch.Size([8, 32, 32])\n",
      "hgt.convs.0.a_rel.miRNA__cofamily__miRNA : torch.Size([8, 32, 32])\n",
      "hgt.convs.0.a_rel.gene__rev_regulate__miRNA : torch.Size([8, 32, 32])\n",
      "hgt.convs.0.m_rel.miRNA__regulate__gene : torch.Size([8, 32, 32])\n",
      "hgt.convs.0.m_rel.gene__coocurrence__gene : torch.Size([8, 32, 32])\n",
      "hgt.convs.0.m_rel.miRNA__cofamily__miRNA : torch.Size([8, 32, 32])\n",
      "hgt.convs.0.m_rel.gene__rev_regulate__miRNA : torch.Size([8, 32, 32])\n",
      "hgt.convs.0.p_rel.miRNA__regulate__gene : torch.Size([8])\n",
      "hgt.convs.0.p_rel.gene__coocurrence__gene : torch.Size([8])\n",
      "hgt.convs.0.p_rel.miRNA__cofamily__miRNA : torch.Size([8])\n",
      "hgt.convs.0.p_rel.gene__rev_regulate__miRNA : torch.Size([8])\n",
      "hgt.convs.1.k_lin.miRNA.weight : torch.Size([128, 256])\n",
      "hgt.convs.1.k_lin.miRNA.bias : torch.Size([128])\n",
      "hgt.convs.1.k_lin.gene.weight : torch.Size([128, 256])\n",
      "hgt.convs.1.k_lin.gene.bias : torch.Size([128])\n",
      "hgt.convs.1.q_lin.miRNA.weight : torch.Size([128, 256])\n",
      "hgt.convs.1.q_lin.miRNA.bias : torch.Size([128])\n",
      "hgt.convs.1.q_lin.gene.weight : torch.Size([128, 256])\n",
      "hgt.convs.1.q_lin.gene.bias : torch.Size([128])\n",
      "hgt.convs.1.v_lin.miRNA.weight : torch.Size([128, 256])\n",
      "hgt.convs.1.v_lin.miRNA.bias : torch.Size([128])\n",
      "hgt.convs.1.v_lin.gene.weight : torch.Size([128, 256])\n",
      "hgt.convs.1.v_lin.gene.bias : torch.Size([128])\n",
      "hgt.convs.1.a_lin.miRNA.weight : torch.Size([128, 128])\n",
      "hgt.convs.1.a_lin.miRNA.bias : torch.Size([128])\n",
      "hgt.convs.1.a_lin.gene.weight : torch.Size([128, 128])\n",
      "hgt.convs.1.a_lin.gene.bias : torch.Size([128])\n",
      "hgt.convs.1.skip.miRNA : torch.Size([1])\n",
      "hgt.convs.1.skip.gene : torch.Size([1])\n",
      "hgt.convs.1.a_rel.miRNA__regulate__gene : torch.Size([8, 16, 16])\n",
      "hgt.convs.1.a_rel.gene__coocurrence__gene : torch.Size([8, 16, 16])\n",
      "hgt.convs.1.a_rel.miRNA__cofamily__miRNA : torch.Size([8, 16, 16])\n",
      "hgt.convs.1.a_rel.gene__rev_regulate__miRNA : torch.Size([8, 16, 16])\n",
      "hgt.convs.1.m_rel.miRNA__regulate__gene : torch.Size([8, 16, 16])\n",
      "hgt.convs.1.m_rel.gene__coocurrence__gene : torch.Size([8, 16, 16])\n",
      "hgt.convs.1.m_rel.miRNA__cofamily__miRNA : torch.Size([8, 16, 16])\n",
      "hgt.convs.1.m_rel.gene__rev_regulate__miRNA : torch.Size([8, 16, 16])\n",
      "hgt.convs.1.p_rel.miRNA__regulate__gene : torch.Size([8])\n",
      "hgt.convs.1.p_rel.gene__coocurrence__gene : torch.Size([8])\n",
      "hgt.convs.1.p_rel.miRNA__cofamily__miRNA : torch.Size([8])\n",
      "hgt.convs.1.p_rel.gene__rev_regulate__miRNA : torch.Size([8])\n",
      "pre.lins.0.weight : torch.Size([1024, 2048])\n",
      "pre.lins.0.bias : torch.Size([1024])\n",
      "pre.lins.1.weight : torch.Size([128, 1024])\n",
      "pre.lins.1.bias : torch.Size([128])\n",
      "pre.pre.weight : torch.Size([1, 128])\n",
      "pre.pre.bias : torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "# for name,parameters in Her.named_parameters():\n",
    "#     print(name,':',parameters.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9062ce50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 _ mcnn.stem.0.1.weight : torch.Size([128, 4, 7])\n",
      "1 _ mcnn.stem.0.1.bias : torch.Size([128])\n",
      "2 _ mcnn.stem.1.fn.0.weight : torch.Size([128])\n",
      "3 _ mcnn.stem.1.fn.0.bias : torch.Size([128])\n",
      "4 _ mcnn.stem.1.fn.2.1.weight : torch.Size([128, 128, 7])\n",
      "5 _ mcnn.stem.1.fn.2.1.bias : torch.Size([128])\n",
      "6 _ mcnn.transformer_encoder.layers.0.self_attn.in_proj_weight : torch.Size([384, 128])\n",
      "7 _ mcnn.transformer_encoder.layers.0.self_attn.in_proj_bias : torch.Size([384])\n",
      "8 _ mcnn.transformer_encoder.layers.0.self_attn.out_proj.weight : torch.Size([128, 128])\n",
      "9 _ mcnn.transformer_encoder.layers.0.self_attn.out_proj.bias : torch.Size([128])\n",
      "10 _ mcnn.transformer_encoder.layers.0.linear1.weight : torch.Size([256, 128])\n",
      "11 _ mcnn.transformer_encoder.layers.0.linear1.bias : torch.Size([256])\n",
      "12 _ mcnn.transformer_encoder.layers.0.linear2.weight : torch.Size([128, 256])\n",
      "13 _ mcnn.transformer_encoder.layers.0.linear2.bias : torch.Size([128])\n",
      "14 _ mcnn.transformer_encoder.layers.0.norm1.weight : torch.Size([128])\n",
      "15 _ mcnn.transformer_encoder.layers.0.norm1.bias : torch.Size([128])\n",
      "16 _ mcnn.transformer_encoder.layers.0.norm2.weight : torch.Size([128])\n",
      "17 _ mcnn.transformer_encoder.layers.0.norm2.bias : torch.Size([128])\n",
      "18 _ mcnn.linear.weight : torch.Size([1024, 3200])\n",
      "19 _ mcnn.linear.bias : torch.Size([1024])\n",
      "20 _ gcnn.stem1.0.conv1.0.weight : torch.Size([7, 15, 7, 1])\n",
      "21 _ gcnn.stem1.0.conv1.0.bias : torch.Size([7])\n",
      "22 _ gcnn.stem1.0.norm1.weight : torch.Size([7])\n",
      "23 _ gcnn.stem1.0.norm1.bias : torch.Size([7])\n",
      "24 _ gcnn.stem1.0.eca2.conv.weight : torch.Size([1, 1, 3])\n",
      "25 _ gcnn.stem1.0.conv2.0.weight : torch.Size([1, 7, 7, 1])\n",
      "26 _ gcnn.stem1.0.conv2.0.bias : torch.Size([1])\n",
      "27 _ gcnn.stem1.0.norm2.weight : torch.Size([1])\n",
      "28 _ gcnn.stem1.0.norm2.bias : torch.Size([1])\n",
      "29 _ gcnn.stem1.0.eca3.conv.weight : torch.Size([1, 1, 3])\n",
      "30 _ gcnn.stem2.0.1.weight : torch.Size([128, 4, 7])\n",
      "31 _ gcnn.stem2.0.1.bias : torch.Size([128])\n",
      "32 _ gcnn.stem2.1.fn.0.weight : torch.Size([128])\n",
      "33 _ gcnn.stem2.1.fn.0.bias : torch.Size([128])\n",
      "34 _ gcnn.stem2.1.fn.2.1.weight : torch.Size([128, 128, 7])\n",
      "35 _ gcnn.stem2.1.fn.2.1.bias : torch.Size([128])\n",
      "36 _ gcnn.transformer_encoder.layers.0.self_attn.in_proj_weight : torch.Size([384, 128])\n",
      "37 _ gcnn.transformer_encoder.layers.0.self_attn.in_proj_bias : torch.Size([384])\n",
      "38 _ gcnn.transformer_encoder.layers.0.self_attn.out_proj.weight : torch.Size([128, 128])\n",
      "39 _ gcnn.transformer_encoder.layers.0.self_attn.out_proj.bias : torch.Size([128])\n",
      "40 _ gcnn.transformer_encoder.layers.0.linear1.weight : torch.Size([256, 128])\n",
      "41 _ gcnn.transformer_encoder.layers.0.linear1.bias : torch.Size([256])\n",
      "42 _ gcnn.transformer_encoder.layers.0.linear2.weight : torch.Size([128, 256])\n",
      "43 _ gcnn.transformer_encoder.layers.0.linear2.bias : torch.Size([128])\n",
      "44 _ gcnn.transformer_encoder.layers.0.norm1.weight : torch.Size([128])\n",
      "45 _ gcnn.transformer_encoder.layers.0.norm1.bias : torch.Size([128])\n",
      "46 _ gcnn.transformer_encoder.layers.0.norm2.weight : torch.Size([128])\n",
      "47 _ gcnn.transformer_encoder.layers.0.norm2.bias : torch.Size([128])\n",
      "48 _ gcnn.linear.weight : torch.Size([1024, 35328])\n",
      "49 _ gcnn.linear.bias : torch.Size([1024])\n",
      "50 _ hgt.lin_dict.miRNA.weight : torch.Size([1024, 279])\n",
      "51 _ hgt.lin_dict.miRNA.bias : torch.Size([1024])\n",
      "52 _ hgt.lin_dict.gene.weight : torch.Size([1024, 14676])\n",
      "53 _ hgt.lin_dict.gene.bias : torch.Size([1024])\n",
      "54 _ hgt.convs.0.k_lin.miRNA.weight : torch.Size([256, 1024])\n",
      "55 _ hgt.convs.0.k_lin.miRNA.bias : torch.Size([256])\n",
      "56 _ hgt.convs.0.k_lin.gene.weight : torch.Size([256, 1024])\n",
      "57 _ hgt.convs.0.k_lin.gene.bias : torch.Size([256])\n",
      "58 _ hgt.convs.0.q_lin.miRNA.weight : torch.Size([256, 1024])\n",
      "59 _ hgt.convs.0.q_lin.miRNA.bias : torch.Size([256])\n",
      "60 _ hgt.convs.0.q_lin.gene.weight : torch.Size([256, 1024])\n",
      "61 _ hgt.convs.0.q_lin.gene.bias : torch.Size([256])\n",
      "62 _ hgt.convs.0.v_lin.miRNA.weight : torch.Size([256, 1024])\n",
      "63 _ hgt.convs.0.v_lin.miRNA.bias : torch.Size([256])\n",
      "64 _ hgt.convs.0.v_lin.gene.weight : torch.Size([256, 1024])\n",
      "65 _ hgt.convs.0.v_lin.gene.bias : torch.Size([256])\n",
      "66 _ hgt.convs.0.a_lin.miRNA.weight : torch.Size([256, 256])\n",
      "67 _ hgt.convs.0.a_lin.miRNA.bias : torch.Size([256])\n",
      "68 _ hgt.convs.0.a_lin.gene.weight : torch.Size([256, 256])\n",
      "69 _ hgt.convs.0.a_lin.gene.bias : torch.Size([256])\n",
      "70 _ hgt.convs.0.skip.miRNA : torch.Size([1])\n",
      "71 _ hgt.convs.0.skip.gene : torch.Size([1])\n",
      "72 _ hgt.convs.0.a_rel.miRNA__regulate__gene : torch.Size([8, 32, 32])\n",
      "73 _ hgt.convs.0.a_rel.gene__coocurrence__gene : torch.Size([8, 32, 32])\n",
      "74 _ hgt.convs.0.a_rel.miRNA__cofamily__miRNA : torch.Size([8, 32, 32])\n",
      "75 _ hgt.convs.0.a_rel.gene__rev_regulate__miRNA : torch.Size([8, 32, 32])\n",
      "76 _ hgt.convs.0.m_rel.miRNA__regulate__gene : torch.Size([8, 32, 32])\n",
      "77 _ hgt.convs.0.m_rel.gene__coocurrence__gene : torch.Size([8, 32, 32])\n",
      "78 _ hgt.convs.0.m_rel.miRNA__cofamily__miRNA : torch.Size([8, 32, 32])\n",
      "79 _ hgt.convs.0.m_rel.gene__rev_regulate__miRNA : torch.Size([8, 32, 32])\n",
      "80 _ hgt.convs.0.p_rel.miRNA__regulate__gene : torch.Size([8])\n",
      "81 _ hgt.convs.0.p_rel.gene__coocurrence__gene : torch.Size([8])\n",
      "82 _ hgt.convs.0.p_rel.miRNA__cofamily__miRNA : torch.Size([8])\n",
      "83 _ hgt.convs.0.p_rel.gene__rev_regulate__miRNA : torch.Size([8])\n",
      "84 _ hgt.convs.1.k_lin.miRNA.weight : torch.Size([128, 256])\n",
      "85 _ hgt.convs.1.k_lin.miRNA.bias : torch.Size([128])\n",
      "86 _ hgt.convs.1.k_lin.gene.weight : torch.Size([128, 256])\n",
      "87 _ hgt.convs.1.k_lin.gene.bias : torch.Size([128])\n",
      "88 _ hgt.convs.1.q_lin.miRNA.weight : torch.Size([128, 256])\n",
      "89 _ hgt.convs.1.q_lin.miRNA.bias : torch.Size([128])\n",
      "90 _ hgt.convs.1.q_lin.gene.weight : torch.Size([128, 256])\n",
      "91 _ hgt.convs.1.q_lin.gene.bias : torch.Size([128])\n",
      "92 _ hgt.convs.1.v_lin.miRNA.weight : torch.Size([128, 256])\n",
      "93 _ hgt.convs.1.v_lin.miRNA.bias : torch.Size([128])\n",
      "94 _ hgt.convs.1.v_lin.gene.weight : torch.Size([128, 256])\n",
      "95 _ hgt.convs.1.v_lin.gene.bias : torch.Size([128])\n",
      "96 _ hgt.convs.1.a_lin.miRNA.weight : torch.Size([128, 128])\n",
      "97 _ hgt.convs.1.a_lin.miRNA.bias : torch.Size([128])\n",
      "98 _ hgt.convs.1.a_lin.gene.weight : torch.Size([128, 128])\n",
      "99 _ hgt.convs.1.a_lin.gene.bias : torch.Size([128])\n",
      "100 _ hgt.convs.1.skip.miRNA : torch.Size([1])\n",
      "101 _ hgt.convs.1.skip.gene : torch.Size([1])\n",
      "102 _ hgt.convs.1.a_rel.miRNA__regulate__gene : torch.Size([8, 16, 16])\n",
      "103 _ hgt.convs.1.a_rel.gene__coocurrence__gene : torch.Size([8, 16, 16])\n",
      "104 _ hgt.convs.1.a_rel.miRNA__cofamily__miRNA : torch.Size([8, 16, 16])\n",
      "105 _ hgt.convs.1.a_rel.gene__rev_regulate__miRNA : torch.Size([8, 16, 16])\n",
      "106 _ hgt.convs.1.m_rel.miRNA__regulate__gene : torch.Size([8, 16, 16])\n",
      "107 _ hgt.convs.1.m_rel.gene__coocurrence__gene : torch.Size([8, 16, 16])\n",
      "108 _ hgt.convs.1.m_rel.miRNA__cofamily__miRNA : torch.Size([8, 16, 16])\n",
      "109 _ hgt.convs.1.m_rel.gene__rev_regulate__miRNA : torch.Size([8, 16, 16])\n",
      "110 _ hgt.convs.1.p_rel.miRNA__regulate__gene : torch.Size([8])\n",
      "111 _ hgt.convs.1.p_rel.gene__coocurrence__gene : torch.Size([8])\n",
      "112 _ hgt.convs.1.p_rel.miRNA__cofamily__miRNA : torch.Size([8])\n",
      "113 _ hgt.convs.1.p_rel.gene__rev_regulate__miRNA : torch.Size([8])\n",
      "114 _ pre.lins.0.weight : torch.Size([1024, 2048])\n",
      "115 _ pre.lins.0.bias : torch.Size([1024])\n",
      "116 _ pre.lins.1.weight : torch.Size([128, 1024])\n",
      "117 _ pre.lins.1.bias : torch.Size([128])\n",
      "118 _ pre.pre.weight : torch.Size([1, 128])\n",
      "119 _ pre.pre.bias : torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "num=0\n",
    "for name,parameters in Her.named_parameters():\n",
    "    print(num,'_',name,':',parameters.size())\n",
    "    num=num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e1f8bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Parameter containing:\n",
      "tensor([[[-0.1287,  0.2812, -0.1097,  ..., -0.0069,  0.2759,  0.2657],\n",
      "         [-0.2793,  0.6601, -0.4633,  ..., -0.0046,  0.0040, -0.4729],\n",
      "         [-0.1652, -0.0386, -0.0010,  ..., -0.0344,  0.2210, -0.5856],\n",
      "         [ 0.5599, -0.0634,  0.1742,  ...,  0.0802, -0.2550,  0.0213]],\n",
      "\n",
      "        [[-0.0295,  0.1051,  0.0673,  ...,  0.0793,  0.4623,  0.2683],\n",
      "         [-0.0424,  0.1442,  0.1101,  ...,  0.0447, -0.0574, -0.1992],\n",
      "         [ 0.0117, -0.2965, -0.1235,  ..., -0.2618, -0.0493,  0.1370],\n",
      "         [ 0.0572, -0.1142, -0.2825,  ...,  0.2913,  0.0688, -0.0919]],\n",
      "\n",
      "        [[ 0.1809, -0.1209, -0.0728,  ..., -0.1570,  0.5075,  0.0302],\n",
      "         [ 0.3395, -0.4444, -0.3194,  ..., -0.0775, -0.0867,  0.4658],\n",
      "         [ 0.1126, -0.1989,  0.0093,  ...,  0.2478,  0.1981, -0.0016],\n",
      "         [-0.0762,  0.0447, -0.2561,  ..., -0.2805,  0.1371, -0.1608]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1975, -0.0311,  0.4644,  ..., -0.1266, -0.0069,  0.2843],\n",
      "         [-0.1441, -0.2957,  0.1301,  ...,  0.0290,  0.0708,  0.0649],\n",
      "         [ 0.1689,  0.1490,  0.0979,  ...,  0.3665, -0.0720, -0.0528],\n",
      "         [ 0.1576,  0.0717, -0.2387,  ..., -0.2140, -0.4249, -0.4498]],\n",
      "\n",
      "        [[ 0.1686,  0.2662,  0.4852,  ..., -0.1181, -0.0078, -0.3534],\n",
      "         [ 0.1048,  0.1299, -0.0195,  ..., -0.1579,  0.3523, -0.1594],\n",
      "         [ 0.0111,  0.0167, -0.4895,  ..., -0.1602, -0.0921,  0.1130],\n",
      "         [ 0.3114, -0.0936,  0.2952,  ...,  0.2433, -0.2475,  0.2980]],\n",
      "\n",
      "        [[-0.0175,  0.2618, -0.0318,  ..., -0.0339, -0.0460, -0.2067],\n",
      "         [ 0.5810, -0.0080, -0.3125,  ..., -0.3810, -0.2687, -0.0800],\n",
      "         [ 0.1802,  0.1656, -0.0465,  ..., -0.0458,  0.1083,  0.1173],\n",
      "         [-0.0969,  0.0682, -0.0107,  ..., -0.2308, -0.0483, -0.3241]]])\n",
      "1 Parameter containing:\n",
      "tensor([-0.0200,  0.0219,  0.0727, -0.0515, -0.0184, -0.1726,  0.0690, -0.0430,\n",
      "         0.0491,  0.0812,  0.0624, -0.0782, -0.1209,  0.0040,  0.0131,  0.1167,\n",
      "         0.0146, -0.1156, -0.1124, -0.1179,  0.1151, -0.0473, -0.1340,  0.0890,\n",
      "         0.0942, -0.0239,  0.0679,  0.1435, -0.0106, -0.1323, -0.1298, -0.0177,\n",
      "        -0.1354, -0.0962, -0.1235, -0.0817, -0.0299,  0.1038,  0.0483, -0.1447,\n",
      "         0.0588, -0.0270,  0.0978,  0.0600,  0.0471, -0.0313,  0.0793,  0.1033,\n",
      "         0.0323, -0.0933,  0.1156,  0.1468, -0.1413, -0.0478, -0.0188, -0.0906,\n",
      "         0.0478, -0.1797, -0.0026,  0.0474, -0.1764, -0.1830,  0.0471,  0.1387,\n",
      "        -0.1525, -0.1313,  0.1477, -0.0451, -0.0159, -0.1903,  0.0589, -0.0612,\n",
      "         0.0664,  0.0709, -0.0309, -0.0657,  0.1205, -0.0660,  0.0049, -0.1553,\n",
      "         0.1490, -0.0347, -0.1812, -0.0781,  0.1500,  0.0275,  0.0927,  0.0374,\n",
      "         0.1402, -0.1797,  0.0424,  0.1109, -0.1260,  0.1488, -0.0546,  0.0848,\n",
      "        -0.0547, -0.0624, -0.0062, -0.1032, -0.1052, -0.0182, -0.0015, -0.1095,\n",
      "         0.1101, -0.1409,  0.1008, -0.1699, -0.1381,  0.0830, -0.0014,  0.0877,\n",
      "        -0.1030,  0.1495, -0.0035, -0.1688,  0.0058,  0.0126,  0.0519,  0.0231,\n",
      "        -0.0314, -0.1719, -0.1101, -0.0146, -0.0019,  0.0739, -0.1533,  0.1262])\n",
      "2 Parameter containing:\n",
      "tensor([0.9314, 0.9212, 0.8919, 0.8862, 0.9049, 0.9810, 0.8430, 0.9124, 0.9258,\n",
      "        0.8309, 0.9097, 0.9039, 0.8808, 0.9177, 0.9206, 0.9200, 0.8989, 0.9397,\n",
      "        0.9383, 0.8907, 0.9194, 0.9319, 0.8840, 0.8840, 0.9175, 0.8673, 0.8902,\n",
      "        0.9865, 0.8811, 1.0082, 0.9142, 0.8841, 0.8797, 0.8748, 0.8876, 0.8640,\n",
      "        1.0333, 0.8585, 0.9578, 0.8861, 0.9446, 0.9252, 0.9230, 0.9665, 0.9081,\n",
      "        1.0052, 0.9628, 0.9071, 0.8769, 0.8893, 0.9283, 0.8811, 0.8556, 0.9022,\n",
      "        0.8953, 0.9075, 0.9160, 0.9303, 0.9231, 0.8105, 0.9244, 0.9630, 0.9534,\n",
      "        0.8662, 0.8760, 0.8622, 0.8519, 0.9779, 0.9425, 0.8518, 0.9100, 0.9730,\n",
      "        0.8822, 0.8942, 0.9280, 0.8592, 1.0051, 0.8784, 0.8894, 0.9453, 0.9452,\n",
      "        0.9504, 0.8792, 0.8699, 0.9155, 0.8947, 0.8610, 0.9096, 0.8843, 0.8670,\n",
      "        0.9564, 0.9086, 0.9592, 0.8647, 0.9647, 0.8825, 0.9590, 0.9375, 0.8778,\n",
      "        0.8941, 0.8778, 0.9169, 0.9089, 0.8951, 1.0017, 0.8941, 0.8890, 0.9274,\n",
      "        0.9546, 0.8855, 0.8793, 0.9462, 0.8679, 0.9281, 0.9595, 0.8178, 0.8778,\n",
      "        0.8933, 0.8701, 0.9212, 0.9382, 0.9217, 0.9201, 0.9600, 0.8671, 0.9199,\n",
      "        0.9036, 0.9502])\n",
      "3 Parameter containing:\n",
      "tensor([-0.1175, -0.1372, -0.1515, -0.2024, -0.1364, -0.1267, -0.1586, -0.1443,\n",
      "        -0.1593, -0.1406, -0.1366, -0.1245, -0.1360, -0.1390, -0.1207, -0.1982,\n",
      "        -0.1283, -0.1014, -0.1960, -0.1446, -0.1580, -0.1341, -0.1470, -0.1325,\n",
      "        -0.1231, -0.1838, -0.1608, -0.1322, -0.1635, -0.1299, -0.1544, -0.1809,\n",
      "        -0.2018, -0.1703, -0.1724, -0.1538, -0.1313, -0.1762, -0.1590, -0.1540,\n",
      "        -0.0944, -0.1369, -0.1604, -0.1130, -0.1440, -0.1337, -0.1374, -0.1545,\n",
      "        -0.1869, -0.1528, -0.1151, -0.1561, -0.1635, -0.1024, -0.1176, -0.1380,\n",
      "        -0.1287, -0.1615, -0.1253, -0.1954, -0.1316, -0.1430, -0.1186, -0.1793,\n",
      "        -0.1577, -0.1467, -0.1934, -0.1223, -0.1502, -0.1515, -0.1677, -0.1368,\n",
      "        -0.1388, -0.1017, -0.1358, -0.1544, -0.1019, -0.1509, -0.1558, -0.1329,\n",
      "        -0.1254, -0.1090, -0.1424, -0.1737, -0.1037, -0.1404, -0.2036, -0.1389,\n",
      "        -0.1910, -0.1885, -0.0743, -0.1641, -0.1261, -0.1808, -0.0982, -0.1698,\n",
      "        -0.1311, -0.1417, -0.1476, -0.1428, -0.2044, -0.1201, -0.1596, -0.1197,\n",
      "        -0.0936, -0.1711, -0.1480, -0.1360, -0.1030, -0.1744, -0.1520, -0.0923,\n",
      "        -0.1866, -0.1354, -0.1103, -0.1922, -0.2062, -0.1527, -0.1822, -0.1536,\n",
      "        -0.1211, -0.1339, -0.1801, -0.1173, -0.1331, -0.1399, -0.1151, -0.1454])\n",
      "4 Parameter containing:\n",
      "tensor([[[-0.1121,  0.0344,  0.0123,  ..., -0.0624, -0.0524,  0.0263],\n",
      "         [-0.0554,  0.0669,  0.0395,  ..., -0.0230,  0.0504, -0.0665],\n",
      "         [-0.0493, -0.0478, -0.0026,  ..., -0.0932, -0.0956, -0.0848],\n",
      "         ...,\n",
      "         [ 0.0994,  0.0665, -0.0057,  ..., -0.0616, -0.0016, -0.0458],\n",
      "         [-0.0186,  0.0443, -0.0515,  ..., -0.0264, -0.0257, -0.0355],\n",
      "         [-0.0090, -0.0201, -0.1338,  ...,  0.1347, -0.0515,  0.0030]],\n",
      "\n",
      "        [[ 0.0140,  0.0606,  0.0293,  ..., -0.0107, -0.0138,  0.0177],\n",
      "         [ 0.0351, -0.0204,  0.0903,  ..., -0.0157, -0.0617,  0.0314],\n",
      "         [ 0.1431,  0.0487,  0.0367,  ..., -0.0313,  0.0140, -0.0397],\n",
      "         ...,\n",
      "         [ 0.1034,  0.0195,  0.0795,  ...,  0.0250,  0.0452, -0.0863],\n",
      "         [-0.0085,  0.1108,  0.0134,  ...,  0.0445,  0.0694, -0.0800],\n",
      "         [ 0.0911, -0.0358,  0.0140,  ..., -0.0025, -0.0386, -0.1410]],\n",
      "\n",
      "        [[ 0.0791,  0.0110, -0.0094,  ..., -0.0089,  0.0046, -0.0969],\n",
      "         [-0.0037,  0.0441,  0.0891,  ..., -0.0711,  0.0145,  0.0354],\n",
      "         [-0.0120,  0.0059,  0.0534,  ...,  0.0918, -0.0213,  0.0806],\n",
      "         ...,\n",
      "         [-0.0101, -0.0131,  0.0090,  ...,  0.0257, -0.0563,  0.0390],\n",
      "         [ 0.0082, -0.0312,  0.0555,  ...,  0.0404, -0.0751, -0.0800],\n",
      "         [-0.0226, -0.0433,  0.0528,  ..., -0.0045,  0.0681,  0.0600]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1289, -0.0471,  0.0308,  ...,  0.0012, -0.0596, -0.0312],\n",
      "         [ 0.0006,  0.0731, -0.0637,  ...,  0.0984, -0.0068,  0.0236],\n",
      "         [-0.0170,  0.0145,  0.0289,  ...,  0.1074,  0.0335, -0.0123],\n",
      "         ...,\n",
      "         [ 0.0489,  0.0161,  0.0444,  ...,  0.0180, -0.0315, -0.0325],\n",
      "         [-0.0500,  0.0265,  0.0613,  ...,  0.0816,  0.0306,  0.0261],\n",
      "         [-0.0214,  0.0776, -0.0320,  ..., -0.1583,  0.0268, -0.0376]],\n",
      "\n",
      "        [[-0.0198, -0.0425, -0.0772,  ..., -0.0163,  0.0459,  0.0629],\n",
      "         [ 0.0011, -0.0221, -0.0494,  ...,  0.0811, -0.0128, -0.0027],\n",
      "         [-0.0196,  0.0422,  0.0089,  ..., -0.0893,  0.0927, -0.0431],\n",
      "         ...,\n",
      "         [-0.0337, -0.0267, -0.0687,  ..., -0.1156,  0.0254, -0.0644],\n",
      "         [-0.0432,  0.0421, -0.0528,  ..., -0.0777, -0.0058, -0.0356],\n",
      "         [-0.0290, -0.0119,  0.0024,  ..., -0.0182,  0.0036, -0.1189]],\n",
      "\n",
      "        [[ 0.0090,  0.0077,  0.0918,  ...,  0.1722,  0.0241, -0.0134],\n",
      "         [-0.0395, -0.1016,  0.0542,  ...,  0.0202, -0.0122, -0.0042],\n",
      "         [ 0.0701,  0.0004,  0.0172,  ...,  0.0032,  0.0484, -0.0239],\n",
      "         ...,\n",
      "         [-0.0274,  0.0440,  0.0082,  ..., -0.0350, -0.0438, -0.0787],\n",
      "         [-0.0259,  0.0228, -0.0566,  ..., -0.0597, -0.0799, -0.0650],\n",
      "         [ 0.0485, -0.0301,  0.0569,  ..., -0.0641,  0.0628, -0.0420]]])\n",
      "5 Parameter containing:\n",
      "tensor([-2.2685e-02, -9.9869e-03,  1.7768e-02, -2.3300e-04,  8.2204e-04,\n",
      "         6.3239e-03,  1.4120e-02, -2.4977e-02, -2.1335e-02, -3.3088e-02,\n",
      "        -2.0849e-02, -2.5302e-02, -2.1701e-02, -1.8497e-02, -2.4014e-02,\n",
      "         3.2751e-03, -1.9822e-02, -4.7154e-02, -2.1306e-02, -2.0303e-02,\n",
      "         1.5280e-02,  1.4467e-03, -1.6309e-02,  5.5553e-03,  4.9872e-03,\n",
      "        -2.0057e-02,  1.5172e-02,  3.0155e-02,  1.0467e-02, -1.0939e-02,\n",
      "        -1.0378e-02,  1.5827e-02,  1.7598e-02, -1.0572e-02,  1.2164e-02,\n",
      "        -2.4316e-02,  2.6181e-02, -1.7687e-02, -1.0547e-02, -3.8555e-02,\n",
      "         5.1929e-03, -3.7188e-02,  7.8528e-03,  2.0338e-02,  9.9242e-03,\n",
      "        -2.2298e-02, -1.0188e-02, -4.1082e-02, -1.5004e-02, -1.6826e-02,\n",
      "        -2.3093e-02, -3.2388e-02, -1.9352e-03, -2.3119e-02,  6.9892e-03,\n",
      "        -4.1613e-02,  8.7296e-03,  1.5074e-02, -2.0871e-02,  1.2452e-02,\n",
      "        -7.6117e-03, -1.1382e-02,  2.1815e-02, -4.7138e-02, -3.1730e-02,\n",
      "        -3.3618e-02,  1.6167e-02, -2.8795e-02,  1.5424e-02,  1.9948e-03,\n",
      "         2.0304e-03, -8.8944e-03,  1.8205e-02, -5.0433e-02, -8.2368e-03,\n",
      "         1.7528e-02,  2.1720e-02, -3.3047e-02,  1.5836e-02, -9.1891e-03,\n",
      "        -1.4058e-02,  4.3835e-03,  6.3935e-04, -5.7929e-02,  7.7190e-03,\n",
      "         1.6052e-02, -1.2383e-03, -3.3334e-02, -3.0267e-02, -4.5164e-02,\n",
      "        -1.6632e-02, -9.1981e-03,  2.3662e-03,  1.5858e-02,  2.2103e-02,\n",
      "        -3.0672e-02,  1.6392e-02, -1.9671e-02, -1.1408e-02, -1.8766e-05,\n",
      "        -2.7346e-02, -3.6109e-02,  1.3356e-02, -3.5367e-04,  2.2569e-02,\n",
      "         1.4064e-02, -2.0531e-02, -3.8737e-02,  1.0768e-02, -9.5071e-03,\n",
      "         2.8265e-02, -3.0957e-02, -1.5239e-02, -4.2789e-03,  1.4428e-02,\n",
      "        -1.4836e-02, -2.5694e-02,  4.0961e-03, -2.4915e-02,  4.2511e-03,\n",
      "        -2.3981e-02, -4.0684e-02, -1.5465e-02, -3.1164e-02,  4.6074e-03,\n",
      "        -3.9795e-02,  3.1285e-02, -4.3039e-02])\n",
      "6 Parameter containing:\n",
      "tensor([[-0.0989,  0.0004, -0.0910,  ..., -0.0649,  0.0447,  0.0528],\n",
      "        [-0.0345, -0.0016,  0.0238,  ...,  0.0476,  0.0545, -0.0508],\n",
      "        [-0.0585, -0.0456, -0.0728,  ...,  0.0116,  0.0020, -0.0305],\n",
      "        ...,\n",
      "        [ 0.0582, -0.1101,  0.0417,  ..., -0.0604, -0.0656, -0.0284],\n",
      "        [-0.0504,  0.0476,  0.0659,  ...,  0.0009,  0.0479, -0.0051],\n",
      "        [ 0.0562, -0.0531, -0.0310,  ...,  0.0509,  0.0040, -0.0665]])\n",
      "7 Parameter containing:\n",
      "tensor([-0.0276,  0.0221,  0.0045, -0.0111,  0.0339, -0.0753, -0.0510, -0.0168,\n",
      "        -0.0127, -0.0515, -0.0040, -0.0439, -0.0146, -0.0454,  0.0211,  0.0212,\n",
      "         0.0221,  0.0391, -0.0418,  0.0251,  0.0589,  0.0075,  0.0191, -0.0034,\n",
      "         0.0371,  0.0168,  0.0176, -0.0057, -0.0089, -0.0057, -0.0369, -0.0340,\n",
      "        -0.0183, -0.0028,  0.0440, -0.0829,  0.0414, -0.0301, -0.0130,  0.0298,\n",
      "        -0.0048, -0.0101, -0.0445, -0.0188,  0.0991,  0.0427, -0.0360,  0.0211,\n",
      "        -0.0413,  0.0473,  0.0586,  0.0249,  0.0498,  0.0216, -0.0616,  0.0017,\n",
      "        -0.0063,  0.0084,  0.0071,  0.0390, -0.0031, -0.0082, -0.0516, -0.0078,\n",
      "        -0.0344,  0.0219, -0.0044,  0.0106, -0.0112,  0.0214,  0.0019,  0.0032,\n",
      "        -0.0013, -0.0237, -0.0349,  0.0189, -0.0409, -0.0325,  0.0405,  0.0611,\n",
      "        -0.0097, -0.0169, -0.0670,  0.0121, -0.0472, -0.0514, -0.0259, -0.0142,\n",
      "        -0.0148,  0.0048,  0.0084,  0.0341,  0.0124, -0.0254, -0.0170, -0.0395,\n",
      "         0.0298,  0.0109, -0.0092,  0.0305, -0.0043,  0.0243, -0.0263, -0.0365,\n",
      "        -0.0176,  0.0075,  0.0383,  0.0386, -0.0085, -0.0574, -0.0110,  0.0192,\n",
      "        -0.0700,  0.0052, -0.0138, -0.0441, -0.0067, -0.0242, -0.0494,  0.0221,\n",
      "         0.0161,  0.0513,  0.0052,  0.0375,  0.0446,  0.0057, -0.0120,  0.0358,\n",
      "        -0.0076, -0.0069, -0.0096, -0.0005,  0.0044, -0.0072,  0.0066,  0.0007,\n",
      "        -0.0081,  0.0057, -0.0025,  0.0073,  0.0028, -0.0087, -0.0034, -0.0063,\n",
      "        -0.0063, -0.0007,  0.0096, -0.0114,  0.0024, -0.0045,  0.0011, -0.0037,\n",
      "        -0.0203,  0.0027, -0.0121,  0.0173, -0.0033, -0.0047, -0.0016, -0.0128,\n",
      "        -0.0002,  0.0071,  0.0023,  0.0054, -0.0072,  0.0046,  0.0045, -0.0034,\n",
      "         0.0081,  0.0015,  0.0004, -0.0043,  0.0056, -0.0263,  0.0050,  0.0021,\n",
      "        -0.0005,  0.0171,  0.0169,  0.0012,  0.0088, -0.0092, -0.0099, -0.0086,\n",
      "        -0.0030,  0.0204, -0.0048,  0.0055,  0.0051, -0.0051,  0.0013,  0.0055,\n",
      "        -0.0062, -0.0017,  0.0095, -0.0070,  0.0058, -0.0031,  0.0084, -0.0232,\n",
      "        -0.0058, -0.0080,  0.0068, -0.0071,  0.0040, -0.0008,  0.0118, -0.0008,\n",
      "         0.0067, -0.0179, -0.0027, -0.0149, -0.0091, -0.0045, -0.0001,  0.0009,\n",
      "        -0.0091,  0.0083, -0.0042,  0.0171, -0.0076, -0.0012,  0.0033, -0.0127,\n",
      "         0.0036, -0.0093, -0.0190, -0.0075,  0.0029,  0.0038, -0.0112,  0.0057,\n",
      "         0.0002, -0.0011, -0.0042, -0.0031,  0.0088,  0.0137,  0.0023,  0.0009,\n",
      "        -0.0005, -0.0031, -0.0046, -0.0088, -0.0048, -0.0074, -0.0029, -0.0041,\n",
      "        -0.0047, -0.0005, -0.0119,  0.0119, -0.0067,  0.0099,  0.0100, -0.0117,\n",
      "         0.0385, -0.0327,  0.0029, -0.0146, -0.0150, -0.0369, -0.0186,  0.0015,\n",
      "         0.0066, -0.0029,  0.0136,  0.0434,  0.0159, -0.0169, -0.0221, -0.0106,\n",
      "        -0.0003, -0.0311, -0.0208, -0.0158,  0.0276,  0.0112, -0.0074,  0.0265,\n",
      "         0.0043, -0.0409,  0.0347,  0.0451, -0.0209, -0.0204,  0.0037,  0.0315,\n",
      "        -0.0178,  0.0332,  0.0357, -0.0116,  0.0097,  0.0338,  0.0211,  0.0104,\n",
      "         0.0236,  0.0140, -0.0031,  0.0026,  0.0114, -0.0045, -0.0155,  0.0006,\n",
      "         0.0526,  0.0130, -0.0422,  0.0341, -0.0213,  0.0124,  0.0344, -0.0180,\n",
      "        -0.0183, -0.0138,  0.0238,  0.0065,  0.0313, -0.0354,  0.0263,  0.0058,\n",
      "         0.0042,  0.0130, -0.0091,  0.0429, -0.0302, -0.0230, -0.0129, -0.0182,\n",
      "        -0.0077,  0.0023,  0.0146, -0.0464,  0.0253, -0.0087,  0.0119, -0.0067,\n",
      "         0.0134,  0.0510,  0.0368,  0.0054,  0.0106,  0.0426,  0.0301, -0.0107,\n",
      "        -0.0397,  0.0077,  0.0290,  0.0254, -0.0101, -0.0495,  0.0026,  0.0034,\n",
      "         0.0020, -0.0153,  0.0105,  0.0339, -0.0145, -0.0031, -0.0220,  0.0157,\n",
      "         0.0056, -0.0341, -0.0314, -0.0199,  0.0092, -0.0051, -0.0136, -0.0050,\n",
      "         0.0212, -0.0153,  0.0082,  0.0253, -0.0398, -0.0589, -0.0026,  0.0069,\n",
      "        -0.0135,  0.0253, -0.0047,  0.0052, -0.0510,  0.0337,  0.0179, -0.0219])\n",
      "8 Parameter containing:\n",
      "tensor([[-0.0135,  0.1464, -0.0032,  ...,  0.0083,  0.1067,  0.0963],\n",
      "        [ 0.0666,  0.0379,  0.2431,  ..., -0.1008, -0.1791, -0.2208],\n",
      "        [-0.0669,  0.2044,  0.1060,  ...,  0.0850,  0.0113,  0.1406],\n",
      "        ...,\n",
      "        [ 0.0083, -0.0024, -0.0254,  ...,  0.0076, -0.2670, -0.0483],\n",
      "        [-0.1643,  0.0670,  0.0081,  ...,  0.0698,  0.0609, -0.1483],\n",
      "        [-0.1990,  0.1241, -0.0034,  ..., -0.0336, -0.0852, -0.0369]])\n",
      "9 Parameter containing:\n",
      "tensor([-0.0268, -0.0626,  0.0673,  0.0331, -0.0277, -0.0267, -0.0182, -0.0516,\n",
      "        -0.0381, -0.0307,  0.0460, -0.0022, -0.0568,  0.0051, -0.0662,  0.0575,\n",
      "         0.0321,  0.0134, -0.0013, -0.0144, -0.0340,  0.0169, -0.0197,  0.0113,\n",
      "        -0.0624, -0.0269, -0.0045,  0.0233,  0.0618,  0.0030, -0.0138, -0.0522,\n",
      "        -0.0126, -0.0281, -0.0024,  0.0273, -0.0051,  0.0559, -0.0438, -0.0129,\n",
      "         0.0225, -0.0030,  0.0123,  0.0662, -0.0333,  0.0080,  0.0291, -0.0210,\n",
      "         0.0283, -0.0016, -0.0256, -0.0409, -0.0391,  0.0035, -0.0074, -0.0915,\n",
      "        -0.0131,  0.0293, -0.0040,  0.0204, -0.0326,  0.0089, -0.0519, -0.0204,\n",
      "         0.0553,  0.0788,  0.0074, -0.0021,  0.0005,  0.0589,  0.0040,  0.0199,\n",
      "         0.0372,  0.1136, -0.0423, -0.0095, -0.0389,  0.0507, -0.0028, -0.0129,\n",
      "         0.0392, -0.0145, -0.0278, -0.0387, -0.0296,  0.0056, -0.0011, -0.0133,\n",
      "        -0.0146,  0.0158,  0.0451,  0.0259,  0.0102, -0.0074, -0.0228,  0.0486,\n",
      "         0.0039,  0.0155, -0.0846,  0.0280, -0.0121,  0.0163,  0.0199, -0.0239,\n",
      "         0.0037,  0.0206, -0.0202,  0.0532, -0.0138, -0.0213,  0.0900,  0.0319,\n",
      "        -0.0041, -0.0501, -0.0277, -0.0574,  0.0608,  0.0104, -0.0294,  0.0268,\n",
      "        -0.0393,  0.0843,  0.0224,  0.0061, -0.0337,  0.0118,  0.0235,  0.0318])\n",
      "10 Parameter containing:\n",
      "tensor([[ 0.0814,  0.0340, -0.0607,  ..., -0.2363,  0.0426, -0.0400],\n",
      "        [ 0.1116, -0.1111, -0.2305,  ..., -0.1173,  0.0144, -0.0314],\n",
      "        [ 0.0215,  0.0008, -0.0853,  ..., -0.1241,  0.0462,  0.0073],\n",
      "        ...,\n",
      "        [-0.0098, -0.0036, -0.3190,  ..., -0.0102,  0.1220, -0.2811],\n",
      "        [ 0.1360,  0.1877, -0.1655,  ...,  0.0333, -0.0561,  0.0375],\n",
      "        [-0.0913,  0.0928,  0.0441,  ...,  0.1054,  0.0097,  0.0476]])\n",
      "11 Parameter containing:\n",
      "tensor([-0.1196, -0.0256, -0.1338, -0.1295, -0.0210,  0.0069, -0.0388, -0.1842,\n",
      "        -0.1146, -0.0341, -0.1265, -0.0593, -0.0828,  0.0226, -0.1556, -0.1565,\n",
      "        -0.0775, -0.0050, -0.0473, -0.0529, -0.0671, -0.1114, -0.1258, -0.1485,\n",
      "        -0.1545, -0.1485, -0.0838, -0.1118, -0.0766, -0.1135, -0.1162, -0.0511,\n",
      "        -0.1545, -0.0141, -0.0515, -0.0495, -0.1283, -0.0364, -0.1502, -0.1414,\n",
      "        -0.0474, -0.1427, -0.0836,  0.0239, -0.1375, -0.0327, -0.1236, -0.0293,\n",
      "        -0.0438, -0.0985, -0.0138, -0.0516, -0.1723, -0.0831, -0.0512, -0.0548,\n",
      "        -0.1451,  0.0095, -0.0520, -0.1115, -0.1475, -0.0592, -0.0943, -0.1112,\n",
      "        -0.1044, -0.0907, -0.1068, -0.0969, -0.0946, -0.1235, -0.0786, -0.1874,\n",
      "        -0.0796, -0.1180, -0.0493, -0.0754, -0.0800,  0.0032, -0.0593, -0.1573,\n",
      "        -0.1831, -0.1002, -0.1455, -0.0827, -0.0203, -0.0680, -0.1417, -0.1131,\n",
      "         0.0296, -0.0057, -0.0782, -0.0883, -0.1479, -0.0295, -0.0296, -0.1419,\n",
      "         0.0096,  0.0063, -0.0847, -0.0356, -0.0411, -0.1439, -0.0656, -0.0920,\n",
      "        -0.0222, -0.0327, -0.0169, -0.0288, -0.1681, -0.1388, -0.1214, -0.0975,\n",
      "        -0.1823, -0.0323, -0.1315, -0.1222, -0.0569, -0.0872, -0.0588, -0.0290,\n",
      "        -0.0409, -0.1092, -0.1171,  0.0173, -0.0961, -0.1512,  0.0217, -0.0392,\n",
      "        -0.0591, -0.0855,  0.0164, -0.0217, -0.0402, -0.1333, -0.0421, -0.0934,\n",
      "        -0.0253,  0.0373, -0.0872, -0.1209, -0.1884,  0.0075,  0.0231, -0.1077,\n",
      "        -0.0298, -0.1134, -0.0129,  0.0029, -0.1538, -0.1519, -0.0155,  0.0210,\n",
      "        -0.1123, -0.0089, -0.0674, -0.0935, -0.0553, -0.0482, -0.1387, -0.0478,\n",
      "        -0.0217, -0.1112, -0.0648, -0.0359, -0.0241, -0.1583, -0.1677, -0.0732,\n",
      "         0.0052, -0.0388, -0.0517, -0.0377, -0.0533, -0.0839, -0.0243, -0.1229,\n",
      "        -0.0564, -0.0980, -0.1494, -0.0546, -0.0860, -0.0246, -0.0436, -0.0120,\n",
      "        -0.0718, -0.0676, -0.0876, -0.1070, -0.0350, -0.0477,  0.0431, -0.0159,\n",
      "         0.0478, -0.0162, -0.1116, -0.0050, -0.1706, -0.1682, -0.0281, -0.0424,\n",
      "        -0.1140, -0.1566, -0.1171, -0.0892, -0.0970, -0.0847,  0.0374, -0.0743,\n",
      "        -0.0172, -0.0129, -0.0131, -0.1061, -0.0634,  0.0060, -0.0419, -0.0121,\n",
      "        -0.0438, -0.1607, -0.0367, -0.0525, -0.0886,  0.0295,  0.0009, -0.1954,\n",
      "        -0.1381, -0.0475, -0.0951, -0.0308, -0.1022, -0.0390, -0.0582, -0.1342,\n",
      "        -0.0954, -0.0281, -0.1061, -0.1472, -0.1827, -0.0993, -0.1086, -0.0307,\n",
      "        -0.1181, -0.1270, -0.0192, -0.1339, -0.0699,  0.0058, -0.0830, -0.1582,\n",
      "        -0.0535, -0.0382, -0.1100, -0.0092,  0.0113, -0.1105, -0.0820, -0.1220])\n",
      "12 Parameter containing:\n",
      "tensor([[ 0.1496, -0.0677, -0.1143,  ...,  0.0621, -0.0139, -0.0496],\n",
      "        [-0.0064, -0.0270,  0.2149,  ..., -0.0127, -0.0296, -0.0407],\n",
      "        [ 0.0441, -0.0435, -0.0159,  ...,  0.0625,  0.0413, -0.0627],\n",
      "        ...,\n",
      "        [-0.1287, -0.1078,  0.2325,  ...,  0.0189,  0.0694,  0.0230],\n",
      "        [ 0.0198,  0.0073,  0.0836,  ..., -0.0333,  0.0071,  0.0789],\n",
      "        [-0.0489, -0.1414,  0.1296,  ...,  0.0326,  0.0827,  0.0749]])\n",
      "13 Parameter containing:\n",
      "tensor([ 0.0455, -0.0187, -0.0471, -0.0257, -0.0118, -0.0129,  0.0496, -0.0305,\n",
      "         0.0509,  0.0117, -0.0356,  0.0691, -0.0076, -0.0378,  0.0622, -0.0239,\n",
      "        -0.0409,  0.0252, -0.0371, -0.0426,  0.0115,  0.0117,  0.0490, -0.0392,\n",
      "         0.0084,  0.0095,  0.0157,  0.0160,  0.0224,  0.0427, -0.0315,  0.0280,\n",
      "        -0.0147,  0.0946,  0.0336, -0.0081,  0.0340, -0.0308,  0.0383, -0.0334,\n",
      "        -0.0103,  0.0295, -0.0487, -0.0267, -0.0304,  0.0117, -0.0103, -0.0043,\n",
      "         0.0443,  0.0362, -0.0254, -0.0480, -0.0032,  0.0250,  0.0323,  0.0193,\n",
      "         0.0338, -0.0136,  0.0479, -0.0022, -0.0282, -0.0051, -0.0122, -0.0109,\n",
      "        -0.0127, -0.0561, -0.0451,  0.0151,  0.0133,  0.0278,  0.0509,  0.0253,\n",
      "         0.0189, -0.0450,  0.0618,  0.0218, -0.0068,  0.0095, -0.0601, -0.0099,\n",
      "        -0.0037,  0.0241, -0.0310,  0.0156,  0.0316,  0.0394,  0.0250,  0.0174,\n",
      "         0.0435,  0.0031, -0.0701,  0.0199,  0.0219, -0.0367,  0.0229, -0.0591,\n",
      "        -0.0181, -0.0223,  0.0396,  0.0469, -0.0144,  0.0381,  0.0077,  0.0051,\n",
      "        -0.0105, -0.0106, -0.0531, -0.0626,  0.0318,  0.0030,  0.0226, -0.0578,\n",
      "        -0.0150, -0.0201,  0.0725,  0.0021,  0.0036, -0.0062,  0.0298, -0.0346,\n",
      "         0.0241, -0.0355, -0.0021,  0.0205,  0.0386,  0.0027, -0.0509, -0.0042])\n",
      "14 Parameter containing:\n",
      "tensor([0.8987, 0.8817, 0.8697, 0.8426, 0.8592, 0.8339, 0.8235, 0.8809, 0.8601,\n",
      "        0.9062, 0.8540, 0.8648, 0.8250, 0.8386, 0.8397, 0.8540, 0.8292, 0.8095,\n",
      "        0.7824, 0.8830, 0.9211, 0.9074, 0.9119, 0.9180, 0.9666, 0.8759, 0.9788,\n",
      "        0.8256, 0.9355, 0.8422, 0.9726, 0.9247, 0.8998, 0.9673, 0.8971, 0.9296,\n",
      "        0.8955, 0.9264, 0.9326, 0.9729, 0.8950, 0.9398, 0.8915, 0.9752, 0.9624,\n",
      "        0.9452, 0.9638, 0.9803, 0.9266, 0.8543, 0.9215, 0.9436, 0.8264, 0.9481,\n",
      "        0.9375, 0.9139, 0.9143, 0.8595, 0.9502, 0.9264, 0.9106, 0.9556, 0.9142,\n",
      "        0.8399, 0.9306, 0.9063, 0.9263, 0.9050, 0.9434, 0.9475, 0.8923, 0.9091,\n",
      "        0.9049, 0.9349, 0.9681, 0.8807, 0.9720, 0.8612, 0.9591, 0.8796, 0.9036,\n",
      "        0.9430, 0.9071, 0.9710, 0.9167, 0.8856, 0.9497, 0.9119, 0.9363, 0.9184,\n",
      "        0.9570, 0.8620, 0.9197, 0.9304, 0.9032, 0.9284, 0.9277, 0.8631, 0.9591,\n",
      "        0.9557, 0.9398, 0.9146, 0.9182, 0.9270, 0.8974, 0.8687, 0.8895, 0.9256,\n",
      "        0.9254, 0.9381, 0.9338, 0.8935, 0.9383, 0.9094, 0.9195, 0.9287, 0.9500,\n",
      "        0.9137, 0.9441, 0.9446, 0.8936, 0.8976, 0.9328, 0.9004, 0.8931, 0.8967,\n",
      "        0.8881, 0.9216])\n",
      "15 Parameter containing:\n",
      "tensor([-0.0647, -0.1538,  0.2192,  0.0401, -0.0625, -0.0141, -0.0553, -0.0791,\n",
      "        -0.1137, -0.1374,  0.1288,  0.0088, -0.0996,  0.0348, -0.1578,  0.1222,\n",
      "         0.0316,  0.0287,  0.0048, -0.0330, -0.0317,  0.0125, -0.0243,  0.0198,\n",
      "        -0.1616, -0.0403, -0.0049,  0.0344,  0.1747,  0.0237, -0.0742, -0.1984,\n",
      "        -0.0432, -0.1252,  0.0356,  0.0154, -0.0031,  0.1821, -0.1177, -0.0096,\n",
      "         0.0769, -0.0023,  0.0376,  0.1429, -0.0952, -0.0245,  0.0945, -0.0171,\n",
      "         0.0424,  0.0217, -0.0431, -0.0771, -0.0477,  0.0421, -0.0046, -0.1894,\n",
      "        -0.0091,  0.0325, -0.0283,  0.0261, -0.0926,  0.0773, -0.0589, -0.0228,\n",
      "         0.1420,  0.0981,  0.0651, -0.0112,  0.0089,  0.1321,  0.0136,  0.0400,\n",
      "         0.1074,  0.1430, -0.0654, -0.0484, -0.1242,  0.1005,  0.0457, -0.0656,\n",
      "         0.1008, -0.0614, -0.0910, -0.0445, -0.1259,  0.0438, -0.0652, -0.0758,\n",
      "         0.0010,  0.1060,  0.0655,  0.0479, -0.0099, -0.0192,  0.0436,  0.1259,\n",
      "        -0.0701,  0.0473, -0.1630,  0.0438, -0.0877,  0.0012,  0.0796, -0.0713,\n",
      "         0.0607,  0.1009, -0.0293,  0.1250, -0.0768, -0.0086,  0.2395,  0.1051,\n",
      "         0.0712, -0.0774, -0.0943, -0.1132,  0.1721,  0.0243, -0.0802,  0.0883,\n",
      "        -0.0437,  0.1503,  0.0665, -0.0108, -0.0638,  0.0683,  0.0103,  0.0718])\n",
      "16 Parameter containing:\n",
      "tensor([0.9358, 0.8523, 0.8931, 0.8611, 0.9536, 0.9179, 0.8457, 0.8573, 0.8891,\n",
      "        0.9129, 0.9060, 0.9110, 0.8844, 0.9277, 0.9001, 0.8694, 0.8137, 0.9014,\n",
      "        0.8999, 0.9360, 0.9459, 0.9357, 0.9313, 0.9320, 0.9035, 0.8567, 0.9473,\n",
      "        0.8826, 0.8809, 0.8430, 0.9179, 0.9209, 0.9145, 0.9068, 0.8485, 0.8868,\n",
      "        0.8904, 0.8482, 0.9136, 0.9721, 0.8335, 0.9084, 0.9008, 0.9297, 0.9811,\n",
      "        0.8997, 0.9463, 0.9757, 0.8533, 0.8842, 0.9353, 0.8953, 0.7927, 0.9491,\n",
      "        0.9502, 0.8568, 0.9503, 0.8511, 0.8969, 0.8569, 0.8810, 0.9202, 0.8868,\n",
      "        0.9052, 0.9077, 0.8413, 0.9470, 0.9093, 0.9264, 0.8494, 0.9062, 0.8743,\n",
      "        0.8446, 0.9147, 0.9005, 0.9090, 0.9817, 0.8388, 0.8739, 0.8509, 0.8662,\n",
      "        0.9092, 0.8899, 0.9310, 0.8502, 0.8347, 0.9529, 0.8891, 0.9068, 0.9134,\n",
      "        0.9681, 0.9082, 0.8719, 0.8800, 0.9074, 0.8893, 0.8908, 0.8949, 0.9235,\n",
      "        0.9365, 0.9277, 0.8973, 0.8186, 0.9134, 0.8712, 0.8686, 0.9060, 0.8778,\n",
      "        0.8377, 0.9102, 0.8512, 0.8670, 0.8897, 0.9222, 0.8993, 0.8966, 0.9216,\n",
      "        0.9038, 0.8690, 0.9347, 0.8746, 0.8361, 0.9225, 0.9515, 0.9138, 0.9055,\n",
      "        0.9065, 0.9300])\n",
      "17 Parameter containing:\n",
      "tensor([-0.0467,  0.0673, -0.0154, -0.0101, -0.0533, -0.0047,  0.1073, -0.0320,\n",
      "         0.0646,  0.0898,  0.0270, -0.0610,  0.0034,  0.0420, -0.0105, -0.0975,\n",
      "        -0.1117, -0.0429, -0.0060,  0.0190, -0.0071, -0.0034,  0.0172, -0.0489,\n",
      "         0.0182, -0.0163,  0.0299, -0.0535, -0.0428,  0.0069, -0.0402,  0.0308,\n",
      "        -0.0178,  0.0173, -0.0250,  0.0123, -0.0054, -0.0486,  0.1035,  0.0071,\n",
      "        -0.0598,  0.0360,  0.0457, -0.0669,  0.0446, -0.0342, -0.0303, -0.0346,\n",
      "        -0.0293,  0.0291,  0.0407,  0.0011, -0.0367, -0.0850,  0.0265,  0.0360,\n",
      "         0.0285, -0.0361, -0.0564,  0.0182,  0.0127,  0.0160, -0.0247, -0.0349,\n",
      "         0.0303,  0.0089, -0.0202, -0.0011, -0.0390, -0.0128, -0.0166,  0.0519,\n",
      "        -0.0530, -0.0403, -0.0029, -0.0614, -0.0212,  0.0658, -0.0578,  0.0402,\n",
      "        -0.0101,  0.0026,  0.0159,  0.0192, -0.0023, -0.0837,  0.0250, -0.0237,\n",
      "        -0.0558, -0.0065,  0.0023, -0.0250,  0.0067,  0.0643,  0.0615, -0.0176,\n",
      "         0.0136,  0.0174,  0.0670,  0.0445, -0.0349,  0.0039,  0.0034,  0.0173,\n",
      "        -0.0450,  0.0015, -0.0528, -0.0539,  0.0365, -0.0515, -0.0564,  0.0162,\n",
      "         0.0243, -0.0025,  0.0884,  0.0279,  0.0428,  0.0024,  0.0518, -0.0440,\n",
      "         0.0691,  0.0206, -0.0347, -0.0550, -0.0281,  0.0644,  0.0176,  0.0395])\n",
      "18 Parameter containing:\n",
      "tensor([[-0.0332,  0.0586, -0.0225,  ...,  0.0408,  0.0251,  0.0240],\n",
      "        [-0.0006,  0.0240,  0.0111,  ..., -0.0211, -0.0155, -0.0399],\n",
      "        [-0.0086, -0.0289, -0.0172,  ..., -0.0578, -0.0205, -0.0467],\n",
      "        ...,\n",
      "        [-0.0669, -0.0624,  0.0535,  ...,  0.0686,  0.0143,  0.0917],\n",
      "        [ 0.0117, -0.0718,  0.0468,  ..., -0.0033, -0.0702, -0.0422],\n",
      "        [ 0.0126,  0.0464,  0.0596,  ..., -0.0432,  0.0372, -0.0166]],\n",
      "       requires_grad=True)\n",
      "19 Parameter containing:\n",
      "tensor([ 0.0124, -0.0221, -0.0182,  ..., -0.0127, -0.0266, -0.0219],\n",
      "       requires_grad=True)\n",
      "20 Parameter containing:\n",
      "tensor([[[[-0.0564],\n",
      "          [-0.1843],\n",
      "          [-0.0902],\n",
      "          [ 0.1222],\n",
      "          [-0.0786],\n",
      "          [ 0.0311],\n",
      "          [-0.0688]],\n",
      "\n",
      "         [[-0.0806],\n",
      "          [-0.2378],\n",
      "          [ 0.2155],\n",
      "          [ 0.1445],\n",
      "          [-0.1175],\n",
      "          [-0.2618],\n",
      "          [-0.0326]],\n",
      "\n",
      "         [[-0.1567],\n",
      "          [-0.1257],\n",
      "          [ 0.1882],\n",
      "          [-0.0398],\n",
      "          [-0.0950],\n",
      "          [ 0.2951],\n",
      "          [ 0.0466]],\n",
      "\n",
      "         [[ 0.1292],\n",
      "          [ 0.0276],\n",
      "          [-0.1734],\n",
      "          [ 0.0924],\n",
      "          [ 0.0811],\n",
      "          [-0.1433],\n",
      "          [ 0.0264]],\n",
      "\n",
      "         [[ 0.0051],\n",
      "          [ 0.0665],\n",
      "          [ 0.0822],\n",
      "          [-0.1438],\n",
      "          [ 0.0939],\n",
      "          [ 0.0258],\n",
      "          [ 0.0176]],\n",
      "\n",
      "         [[-0.2408],\n",
      "          [-0.1277],\n",
      "          [ 0.0070],\n",
      "          [ 0.0185],\n",
      "          [-0.1691],\n",
      "          [ 0.0136],\n",
      "          [-0.0253]],\n",
      "\n",
      "         [[-0.1726],\n",
      "          [-0.2262],\n",
      "          [ 0.1466],\n",
      "          [-0.1643],\n",
      "          [ 0.0804],\n",
      "          [-0.0028],\n",
      "          [-0.0935]],\n",
      "\n",
      "         [[-0.2322],\n",
      "          [-0.0180],\n",
      "          [-0.0748],\n",
      "          [ 0.1940],\n",
      "          [ 0.0583],\n",
      "          [-0.0435],\n",
      "          [-0.0095]],\n",
      "\n",
      "         [[ 0.1191],\n",
      "          [ 0.0745],\n",
      "          [ 0.0888],\n",
      "          [ 0.1815],\n",
      "          [ 0.0327],\n",
      "          [-0.0646],\n",
      "          [ 0.0368]],\n",
      "\n",
      "         [[ 0.0671],\n",
      "          [-0.3166],\n",
      "          [ 0.1036],\n",
      "          [-0.1709],\n",
      "          [ 0.1194],\n",
      "          [-0.1308],\n",
      "          [ 0.1101]],\n",
      "\n",
      "         [[ 0.0440],\n",
      "          [ 0.0272],\n",
      "          [ 0.0407],\n",
      "          [-0.0466],\n",
      "          [ 0.1770],\n",
      "          [-0.0041],\n",
      "          [-0.0713]],\n",
      "\n",
      "         [[ 0.1182],\n",
      "          [-0.1531],\n",
      "          [ 0.1003],\n",
      "          [ 0.0476],\n",
      "          [-0.1756],\n",
      "          [-0.0770],\n",
      "          [-0.4175]],\n",
      "\n",
      "         [[-0.0821],\n",
      "          [-0.0144],\n",
      "          [ 0.0720],\n",
      "          [-0.1176],\n",
      "          [ 0.0557],\n",
      "          [-0.1044],\n",
      "          [ 0.0367]],\n",
      "\n",
      "         [[ 0.0440],\n",
      "          [ 0.0151],\n",
      "          [ 0.0408],\n",
      "          [ 0.2329],\n",
      "          [ 0.0410],\n",
      "          [ 0.0363],\n",
      "          [-0.1716]],\n",
      "\n",
      "         [[-0.0396],\n",
      "          [ 0.0702],\n",
      "          [-0.1004],\n",
      "          [-0.1640],\n",
      "          [ 0.0761],\n",
      "          [ 0.0800],\n",
      "          [ 0.1054]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1455],\n",
      "          [-0.2527],\n",
      "          [-0.0831],\n",
      "          [-0.2934],\n",
      "          [ 0.0704],\n",
      "          [ 0.0399],\n",
      "          [-0.0412]],\n",
      "\n",
      "         [[ 0.3476],\n",
      "          [-0.0334],\n",
      "          [-0.1733],\n",
      "          [ 0.0773],\n",
      "          [-0.1248],\n",
      "          [ 0.0052],\n",
      "          [ 0.0396]],\n",
      "\n",
      "         [[ 0.0137],\n",
      "          [ 0.0192],\n",
      "          [-0.0230],\n",
      "          [ 0.0556],\n",
      "          [ 0.0080],\n",
      "          [-0.0818],\n",
      "          [-0.1990]],\n",
      "\n",
      "         [[-0.0344],\n",
      "          [ 0.1088],\n",
      "          [ 0.1722],\n",
      "          [-0.0684],\n",
      "          [-0.0540],\n",
      "          [-0.0378],\n",
      "          [-0.0336]],\n",
      "\n",
      "         [[-0.1447],\n",
      "          [ 0.0849],\n",
      "          [-0.1565],\n",
      "          [ 0.0710],\n",
      "          [-0.0702],\n",
      "          [-0.1524],\n",
      "          [-0.1074]],\n",
      "\n",
      "         [[-0.1103],\n",
      "          [-0.0247],\n",
      "          [ 0.1797],\n",
      "          [ 0.0368],\n",
      "          [ 0.0230],\n",
      "          [ 0.1138],\n",
      "          [ 0.0389]],\n",
      "\n",
      "         [[-0.0382],\n",
      "          [-0.0412],\n",
      "          [-0.1971],\n",
      "          [ 0.1066],\n",
      "          [ 0.1133],\n",
      "          [ 0.3243],\n",
      "          [ 0.0061]],\n",
      "\n",
      "         [[-0.0289],\n",
      "          [ 0.2133],\n",
      "          [ 0.2196],\n",
      "          [-0.0422],\n",
      "          [ 0.3170],\n",
      "          [ 0.0377],\n",
      "          [ 0.0397]],\n",
      "\n",
      "         [[ 0.1388],\n",
      "          [ 0.2046],\n",
      "          [ 0.0125],\n",
      "          [ 0.0891],\n",
      "          [-0.1666],\n",
      "          [ 0.0709],\n",
      "          [-0.0622]],\n",
      "\n",
      "         [[-0.3294],\n",
      "          [ 0.1665],\n",
      "          [-0.1037],\n",
      "          [-0.1391],\n",
      "          [ 0.2131],\n",
      "          [-0.1364],\n",
      "          [-0.1923]],\n",
      "\n",
      "         [[ 0.2546],\n",
      "          [-0.0456],\n",
      "          [-0.1083],\n",
      "          [-0.1183],\n",
      "          [-0.2009],\n",
      "          [-0.0444],\n",
      "          [ 0.0518]],\n",
      "\n",
      "         [[ 0.0530],\n",
      "          [ 0.0020],\n",
      "          [-0.0263],\n",
      "          [ 0.0978],\n",
      "          [ 0.0237],\n",
      "          [ 0.1794],\n",
      "          [-0.0761]],\n",
      "\n",
      "         [[-0.1669],\n",
      "          [ 0.1991],\n",
      "          [ 0.1298],\n",
      "          [-0.2013],\n",
      "          [-0.1031],\n",
      "          [ 0.2198],\n",
      "          [-0.1358]],\n",
      "\n",
      "         [[-0.0213],\n",
      "          [-0.1802],\n",
      "          [ 0.0687],\n",
      "          [-0.1050],\n",
      "          [-0.1597],\n",
      "          [ 0.0612],\n",
      "          [ 0.2050]],\n",
      "\n",
      "         [[ 0.0925],\n",
      "          [-0.0227],\n",
      "          [ 0.1861],\n",
      "          [ 0.0625],\n",
      "          [-0.0918],\n",
      "          [-0.0062],\n",
      "          [ 0.2044]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1091],\n",
      "          [-0.1747],\n",
      "          [ 0.0625],\n",
      "          [-0.0592],\n",
      "          [-0.1142],\n",
      "          [ 0.0467],\n",
      "          [ 0.0286]],\n",
      "\n",
      "         [[ 0.1928],\n",
      "          [ 0.2820],\n",
      "          [ 0.1035],\n",
      "          [ 0.2259],\n",
      "          [ 0.0153],\n",
      "          [-0.0809],\n",
      "          [-0.0443]],\n",
      "\n",
      "         [[ 0.0860],\n",
      "          [-0.1012],\n",
      "          [ 0.0336],\n",
      "          [ 0.0979],\n",
      "          [ 0.0122],\n",
      "          [-0.0945],\n",
      "          [ 0.1599]],\n",
      "\n",
      "         [[-0.1796],\n",
      "          [ 0.0132],\n",
      "          [ 0.0906],\n",
      "          [-0.1217],\n",
      "          [ 0.0952],\n",
      "          [-0.2011],\n",
      "          [-0.1588]],\n",
      "\n",
      "         [[-0.3495],\n",
      "          [ 0.4641],\n",
      "          [-0.1003],\n",
      "          [ 0.0035],\n",
      "          [ 0.1428],\n",
      "          [ 0.0298],\n",
      "          [ 0.1172]],\n",
      "\n",
      "         [[ 0.0773],\n",
      "          [ 0.1029],\n",
      "          [ 0.1324],\n",
      "          [-0.1449],\n",
      "          [ 0.1605],\n",
      "          [ 0.0358],\n",
      "          [ 0.0756]],\n",
      "\n",
      "         [[-0.1281],\n",
      "          [-0.0529],\n",
      "          [ 0.0299],\n",
      "          [-0.1159],\n",
      "          [-0.0481],\n",
      "          [ 0.1700],\n",
      "          [-0.0684]],\n",
      "\n",
      "         [[ 0.0837],\n",
      "          [ 0.1249],\n",
      "          [ 0.0210],\n",
      "          [-0.1193],\n",
      "          [-0.0105],\n",
      "          [ 0.0042],\n",
      "          [ 0.0457]],\n",
      "\n",
      "         [[ 0.0587],\n",
      "          [ 0.0666],\n",
      "          [ 0.0715],\n",
      "          [ 0.0402],\n",
      "          [ 0.0224],\n",
      "          [ 0.0108],\n",
      "          [-0.0223]],\n",
      "\n",
      "         [[ 0.1399],\n",
      "          [-0.0502],\n",
      "          [ 0.0403],\n",
      "          [ 0.0527],\n",
      "          [ 0.1359],\n",
      "          [ 0.2048],\n",
      "          [-0.0269]],\n",
      "\n",
      "         [[-0.0338],\n",
      "          [ 0.1462],\n",
      "          [-0.0089],\n",
      "          [-0.1376],\n",
      "          [ 0.0101],\n",
      "          [-0.1029],\n",
      "          [-0.0471]],\n",
      "\n",
      "         [[ 0.1796],\n",
      "          [-0.0006],\n",
      "          [-0.0116],\n",
      "          [ 0.0377],\n",
      "          [ 0.0488],\n",
      "          [ 0.0054],\n",
      "          [ 0.1655]],\n",
      "\n",
      "         [[-0.1051],\n",
      "          [-0.3865],\n",
      "          [-0.2452],\n",
      "          [ 0.0055],\n",
      "          [-0.1057],\n",
      "          [ 0.0078],\n",
      "          [-0.1644]],\n",
      "\n",
      "         [[ 0.1015],\n",
      "          [ 0.0413],\n",
      "          [ 0.1447],\n",
      "          [ 0.0601],\n",
      "          [ 0.0907],\n",
      "          [ 0.0600],\n",
      "          [-0.0799]],\n",
      "\n",
      "         [[-0.0382],\n",
      "          [ 0.0832],\n",
      "          [ 0.0318],\n",
      "          [ 0.0375],\n",
      "          [-0.1432],\n",
      "          [-0.1943],\n",
      "          [ 0.0545]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0469],\n",
      "          [ 0.1715],\n",
      "          [ 0.1458],\n",
      "          [ 0.1838],\n",
      "          [-0.2277],\n",
      "          [-0.1047],\n",
      "          [-0.1505]],\n",
      "\n",
      "         [[-0.1573],\n",
      "          [-0.1292],\n",
      "          [ 0.1605],\n",
      "          [-0.1116],\n",
      "          [-0.0299],\n",
      "          [-0.0781],\n",
      "          [-0.1499]],\n",
      "\n",
      "         [[-0.1282],\n",
      "          [ 0.1518],\n",
      "          [ 0.0517],\n",
      "          [-0.0513],\n",
      "          [ 0.1838],\n",
      "          [ 0.0056],\n",
      "          [-0.0747]],\n",
      "\n",
      "         [[ 0.1142],\n",
      "          [-0.1551],\n",
      "          [-0.2038],\n",
      "          [-0.1129],\n",
      "          [ 0.0665],\n",
      "          [ 0.0282],\n",
      "          [ 0.1541]],\n",
      "\n",
      "         [[ 0.0054],\n",
      "          [ 0.0437],\n",
      "          [-0.1371],\n",
      "          [-0.1034],\n",
      "          [ 0.0325],\n",
      "          [ 0.0617],\n",
      "          [-0.1932]],\n",
      "\n",
      "         [[-0.1831],\n",
      "          [-0.0986],\n",
      "          [-0.0644],\n",
      "          [ 0.0508],\n",
      "          [ 0.0362],\n",
      "          [ 0.0970],\n",
      "          [ 0.0393]],\n",
      "\n",
      "         [[-0.0155],\n",
      "          [ 0.1417],\n",
      "          [ 0.1679],\n",
      "          [-0.0219],\n",
      "          [ 0.2188],\n",
      "          [-0.0793],\n",
      "          [ 0.1213]],\n",
      "\n",
      "         [[-0.1682],\n",
      "          [ 0.0417],\n",
      "          [ 0.2581],\n",
      "          [ 0.0153],\n",
      "          [-0.1441],\n",
      "          [-0.0567],\n",
      "          [-0.0440]],\n",
      "\n",
      "         [[-0.0943],\n",
      "          [ 0.0717],\n",
      "          [-0.0562],\n",
      "          [ 0.1529],\n",
      "          [-0.0880],\n",
      "          [-0.0836],\n",
      "          [-0.0331]],\n",
      "\n",
      "         [[ 0.0216],\n",
      "          [ 0.0925],\n",
      "          [-0.1878],\n",
      "          [ 0.1072],\n",
      "          [ 0.0343],\n",
      "          [-0.0851],\n",
      "          [ 0.0309]],\n",
      "\n",
      "         [[-0.1112],\n",
      "          [ 0.0339],\n",
      "          [ 0.0118],\n",
      "          [-0.0506],\n",
      "          [-0.1063],\n",
      "          [-0.1543],\n",
      "          [-0.1122]],\n",
      "\n",
      "         [[ 0.0535],\n",
      "          [ 0.3092],\n",
      "          [ 0.1051],\n",
      "          [-0.0137],\n",
      "          [-0.1432],\n",
      "          [ 0.1509],\n",
      "          [-0.1722]],\n",
      "\n",
      "         [[ 0.0354],\n",
      "          [ 0.0831],\n",
      "          [-0.3707],\n",
      "          [ 0.0108],\n",
      "          [ 0.1083],\n",
      "          [ 0.2151],\n",
      "          [ 0.0813]],\n",
      "\n",
      "         [[ 0.2974],\n",
      "          [ 0.1815],\n",
      "          [-0.0688],\n",
      "          [-0.1177],\n",
      "          [ 0.3112],\n",
      "          [ 0.0178],\n",
      "          [ 0.1780]],\n",
      "\n",
      "         [[-0.1161],\n",
      "          [-0.0553],\n",
      "          [-0.0744],\n",
      "          [ 0.0278],\n",
      "          [-0.0360],\n",
      "          [ 0.0855],\n",
      "          [ 0.0838]]],\n",
      "\n",
      "\n",
      "        [[[-0.2917],\n",
      "          [ 0.0865],\n",
      "          [-0.0279],\n",
      "          [ 0.2312],\n",
      "          [-0.1338],\n",
      "          [-0.0718],\n",
      "          [-0.1667]],\n",
      "\n",
      "         [[-0.0417],\n",
      "          [ 0.0076],\n",
      "          [-0.1372],\n",
      "          [ 0.1384],\n",
      "          [ 0.2414],\n",
      "          [-0.0165],\n",
      "          [-0.1295]],\n",
      "\n",
      "         [[-0.1330],\n",
      "          [-0.0858],\n",
      "          [-0.1716],\n",
      "          [-0.1513],\n",
      "          [-0.0829],\n",
      "          [ 0.1344],\n",
      "          [-0.0015]],\n",
      "\n",
      "         [[ 0.0812],\n",
      "          [-0.0774],\n",
      "          [-0.0631],\n",
      "          [ 0.1595],\n",
      "          [ 0.0778],\n",
      "          [ 0.1329],\n",
      "          [-0.0136]],\n",
      "\n",
      "         [[ 0.0821],\n",
      "          [-0.1524],\n",
      "          [ 0.2227],\n",
      "          [-0.1555],\n",
      "          [-0.2174],\n",
      "          [ 0.0918],\n",
      "          [-0.0789]],\n",
      "\n",
      "         [[-0.0341],\n",
      "          [-0.0692],\n",
      "          [ 0.0434],\n",
      "          [ 0.0759],\n",
      "          [-0.2025],\n",
      "          [ 0.0209],\n",
      "          [-0.1401]],\n",
      "\n",
      "         [[-0.1231],\n",
      "          [ 0.0767],\n",
      "          [-0.2105],\n",
      "          [ 0.1581],\n",
      "          [ 0.0120],\n",
      "          [-0.0969],\n",
      "          [ 0.0341]],\n",
      "\n",
      "         [[ 0.1373],\n",
      "          [ 0.2149],\n",
      "          [-0.0653],\n",
      "          [-0.0912],\n",
      "          [-0.0172],\n",
      "          [ 0.2823],\n",
      "          [ 0.2379]],\n",
      "\n",
      "         [[-0.2054],\n",
      "          [ 0.0786],\n",
      "          [-0.0408],\n",
      "          [ 0.1121],\n",
      "          [-0.0233],\n",
      "          [-0.0316],\n",
      "          [-0.1583]],\n",
      "\n",
      "         [[-0.0101],\n",
      "          [ 0.1552],\n",
      "          [ 0.1923],\n",
      "          [-0.2059],\n",
      "          [ 0.0310],\n",
      "          [ 0.0117],\n",
      "          [-0.0041]],\n",
      "\n",
      "         [[-0.2372],\n",
      "          [-0.0601],\n",
      "          [ 0.0541],\n",
      "          [-0.0938],\n",
      "          [-0.0980],\n",
      "          [-0.1649],\n",
      "          [ 0.2013]],\n",
      "\n",
      "         [[-0.1991],\n",
      "          [ 0.0715],\n",
      "          [-0.0553],\n",
      "          [-0.0493],\n",
      "          [-0.2411],\n",
      "          [ 0.1633],\n",
      "          [-0.2999]],\n",
      "\n",
      "         [[ 0.2134],\n",
      "          [-0.1030],\n",
      "          [-0.1474],\n",
      "          [-0.1221],\n",
      "          [-0.2040],\n",
      "          [-0.1308],\n",
      "          [-0.1773]],\n",
      "\n",
      "         [[ 0.0743],\n",
      "          [-0.1092],\n",
      "          [-0.0925],\n",
      "          [ 0.0008],\n",
      "          [ 0.1445],\n",
      "          [ 0.1069],\n",
      "          [ 0.0821]],\n",
      "\n",
      "         [[ 0.0156],\n",
      "          [ 0.3481],\n",
      "          [-0.1833],\n",
      "          [-0.0747],\n",
      "          [-0.0074],\n",
      "          [ 0.2436],\n",
      "          [ 0.0293]]],\n",
      "\n",
      "\n",
      "        [[[-0.1144],\n",
      "          [ 0.2252],\n",
      "          [-0.0619],\n",
      "          [-0.2052],\n",
      "          [ 0.1617],\n",
      "          [ 0.1929],\n",
      "          [ 0.1985]],\n",
      "\n",
      "         [[-0.0598],\n",
      "          [ 0.1121],\n",
      "          [ 0.1042],\n",
      "          [ 0.1205],\n",
      "          [-0.1695],\n",
      "          [ 0.0391],\n",
      "          [ 0.0111]],\n",
      "\n",
      "         [[-0.1410],\n",
      "          [ 0.0884],\n",
      "          [ 0.1580],\n",
      "          [ 0.2198],\n",
      "          [ 0.0011],\n",
      "          [-0.0416],\n",
      "          [-0.1194]],\n",
      "\n",
      "         [[ 0.2011],\n",
      "          [ 0.1009],\n",
      "          [-0.2510],\n",
      "          [-0.1020],\n",
      "          [ 0.1169],\n",
      "          [ 0.1596],\n",
      "          [ 0.2602]],\n",
      "\n",
      "         [[-0.0525],\n",
      "          [-0.0447],\n",
      "          [-0.0274],\n",
      "          [-0.2790],\n",
      "          [ 0.1212],\n",
      "          [-0.1865],\n",
      "          [-0.0691]],\n",
      "\n",
      "         [[ 0.0886],\n",
      "          [ 0.1073],\n",
      "          [-0.2724],\n",
      "          [-0.0582],\n",
      "          [-0.0185],\n",
      "          [ 0.2633],\n",
      "          [-0.0766]],\n",
      "\n",
      "         [[-0.0665],\n",
      "          [ 0.1442],\n",
      "          [-0.0725],\n",
      "          [-0.1577],\n",
      "          [-0.0524],\n",
      "          [-0.0727],\n",
      "          [ 0.0622]],\n",
      "\n",
      "         [[-0.1965],\n",
      "          [ 0.0979],\n",
      "          [ 0.3047],\n",
      "          [-0.1928],\n",
      "          [ 0.2620],\n",
      "          [ 0.1391],\n",
      "          [-0.0623]],\n",
      "\n",
      "         [[ 0.2389],\n",
      "          [-0.1801],\n",
      "          [-0.2146],\n",
      "          [-0.0890],\n",
      "          [ 0.0642],\n",
      "          [-0.0663],\n",
      "          [ 0.0804]],\n",
      "\n",
      "         [[-0.1056],\n",
      "          [-0.1840],\n",
      "          [ 0.1497],\n",
      "          [ 0.0325],\n",
      "          [ 0.1721],\n",
      "          [-0.3315],\n",
      "          [ 0.0044]],\n",
      "\n",
      "         [[-0.0602],\n",
      "          [-0.2935],\n",
      "          [ 0.1152],\n",
      "          [ 0.0914],\n",
      "          [-0.0521],\n",
      "          [-0.0242],\n",
      "          [-0.1227]],\n",
      "\n",
      "         [[-0.0136],\n",
      "          [-0.0815],\n",
      "          [ 0.2335],\n",
      "          [-0.1198],\n",
      "          [ 0.2432],\n",
      "          [-0.1396],\n",
      "          [-0.1227]],\n",
      "\n",
      "         [[-0.1326],\n",
      "          [-0.1214],\n",
      "          [ 0.0573],\n",
      "          [-0.0319],\n",
      "          [ 0.0705],\n",
      "          [-0.3750],\n",
      "          [-0.1365]],\n",
      "\n",
      "         [[-0.0920],\n",
      "          [-0.0492],\n",
      "          [ 0.0212],\n",
      "          [-0.0178],\n",
      "          [ 0.0167],\n",
      "          [ 0.1663],\n",
      "          [ 0.1996]],\n",
      "\n",
      "         [[-0.0080],\n",
      "          [-0.0157],\n",
      "          [ 0.1823],\n",
      "          [-0.0427],\n",
      "          [-0.1880],\n",
      "          [-0.1739],\n",
      "          [ 0.0025]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0011],\n",
      "          [ 0.2008],\n",
      "          [ 0.0398],\n",
      "          [ 0.2561],\n",
      "          [-0.2163],\n",
      "          [-0.1385],\n",
      "          [-0.4336]],\n",
      "\n",
      "         [[-0.0596],\n",
      "          [-0.2483],\n",
      "          [-0.0875],\n",
      "          [ 0.1567],\n",
      "          [-0.0563],\n",
      "          [-0.0509],\n",
      "          [ 0.0150]],\n",
      "\n",
      "         [[-0.0762],\n",
      "          [-0.1939],\n",
      "          [ 0.0921],\n",
      "          [ 0.0622],\n",
      "          [-0.1251],\n",
      "          [-0.1946],\n",
      "          [ 0.0859]],\n",
      "\n",
      "         [[-0.1182],\n",
      "          [-0.0603],\n",
      "          [-0.0117],\n",
      "          [ 0.0430],\n",
      "          [ 0.0192],\n",
      "          [-0.1530],\n",
      "          [-0.2718]],\n",
      "\n",
      "         [[ 0.0661],\n",
      "          [ 0.0600],\n",
      "          [ 0.0247],\n",
      "          [-0.1334],\n",
      "          [ 0.1093],\n",
      "          [ 0.0653],\n",
      "          [ 0.0120]],\n",
      "\n",
      "         [[-0.0844],\n",
      "          [-0.0775],\n",
      "          [-0.2273],\n",
      "          [-0.0824],\n",
      "          [-0.1033],\n",
      "          [-0.0251],\n",
      "          [-0.1688]],\n",
      "\n",
      "         [[-0.0521],\n",
      "          [-0.0136],\n",
      "          [-0.0658],\n",
      "          [ 0.0196],\n",
      "          [-0.0583],\n",
      "          [ 0.1337],\n",
      "          [ 0.0417]],\n",
      "\n",
      "         [[-0.0618],\n",
      "          [ 0.0177],\n",
      "          [ 0.0535],\n",
      "          [-0.2757],\n",
      "          [-0.0220],\n",
      "          [-0.0369],\n",
      "          [ 0.1014]],\n",
      "\n",
      "         [[-0.1493],\n",
      "          [-0.0075],\n",
      "          [ 0.2588],\n",
      "          [-0.1886],\n",
      "          [-0.0189],\n",
      "          [-0.0068],\n",
      "          [-0.1221]],\n",
      "\n",
      "         [[ 0.0364],\n",
      "          [-0.2720],\n",
      "          [ 0.0870],\n",
      "          [-0.0444],\n",
      "          [-0.0045],\n",
      "          [-0.0730],\n",
      "          [ 0.0099]],\n",
      "\n",
      "         [[-0.0187],\n",
      "          [-0.0457],\n",
      "          [-0.2437],\n",
      "          [ 0.0011],\n",
      "          [ 0.0717],\n",
      "          [-0.0905],\n",
      "          [-0.0674]],\n",
      "\n",
      "         [[ 0.0187],\n",
      "          [ 0.1927],\n",
      "          [ 0.1920],\n",
      "          [-0.1183],\n",
      "          [ 0.2116],\n",
      "          [-0.0656],\n",
      "          [-0.0667]],\n",
      "\n",
      "         [[-0.2284],\n",
      "          [ 0.0039],\n",
      "          [-0.0949],\n",
      "          [-0.2665],\n",
      "          [ 0.1202],\n",
      "          [ 0.0096],\n",
      "          [-0.1445]],\n",
      "\n",
      "         [[ 0.0087],\n",
      "          [-0.0788],\n",
      "          [-0.1123],\n",
      "          [-0.1358],\n",
      "          [-0.1717],\n",
      "          [ 0.0017],\n",
      "          [-0.0123]],\n",
      "\n",
      "         [[ 0.1471],\n",
      "          [ 0.0023],\n",
      "          [-0.1741],\n",
      "          [ 0.0344],\n",
      "          [-0.0811],\n",
      "          [-0.0897],\n",
      "          [-0.0039]]]])\n",
      "21 Parameter containing:\n",
      "tensor([ 0.0135,  0.0146,  0.0328,  0.1242, -0.0687, -0.0280,  0.0804])\n",
      "22 Parameter containing:\n",
      "tensor([0.9302, 0.9131, 0.9211, 1.0419, 0.9490, 0.9586, 1.0231])\n",
      "23 Parameter containing:\n",
      "tensor([-0.0155, -0.0013, -0.0317,  0.0495,  0.0190,  0.0144,  0.0184])\n",
      "24 Parameter containing:\n",
      "tensor([[[-0.9180,  0.0149,  0.8810]]])\n",
      "25 Parameter containing:\n",
      "tensor([[[[ 0.0961],\n",
      "          [ 0.1185],\n",
      "          [ 0.1806],\n",
      "          [-0.0957],\n",
      "          [-0.1032],\n",
      "          [-0.2755],\n",
      "          [ 0.2202]],\n",
      "\n",
      "         [[-0.1478],\n",
      "          [-0.1136],\n",
      "          [-0.3203],\n",
      "          [-0.0186],\n",
      "          [ 0.0448],\n",
      "          [-0.0191],\n",
      "          [-0.0810]],\n",
      "\n",
      "         [[ 0.4268],\n",
      "          [-0.3269],\n",
      "          [-0.1717],\n",
      "          [-0.3920],\n",
      "          [-0.1762],\n",
      "          [ 0.1928],\n",
      "          [ 0.2188]],\n",
      "\n",
      "         [[-0.2828],\n",
      "          [-0.2923],\n",
      "          [ 0.2850],\n",
      "          [-0.0018],\n",
      "          [ 0.2387],\n",
      "          [-0.0880],\n",
      "          [-0.0425]],\n",
      "\n",
      "         [[-0.1252],\n",
      "          [-0.1964],\n",
      "          [ 0.3040],\n",
      "          [ 0.0235],\n",
      "          [-0.1431],\n",
      "          [ 0.0148],\n",
      "          [ 0.1600]],\n",
      "\n",
      "         [[ 0.1668],\n",
      "          [ 0.0140],\n",
      "          [-0.0842],\n",
      "          [ 0.0264],\n",
      "          [-0.1064],\n",
      "          [-0.0806],\n",
      "          [ 0.3453]],\n",
      "\n",
      "         [[-0.1852],\n",
      "          [ 0.0208],\n",
      "          [ 0.1064],\n",
      "          [ 0.0989],\n",
      "          [ 0.1110],\n",
      "          [-0.2808],\n",
      "          [-0.0665]]]])\n",
      "26 Parameter containing:\n",
      "tensor([-0.1169])\n",
      "27 Parameter containing:\n",
      "tensor([1.1254])\n",
      "28 Parameter containing:\n",
      "tensor([-0.1577])\n",
      "29 Parameter containing:\n",
      "tensor([[[ 0.4524, -1.9463, -1.0665]]])\n",
      "30 Parameter containing:\n",
      "tensor([[[ 4.1289e-02, -1.7699e-01, -5.3084e-02,  ..., -3.2913e-02,\n",
      "           3.0623e-02,  5.4850e-01],\n",
      "         [-6.8168e-04, -6.9128e-02,  8.4097e-02,  ..., -1.4632e-02,\n",
      "          -2.8297e-01,  1.5419e-01],\n",
      "         [-4.1488e-01, -8.4018e-02,  4.3532e-01,  ...,  5.1070e-01,\n",
      "          -1.4416e-01, -3.4245e-01],\n",
      "         [-2.7500e-01, -9.2454e-02, -1.9878e-01,  ..., -2.5585e-01,\n",
      "          -1.4744e-02, -2.5108e-01]],\n",
      "\n",
      "        [[-9.5320e-02,  7.4630e-02,  8.9576e-02,  ...,  6.8803e-01,\n",
      "          -6.8758e-01, -7.0963e-01],\n",
      "         [-3.2988e-01,  5.4799e-01, -9.9434e-02,  ..., -9.7263e-02,\n",
      "          -2.1913e-01,  9.2484e-02],\n",
      "         [ 9.8908e-02, -2.7911e-01,  3.1010e-02,  ..., -5.4337e-01,\n",
      "          -1.7564e-01,  4.3032e-02],\n",
      "         [ 1.6598e-01,  9.0197e-03,  5.2593e-02,  ...,  4.4336e-01,\n",
      "          -2.3898e-01, -6.1945e-02]],\n",
      "\n",
      "        [[-2.9754e-01,  4.2642e-02,  1.8933e-01,  ..., -1.0970e-01,\n",
      "          -6.5284e-02, -2.0646e-01],\n",
      "         [-9.9441e-03, -2.3386e-02, -1.5229e-01,  ...,  3.3338e-01,\n",
      "          -2.7437e-01, -2.8446e-01],\n",
      "         [ 4.2424e-02, -6.3604e-01, -1.5552e-01,  ...,  6.0439e-02,\n",
      "          -2.7906e-01,  2.7110e-01],\n",
      "         [-6.6980e-02, -3.7164e-01,  5.0140e-02,  ..., -5.2169e-02,\n",
      "          -1.5626e-01,  4.6330e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.0394e-01, -6.0014e-02,  3.8622e-01,  ...,  5.6912e-03,\n",
      "           2.8195e-01, -3.0789e-01],\n",
      "         [-1.2092e-01, -5.5535e-01, -2.1203e-01,  ..., -6.4201e-01,\n",
      "          -2.1039e-01,  2.9249e-01],\n",
      "         [ 2.9080e-01,  2.6690e-01, -1.2788e-01,  ...,  1.4517e-01,\n",
      "          -5.5658e-02, -1.8687e-01],\n",
      "         [ 2.6950e-01, -1.0247e-01, -2.7344e-01,  ..., -4.2908e-01,\n",
      "          -4.2843e-02,  9.8706e-02]],\n",
      "\n",
      "        [[ 3.5067e-01, -4.9265e-02, -7.8467e-02,  ..., -9.2631e-03,\n",
      "           1.7159e-01,  2.6601e-01],\n",
      "         [-1.9508e-01, -2.6960e-01, -1.0506e-01,  ...,  2.4177e-01,\n",
      "          -2.9046e-01, -8.9556e-03],\n",
      "         [-1.4775e-01,  2.2558e-01, -2.7014e-01,  ...,  1.7908e-01,\n",
      "           1.2042e-01,  6.4376e-02],\n",
      "         [ 1.5464e-01, -3.7615e-01,  3.9709e-02,  ...,  2.1070e-01,\n",
      "          -8.4915e-02,  6.3587e-02]],\n",
      "\n",
      "        [[-1.9756e-01,  1.7818e-01, -3.5340e-01,  ...,  2.6601e-01,\n",
      "           1.9311e-02, -2.8648e-01],\n",
      "         [ 4.3606e-01,  2.3187e-02, -7.7352e-02,  ..., -5.4826e-01,\n",
      "          -2.3807e-01,  2.2850e-01],\n",
      "         [-2.1941e-01, -4.6339e-03,  4.7747e-01,  ...,  1.3017e-01,\n",
      "          -4.4470e-02,  1.4162e-02],\n",
      "         [ 2.3836e-01, -1.6362e-01,  1.3449e-01,  ...,  2.0333e-01,\n",
      "          -2.9601e-01,  2.2592e-02]]])\n",
      "31 Parameter containing:\n",
      "tensor([ 0.1194, -0.0376,  0.0410, -0.0564, -0.0100, -0.1432, -0.1633,  0.1087,\n",
      "         0.1262, -0.1771, -0.1291, -0.1392,  0.0007,  0.1155,  0.0254,  0.0511,\n",
      "        -0.1136,  0.1592,  0.0115,  0.1108,  0.0021, -0.1721,  0.1175, -0.1145,\n",
      "        -0.0134, -0.1019, -0.0113, -0.1239, -0.1262, -0.1525,  0.0204, -0.1330,\n",
      "         0.1144,  0.1518,  0.1084, -0.1970,  0.0567, -0.0420, -0.1784,  0.1473,\n",
      "         0.0765,  0.1310, -0.1349,  0.0220, -0.1110, -0.0422,  0.0604, -0.0098,\n",
      "         0.0332, -0.1555, -0.0989,  0.0828,  0.0716, -0.1382, -0.0087,  0.0985,\n",
      "         0.0202,  0.1266, -0.1177,  0.1136, -0.0917, -0.0346, -0.1236,  0.0832,\n",
      "        -0.0617, -0.1648,  0.1323,  0.0487, -0.0937, -0.0015, -0.1723, -0.1150,\n",
      "         0.1070, -0.0023, -0.1119, -0.1360, -0.0996, -0.0290,  0.1086,  0.1019,\n",
      "        -0.0030,  0.0101, -0.1968, -0.0073,  0.1548, -0.0789, -0.1720, -0.0656,\n",
      "         0.1056, -0.0969,  0.0235, -0.0276, -0.0197,  0.1501,  0.1442, -0.2089,\n",
      "        -0.0764, -0.0853,  0.0870,  0.0380,  0.1640, -0.0396,  0.1431, -0.1939,\n",
      "        -0.1122, -0.1585,  0.0567, -0.1819, -0.0851, -0.0545,  0.0222, -0.1123,\n",
      "         0.1071,  0.1071,  0.0302,  0.0342, -0.2001, -0.1567, -0.1027,  0.0092,\n",
      "         0.0399, -0.0754,  0.1090,  0.0619,  0.0267,  0.0107, -0.0838,  0.0427])\n",
      "32 Parameter containing:\n",
      "tensor([0.9021, 0.9409, 1.0093, 0.9828, 0.9579, 0.9761, 1.0098, 0.8825, 0.9313,\n",
      "        0.9676, 0.9875, 0.9215, 0.9208, 0.9633, 0.9848, 0.9706, 0.9418, 0.9691,\n",
      "        0.9801, 0.9343, 0.9457, 1.0284, 0.8903, 0.9233, 0.9250, 0.8510, 0.9704,\n",
      "        0.9533, 0.9491, 0.9604, 0.9876, 0.9645, 0.9175, 0.9575, 1.0188, 1.0057,\n",
      "        0.9189, 0.9548, 0.9511, 0.9936, 0.9555, 0.9365, 0.9580, 0.9869, 0.9510,\n",
      "        0.9997, 1.0246, 1.0476, 0.9651, 0.9097, 0.9091, 0.8753, 1.0211, 1.0277,\n",
      "        1.0380, 1.0350, 0.9640, 0.9007, 0.9860, 0.9267, 0.9942, 0.9599, 1.0273,\n",
      "        0.9793, 0.8687, 0.9626, 1.0223, 0.9885, 0.9692, 1.0332, 0.9605, 0.9902,\n",
      "        0.9810, 0.9385, 0.9399, 0.9358, 1.0250, 0.9987, 1.0205, 0.9745, 0.9823,\n",
      "        0.9962, 0.9294, 0.9954, 1.0116, 1.0281, 0.9764, 0.9721, 0.8945, 0.9395,\n",
      "        1.0371, 0.9022, 0.9478, 0.9469, 0.9887, 1.0139, 0.9044, 0.9410, 0.8681,\n",
      "        0.9875, 0.9859, 0.9738, 0.9563, 0.9947, 1.0188, 0.9971, 0.9959, 0.9178,\n",
      "        0.9074, 0.9527, 0.9984, 0.9525, 0.9985, 1.0039, 0.9859, 1.0209, 0.9087,\n",
      "        0.9961, 0.9853, 0.9946, 0.9560, 0.8559, 0.9924, 0.9560, 0.9042, 0.8863,\n",
      "        0.9856, 0.9347])\n",
      "33 Parameter containing:\n",
      "tensor([-0.0517, -0.1005, -0.0581, -0.0566, -0.0626, -0.0562, -0.0619, -0.1314,\n",
      "        -0.0861, -0.0826, -0.0808, -0.1002, -0.1070, -0.0787, -0.0327, -0.0666,\n",
      "        -0.0810, -0.1036, -0.0078, -0.0729, -0.0798, -0.0353, -0.1164, -0.0900,\n",
      "        -0.0711, -0.1708, -0.0387, -0.0756, -0.0586, -0.0800, -0.0431, -0.0773,\n",
      "        -0.0906, -0.0593, -0.0720, -0.0374, -0.0970, -0.0583, -0.0834, -0.0381,\n",
      "        -0.0670, -0.0697, -0.0812, -0.0629, -0.0982, -0.0489, -0.0420, -0.0247,\n",
      "        -0.0754, -0.0889, -0.0999, -0.1256,  0.0042, -0.0258, -0.0399, -0.0312,\n",
      "        -0.0385, -0.1011, -0.0200, -0.0613, -0.0552, -0.0651, -0.0213, -0.0209,\n",
      "        -0.1474, -0.0805, -0.0516, -0.0326, -0.0227, -0.0430, -0.1032, -0.0198,\n",
      "        -0.0543, -0.0575, -0.1120, -0.0738, -0.0307, -0.0629, -0.0245, -0.0474,\n",
      "        -0.0405, -0.1078, -0.0626, -0.0550, -0.0449, -0.0451, -0.0565, -0.0778,\n",
      "        -0.1112, -0.0638, -0.0432, -0.1067, -0.0865, -0.0825, -0.0488,  0.0066,\n",
      "        -0.1071, -0.0709, -0.1150, -0.0364, -0.0489, -0.0496, -0.0504, -0.0890,\n",
      "        -0.0330, -0.0280, -0.0098, -0.0802, -0.1007, -0.0912, -0.0302, -0.0725,\n",
      "        -0.0167, -0.0235, -0.0608, -0.0282, -0.0779, -0.0811, -0.0536, -0.0369,\n",
      "        -0.0516, -0.1306, -0.0529, -0.0709, -0.1276, -0.1004, -0.0433, -0.0808])\n",
      "34 Parameter containing:\n",
      "tensor([[[ 1.3713e-02, -1.8821e-02, -2.4442e-02,  ..., -5.4468e-02,\n",
      "           4.2512e-03, -7.5687e-02],\n",
      "         [-6.3815e-02, -9.2533e-02,  8.8581e-03,  ..., -5.2059e-03,\n",
      "          -1.5370e-02, -2.6285e-02],\n",
      "         [-1.9682e-02,  2.0156e-03, -1.7494e-01,  ..., -4.9713e-03,\n",
      "          -9.6555e-02, -8.8945e-02],\n",
      "         ...,\n",
      "         [ 2.7677e-02, -4.2166e-03, -4.4024e-02,  ...,  3.0469e-02,\n",
      "           8.5019e-02,  4.2725e-02],\n",
      "         [ 5.9374e-02,  5.9985e-03, -4.6781e-02,  ...,  1.1114e-01,\n",
      "          -2.4554e-03, -5.0274e-02],\n",
      "         [ 1.7153e-02,  3.4793e-03,  9.3080e-02,  ...,  2.9881e-02,\n",
      "           2.3285e-02,  2.1934e-02]],\n",
      "\n",
      "        [[ 1.8624e-01, -7.2854e-02,  7.2665e-02,  ..., -2.4616e-02,\n",
      "           1.5990e-02,  2.9961e-02],\n",
      "         [ 6.1020e-02, -1.0825e-02,  1.1246e-02,  ..., -8.7293e-03,\n",
      "          -2.4489e-02, -5.7476e-02],\n",
      "         [ 2.3298e-02, -6.9100e-02,  1.3044e-02,  ..., -1.1723e-02,\n",
      "           5.4923e-03,  3.2091e-02],\n",
      "         ...,\n",
      "         [-6.7791e-02,  5.0628e-02, -6.7847e-02,  ...,  3.7389e-02,\n",
      "          -3.7546e-02, -9.8028e-03],\n",
      "         [-1.8851e-02, -7.9897e-02, -6.9973e-02,  ..., -2.7860e-02,\n",
      "           4.3095e-02, -3.9469e-02],\n",
      "         [ 5.3392e-02,  2.2927e-02, -2.4534e-02,  ..., -2.9677e-03,\n",
      "          -4.0875e-02, -2.6664e-02]],\n",
      "\n",
      "        [[-3.0513e-03, -5.8187e-02, -1.0242e-01,  ..., -8.4374e-02,\n",
      "          -7.5044e-02, -1.8408e-03],\n",
      "         [-1.5287e-02, -2.1693e-02,  1.7503e-02,  ..., -7.9262e-02,\n",
      "          -1.2128e-02,  2.5065e-02],\n",
      "         [-1.7916e-03, -1.7199e-02, -3.4350e-02,  ..., -1.2117e-01,\n",
      "          -1.1514e-02,  1.5604e-02],\n",
      "         ...,\n",
      "         [-7.3453e-02, -4.2834e-02,  6.3949e-02,  ..., -3.3883e-02,\n",
      "          -3.5913e-03, -1.4417e-02],\n",
      "         [-6.6353e-04, -1.0477e-02, -5.4330e-02,  ...,  5.3131e-02,\n",
      "          -2.1782e-02, -3.4269e-03],\n",
      "         [-1.0186e-01,  7.2605e-02, -4.7836e-02,  ...,  4.2298e-02,\n",
      "           7.9376e-02,  1.5820e-02]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.0884e-02,  7.4038e-04, -1.6249e-02,  ..., -7.8623e-02,\n",
      "          -6.0744e-02, -1.3688e-01],\n",
      "         [-1.1959e-01, -5.9568e-02, -3.0651e-02,  ..., -1.9229e-02,\n",
      "           1.4059e-02,  2.7902e-02],\n",
      "         [-3.3024e-02, -4.3339e-02, -4.5539e-02,  ..., -1.6292e-03,\n",
      "          -3.2529e-02, -4.0939e-02],\n",
      "         ...,\n",
      "         [ 6.1435e-02, -4.2518e-02, -7.5489e-03,  ..., -7.1280e-02,\n",
      "          -4.2905e-02, -6.7713e-02],\n",
      "         [ 5.7190e-02, -4.6518e-02,  6.8538e-02,  ...,  1.7406e-02,\n",
      "          -8.9898e-02, -4.7531e-02],\n",
      "         [ 5.7955e-02, -5.9209e-03, -4.5636e-02,  ..., -1.2844e-01,\n",
      "           6.5155e-03, -7.7607e-03]],\n",
      "\n",
      "        [[-9.6708e-02, -3.5012e-02,  4.3892e-03,  ...,  2.0300e-03,\n",
      "          -1.1606e-01,  3.8769e-02],\n",
      "         [-9.7412e-02, -1.6705e-02, -5.6892e-02,  ...,  7.6611e-03,\n",
      "           1.9917e-02, -4.6009e-02],\n",
      "         [ 1.0579e-01,  2.7150e-02,  5.1765e-02,  ..., -3.2453e-02,\n",
      "           3.3254e-02, -3.3309e-02],\n",
      "         ...,\n",
      "         [ 4.1909e-02,  2.5875e-02, -1.4756e-02,  ...,  5.2547e-02,\n",
      "           2.5368e-02, -9.5937e-02],\n",
      "         [-1.2921e-01, -5.4264e-02,  7.3371e-02,  ..., -4.9882e-04,\n",
      "           4.7170e-02, -6.4732e-02],\n",
      "         [ 4.5090e-02,  6.1954e-02,  4.4523e-02,  ...,  3.2559e-02,\n",
      "          -7.4569e-02,  1.4435e-02]],\n",
      "\n",
      "        [[-9.2924e-02, -6.6231e-02, -5.6905e-03,  ...,  7.2452e-02,\n",
      "          -5.7504e-02,  1.7758e-02],\n",
      "         [-6.2255e-02, -2.8855e-03, -2.6354e-02,  ..., -1.9089e-02,\n",
      "          -6.1090e-02,  1.0062e-04],\n",
      "         [-2.1569e-03, -6.7567e-02, -1.1418e-01,  ..., -1.0593e-01,\n",
      "           4.9026e-03, -8.7769e-02],\n",
      "         ...,\n",
      "         [-3.4473e-02, -1.6975e-02,  1.2516e-03,  ...,  3.4681e-02,\n",
      "           1.9279e-02,  4.4779e-02],\n",
      "         [ 5.6294e-02, -6.0745e-02,  2.0352e-02,  ..., -1.0467e-01,\n",
      "           7.5108e-03, -9.7289e-02],\n",
      "         [ 1.3232e-02,  7.0267e-03, -4.7219e-02,  ...,  2.2632e-02,\n",
      "           7.3668e-02, -8.8010e-02]]])\n",
      "35 Parameter containing:\n",
      "tensor([-1.2965e-02,  1.8081e-02, -3.2014e-02, -3.7330e-02, -4.5542e-02,\n",
      "         1.4155e-03, -6.4273e-03, -5.8572e-02,  1.9063e-02, -4.8146e-02,\n",
      "         4.7429e-03, -1.0196e-02,  7.7202e-03, -6.4521e-02, -1.4233e-02,\n",
      "        -3.4375e-02, -1.4493e-02, -3.8742e-02, -8.7725e-03, -4.5042e-02,\n",
      "        -2.8530e-02, -5.5841e-02, -1.7042e-02, -3.8167e-02, -4.7652e-02,\n",
      "         1.4835e-02, -9.4632e-03,  1.1288e-02, -9.2126e-03,  4.1654e-03,\n",
      "        -2.1604e-02, -1.8659e-02, -2.3110e-03, -4.9357e-02, -2.4902e-02,\n",
      "        -3.1421e-02, -3.9793e-02, -2.7527e-03, -6.4495e-03,  1.4524e-02,\n",
      "         1.6646e-03, -4.0509e-03, -6.2150e-03, -4.6958e-02,  1.5787e-02,\n",
      "        -2.8095e-02, -1.3614e-04,  1.1370e-05, -1.0850e-02, -5.2793e-02,\n",
      "        -1.8226e-02, -3.6747e-02, -1.3913e-02, -5.1648e-02, -2.2937e-02,\n",
      "        -4.0634e-02, -2.6032e-02, -9.3078e-03, -1.4712e-02,  7.7682e-03,\n",
      "        -3.4687e-02, -4.8625e-02, -4.5186e-03,  5.2879e-06, -4.5467e-03,\n",
      "        -2.2215e-02, -2.2060e-02, -3.3673e-02, -4.7088e-02,  1.4176e-02,\n",
      "        -2.9272e-02, -5.4595e-02, -4.2554e-02, -9.8758e-03, -3.1753e-02,\n",
      "        -2.2471e-02, -3.0131e-02, -1.3291e-02, -5.4550e-02, -1.6044e-02,\n",
      "        -5.0709e-02, -1.4301e-03, -3.1969e-02, -6.8742e-03, -1.8648e-02,\n",
      "         9.8690e-03, -4.9210e-03, -4.1566e-02, -9.5763e-03, -5.4300e-02,\n",
      "        -3.7905e-02,  2.9805e-03, -1.2441e-02, -3.7393e-02,  1.6376e-03,\n",
      "        -2.9627e-02, -3.3023e-02, -3.9595e-02, -6.4393e-02,  1.3889e-02,\n",
      "         2.1659e-02, -6.2762e-02, -5.6656e-02, -5.5207e-02, -1.6092e-03,\n",
      "        -2.8897e-02, -6.6852e-02, -3.8075e-02, -1.6162e-02, -1.0087e-02,\n",
      "        -3.4926e-02, -3.0380e-03, -3.3926e-02,  8.3426e-04, -4.6438e-03,\n",
      "        -1.1525e-02, -3.2908e-02, -5.9758e-03, -1.9585e-02, -4.6070e-02,\n",
      "        -4.4638e-02, -9.0891e-03, -5.4625e-03, -3.3662e-02, -8.8257e-03,\n",
      "        -4.6533e-02, -1.6706e-02, -4.0107e-02])\n",
      "36 Parameter containing:\n",
      "tensor([[ 0.0486,  0.0936,  0.0093,  ...,  0.0596,  0.0068,  0.0772],\n",
      "        [ 0.0062,  0.0016,  0.0121,  ...,  0.1186,  0.0007,  0.0088],\n",
      "        [ 0.0361, -0.0344, -0.0357,  ...,  0.1245,  0.0415, -0.0282],\n",
      "        ...,\n",
      "        [ 0.0150, -0.0890, -0.0721,  ...,  0.0026,  0.0069, -0.0623],\n",
      "        [ 0.0119, -0.0278, -0.0160,  ..., -0.1034, -0.0227,  0.1247],\n",
      "        [ 0.0256,  0.0382, -0.0299,  ..., -0.0209,  0.0204,  0.0349]])\n",
      "37 Parameter containing:\n",
      "tensor([ 1.8274e-02,  4.0817e-02,  5.4504e-03, -4.5041e-03, -1.0312e-03,\n",
      "         1.7515e-02, -2.6932e-02,  3.6299e-02,  2.2668e-02, -2.6814e-02,\n",
      "         7.4306e-03, -2.1165e-02, -3.9688e-03,  4.1696e-02,  7.8788e-03,\n",
      "         2.2308e-02,  6.0585e-03,  2.4461e-02, -1.7668e-02, -1.2186e-02,\n",
      "         1.4243e-02,  1.5673e-02, -6.4126e-02,  2.4512e-02, -3.9422e-02,\n",
      "         2.5527e-02,  2.6561e-02,  5.2762e-02, -3.2498e-02,  1.6792e-02,\n",
      "        -3.6527e-02,  1.6393e-02,  4.2304e-02,  3.3370e-02, -1.1936e-02,\n",
      "         1.6928e-02, -2.0727e-02, -3.8255e-02, -2.6720e-02, -5.8273e-03,\n",
      "         6.6844e-02,  2.1427e-02,  1.9779e-03,  2.4150e-02, -3.5320e-02,\n",
      "        -1.0773e-02,  2.9133e-02, -4.1249e-02, -8.1135e-03, -6.3517e-03,\n",
      "        -4.8571e-02, -1.3405e-02,  1.8374e-02, -1.1156e-02, -4.1909e-02,\n",
      "         1.1145e-02, -5.8130e-02, -6.0745e-02,  8.7005e-02,  1.5684e-03,\n",
      "        -2.7528e-02,  1.0331e-02,  3.7463e-02,  7.6043e-02, -4.4208e-02,\n",
      "         3.6729e-02, -4.8385e-02,  5.2924e-03, -1.7810e-02, -2.8058e-02,\n",
      "         2.9520e-02, -1.7266e-02, -5.7756e-02, -7.5381e-03,  4.0917e-02,\n",
      "        -7.7847e-02,  1.3465e-02, -5.9114e-02,  2.5772e-04, -3.9144e-02,\n",
      "        -5.5287e-03, -2.1092e-02,  4.8976e-02, -2.4056e-02, -1.3270e-04,\n",
      "        -8.2085e-03,  4.7573e-02, -5.1833e-02,  4.5576e-02, -3.7775e-03,\n",
      "         2.1070e-02,  1.1149e-01, -1.0287e-02,  7.7134e-04,  1.9128e-02,\n",
      "         5.2172e-03,  5.7784e-02,  2.0543e-02, -9.5097e-03, -2.4408e-02,\n",
      "        -2.6609e-02,  1.2888e-01,  5.2616e-02, -6.7298e-02, -4.5433e-02,\n",
      "         1.6229e-02,  3.9685e-02,  4.2381e-02,  5.6771e-02, -1.0619e-02,\n",
      "        -7.6205e-03, -1.2313e-02,  4.3385e-02,  3.7025e-03,  3.3301e-02,\n",
      "        -2.3576e-03, -4.8657e-02, -4.4709e-02,  4.7701e-02,  4.6823e-02,\n",
      "         2.0862e-02, -4.9123e-02, -1.0092e-02,  3.4277e-02,  8.5982e-03,\n",
      "        -1.8407e-02,  2.3281e-02,  1.6855e-02, -8.3620e-03,  2.2189e-03,\n",
      "        -1.7377e-03,  1.1421e-02,  6.0952e-03, -2.8191e-03, -1.2342e-02,\n",
      "        -7.6782e-03, -6.5972e-03,  4.9697e-03,  1.5578e-02, -1.8277e-02,\n",
      "        -3.4935e-03,  4.4074e-03,  1.2058e-02,  4.2629e-03,  4.3198e-03,\n",
      "         1.3985e-03,  9.5677e-03,  2.2944e-04, -2.4337e-02, -1.0190e-02,\n",
      "        -1.2407e-02, -1.2457e-03,  1.7580e-02,  3.2752e-03, -6.3014e-03,\n",
      "        -9.0913e-03, -2.5605e-02,  1.4269e-03,  2.1916e-02,  2.2366e-02,\n",
      "         1.9221e-02,  1.1170e-03,  9.0773e-03,  5.9511e-03, -5.4611e-03,\n",
      "         2.5473e-03,  1.1788e-02, -2.4040e-02, -6.3625e-03,  9.9312e-04,\n",
      "         7.7384e-03,  1.5543e-02, -1.9763e-02, -1.3484e-03, -1.2793e-02,\n",
      "        -1.1188e-03, -9.8147e-03, -6.3238e-03,  1.2978e-02, -1.2972e-02,\n",
      "         3.0752e-03, -9.6164e-03,  9.3908e-03, -4.8143e-03, -1.3433e-02,\n",
      "         1.9467e-02,  1.3944e-02,  6.6492e-03, -8.3754e-03, -2.9471e-03,\n",
      "        -2.2135e-02,  5.6777e-03,  6.3151e-03,  2.7566e-03, -1.3233e-02,\n",
      "         8.3908e-03, -2.0384e-03, -3.1632e-03, -7.5310e-03, -1.0378e-02,\n",
      "        -2.1192e-02, -8.0043e-03,  1.0494e-02, -2.0175e-03, -2.8690e-03,\n",
      "         2.7842e-03,  1.2495e-02,  1.7919e-02, -1.1094e-02, -2.2214e-03,\n",
      "         2.0302e-02,  4.8763e-03,  2.3676e-03,  1.3270e-02,  1.8895e-02,\n",
      "        -1.2535e-02,  1.2727e-02,  4.4670e-03, -1.7360e-03, -2.2654e-03,\n",
      "        -2.3382e-03,  1.2239e-02, -5.2770e-03,  7.1446e-04,  7.6409e-03,\n",
      "         3.8403e-03, -8.5559e-03, -1.3466e-02, -5.3747e-04, -1.0793e-03,\n",
      "         9.6003e-03, -2.0360e-04,  2.5461e-02,  6.0157e-03, -3.1774e-03,\n",
      "        -1.9264e-03, -3.3469e-03, -3.2221e-03, -5.3849e-03, -1.3171e-02,\n",
      "        -1.3538e-02, -9.3536e-03, -8.6892e-03, -1.2279e-02,  7.5221e-03,\n",
      "        -4.4991e-03, -9.5893e-03, -3.9622e-03, -6.7173e-03, -4.9756e-03,\n",
      "         1.2904e-02, -6.7920e-03, -1.8762e-02,  1.2414e-02,  5.3853e-03,\n",
      "        -1.3380e-03,  2.4085e-02,  1.4916e-02, -2.0633e-02,  1.3129e-02,\n",
      "         4.1065e-02,  1.5720e-02,  1.3387e-02,  5.1601e-02, -7.8067e-03,\n",
      "         4.1630e-03, -2.1804e-02,  4.0979e-03, -4.2383e-02, -1.4652e-02,\n",
      "         2.8140e-03, -3.1625e-02, -2.2016e-02,  1.3046e-02, -7.1860e-03,\n",
      "         2.3445e-03, -2.6487e-02,  2.6563e-02,  2.8473e-02,  1.6065e-02,\n",
      "         5.2237e-03,  1.2420e-03,  3.3228e-02, -1.1520e-03,  3.1040e-02,\n",
      "        -9.1296e-03,  6.5532e-03, -3.2491e-02, -2.7847e-02, -1.9174e-02,\n",
      "         3.7424e-03,  1.2493e-02, -1.3352e-02,  2.3252e-02,  4.2423e-02,\n",
      "         1.9180e-02,  2.2800e-03,  2.6837e-02,  1.4072e-02,  1.3403e-03,\n",
      "        -6.3217e-03, -9.8147e-03, -9.3444e-03, -4.3904e-03,  2.3283e-02,\n",
      "        -2.5836e-02,  1.5431e-02, -2.3945e-02,  5.9100e-02,  4.6169e-02,\n",
      "         2.1375e-02, -2.5417e-03, -1.5555e-02, -2.0087e-02,  2.9016e-02,\n",
      "        -1.8049e-02, -5.6939e-03, -2.2844e-02, -1.5507e-02, -2.4995e-02,\n",
      "         8.1557e-03,  2.2756e-03, -3.3546e-02,  7.9499e-03, -2.8398e-02,\n",
      "        -3.1018e-02, -1.5273e-03,  1.3073e-02,  8.3280e-03,  2.8476e-03,\n",
      "        -9.1205e-03,  4.9296e-02,  4.0417e-02, -1.2248e-03, -1.2568e-02,\n",
      "        -2.2101e-02, -1.3479e-02,  3.2288e-02,  3.7707e-04, -2.4247e-02,\n",
      "        -1.8580e-02, -3.4348e-02,  2.1846e-02, -2.8151e-02, -1.4315e-03,\n",
      "        -4.0403e-02,  2.5723e-02,  1.0127e-04, -3.5379e-02, -2.7275e-02,\n",
      "         7.1444e-03,  4.1326e-02, -2.6994e-02, -3.0569e-03, -1.0495e-02,\n",
      "         3.8165e-03,  1.5170e-02,  2.3357e-02, -4.7760e-03,  1.5698e-02,\n",
      "        -1.9087e-02,  2.0078e-02, -2.2185e-02, -2.7203e-02, -1.4834e-02,\n",
      "         2.0641e-02,  1.9273e-02,  2.4215e-02,  1.7138e-02, -2.3620e-02,\n",
      "        -6.4204e-03,  6.7188e-04,  8.3938e-03, -1.2036e-02,  3.3198e-03,\n",
      "        -2.2090e-02,  4.4326e-02, -1.5404e-02,  2.6408e-02, -2.6771e-02,\n",
      "         1.7848e-02, -1.1916e-02,  3.0933e-03,  1.3172e-02])\n",
      "38 Parameter containing:\n",
      "tensor([[-0.0383,  0.1643, -0.0458,  ...,  0.1342, -0.0695,  0.0742],\n",
      "        [-0.0350,  0.0331,  0.0981,  ..., -0.0949, -0.0568, -0.0339],\n",
      "        [-0.0232, -0.1478,  0.0049,  ...,  0.0353,  0.0858,  0.1521],\n",
      "        ...,\n",
      "        [ 0.0915,  0.2163, -0.0465,  ...,  0.0287,  0.0481,  0.1540],\n",
      "        [ 0.0718,  0.0158,  0.0837,  ..., -0.0163,  0.0349,  0.1143],\n",
      "        [ 0.0178, -0.0115,  0.0963,  ..., -0.0381,  0.0300, -0.0443]])\n",
      "39 Parameter containing:\n",
      "tensor([-0.0287,  0.0522,  0.0543,  0.0176, -0.0274, -0.0503, -0.0367, -0.0109,\n",
      "         0.0753,  0.0393, -0.0148, -0.0518,  0.0111, -0.0132, -0.0137, -0.0223,\n",
      "        -0.0178, -0.0062,  0.0106,  0.0714, -0.0083, -0.0239, -0.0426, -0.0309,\n",
      "        -0.0094, -0.0610, -0.0158,  0.0115,  0.0782, -0.0353, -0.0265, -0.0085,\n",
      "         0.0211, -0.0322, -0.0281, -0.0656,  0.0125,  0.0102,  0.0505,  0.0520,\n",
      "         0.0017,  0.0266,  0.0683,  0.0450, -0.0360, -0.0477,  0.0589, -0.0241,\n",
      "         0.0028, -0.0055, -0.0382, -0.0307, -0.0055, -0.0197,  0.0280,  0.0222,\n",
      "        -0.0012,  0.1089,  0.0141,  0.0264,  0.0317, -0.0060,  0.0134,  0.0513,\n",
      "         0.0333, -0.0284,  0.0072,  0.0340,  0.0093,  0.0772, -0.0354, -0.0293,\n",
      "        -0.0157,  0.0187,  0.0178, -0.0227,  0.0014,  0.0615, -0.0058,  0.0208,\n",
      "        -0.0124,  0.0342, -0.0498, -0.0120, -0.0271,  0.0310,  0.0627,  0.0249,\n",
      "         0.0157, -0.0126, -0.0114,  0.0343, -0.0672, -0.0074,  0.0069,  0.0052,\n",
      "        -0.0365, -0.0255, -0.0350,  0.0021,  0.0105,  0.0020,  0.0095, -0.0266,\n",
      "        -0.0313,  0.0239,  0.0021, -0.0166,  0.0095,  0.0510,  0.0212,  0.0510,\n",
      "        -0.0094, -0.0115, -0.0511,  0.0829,  0.0345, -0.0470, -0.0020,  0.0087,\n",
      "        -0.0192,  0.0053, -0.0469, -0.0107,  0.0099,  0.0098, -0.0019, -0.0143])\n",
      "40 Parameter containing:\n",
      "tensor([[ 0.0210, -0.0998,  0.1197,  ..., -0.1861,  0.0625, -0.0844],\n",
      "        [ 0.0980, -0.0115, -0.1206,  ..., -0.1575,  0.0234, -0.0131],\n",
      "        [-0.0139, -0.1211,  0.0769,  ...,  0.0609, -0.1343, -0.0531],\n",
      "        ...,\n",
      "        [ 0.1551, -0.0595,  0.0114,  ..., -0.0026,  0.0756, -0.0138],\n",
      "        [ 0.0043, -0.0321,  0.0325,  ..., -0.1007,  0.0884, -0.1635],\n",
      "        [ 0.0630, -0.0169, -0.0069,  ..., -0.0029, -0.1085,  0.1263]])\n",
      "41 Parameter containing:\n",
      "tensor([-0.0245, -0.0352, -0.1291, -0.1641, -0.0661, -0.0855, -0.1097, -0.0841,\n",
      "        -0.1559, -0.0338, -0.0389, -0.1583, -0.1144, -0.0984, -0.1377, -0.0419,\n",
      "        -0.0643, -0.1755, -0.0753, -0.0961, -0.0651, -0.0176, -0.1636, -0.1161,\n",
      "        -0.1343, -0.1565, -0.0346, -0.0596, -0.0972, -0.1584, -0.1458, -0.0815,\n",
      "        -0.1465, -0.0997, -0.1270, -0.1981, -0.1683, -0.1838, -0.0769, -0.1251,\n",
      "        -0.0140, -0.0967, -0.1381, -0.1070, -0.1202, -0.0514, -0.0577, -0.1649,\n",
      "        -0.0858, -0.1276,  0.0097, -0.1498, -0.1455, -0.1942, -0.0609, -0.1225,\n",
      "        -0.1224, -0.0660, -0.2015, -0.0820, -0.1214, -0.0788, -0.1490, -0.1250,\n",
      "        -0.1081, -0.0516, -0.1483, -0.1017, -0.1714,  0.0249, -0.1000, -0.1844,\n",
      "        -0.1638, -0.1737, -0.1177, -0.0118, -0.1395, -0.0397,  0.0164, -0.1720,\n",
      "        -0.0746, -0.0899, -0.1053, -0.1297, -0.1474, -0.0351, -0.0140, -0.0996,\n",
      "        -0.0724, -0.1225, -0.1336, -0.2138, -0.0654, -0.1418, -0.1231, -0.0891,\n",
      "        -0.0237, -0.1265, -0.1306, -0.1463, -0.0959, -0.1069, -0.1626, -0.0980,\n",
      "        -0.1806, -0.1917, -0.0402, -0.0582, -0.1895, -0.0112, -0.0360, -0.0881,\n",
      "        -0.1036, -0.0671, -0.0545, -0.1143, -0.1431, -0.0659, -0.1336, -0.1194,\n",
      "        -0.1232, -0.0406,  0.0092, -0.1011,  0.0286, -0.0329, -0.0577, -0.1748,\n",
      "        -0.1702, -0.1776, -0.1168, -0.1196, -0.1022, -0.2035, -0.1481, -0.1510,\n",
      "        -0.1191, -0.1158, -0.0270, -0.1320, -0.1906, -0.1152, -0.0115, -0.0192,\n",
      "        -0.0050, -0.1410, -0.0556, -0.0296, -0.1032, -0.1239, -0.1453, -0.1200,\n",
      "        -0.1064, -0.0188, -0.0923, -0.0531, -0.0818,  0.0117, -0.1476, -0.0327,\n",
      "        -0.1410, -0.1285, -0.0617, -0.0464, -0.1120, -0.0793, -0.0746, -0.0544,\n",
      "        -0.1481, -0.1002, -0.0640, -0.0475, -0.1674, -0.1279, -0.0761, -0.0284,\n",
      "        -0.0466, -0.0462, -0.0938, -0.0679, -0.1464, -0.0914, -0.0572, -0.1073,\n",
      "        -0.0870, -0.1446, -0.0878, -0.1288, -0.1849, -0.0708, -0.0349, -0.0183,\n",
      "        -0.0447, -0.0032, -0.2225, -0.1256, -0.0870, -0.0974, -0.0149, -0.1641,\n",
      "        -0.1031, -0.1967, -0.0600, -0.0485,  0.0140, -0.1596, -0.2061, -0.0684,\n",
      "        -0.1824, -0.1728, -0.1870, -0.1322, -0.1584, -0.0110, -0.1025, -0.0152,\n",
      "        -0.0852, -0.0504, -0.1581, -0.0495, -0.0500, -0.1236, -0.1121,  0.0396,\n",
      "        -0.0276, -0.1511, -0.0911, -0.2037, -0.0703, -0.1108, -0.1323, -0.1388,\n",
      "        -0.0597, -0.0772, -0.1441, -0.1122, -0.0595, -0.1102, -0.0493, -0.1270,\n",
      "        -0.0707, -0.0828, -0.0574, -0.1175, -0.0911,  0.0005, -0.0733,  0.0026,\n",
      "        -0.1590, -0.0445, -0.0282, -0.0535, -0.0570, -0.1058, -0.1664, -0.1562])\n",
      "42 Parameter containing:\n",
      "tensor([[-0.0954, -0.1311,  0.0920,  ...,  0.0889,  0.0221,  0.0865],\n",
      "        [-0.0283, -0.0152, -0.1037,  ..., -0.0299, -0.0098, -0.0037],\n",
      "        [-0.0892, -0.1637, -0.0456,  ..., -0.0517, -0.0308,  0.0180],\n",
      "        ...,\n",
      "        [-0.0748, -0.0385,  0.0527,  ..., -0.1043,  0.1414, -0.0688],\n",
      "        [ 0.0020,  0.0026,  0.0963,  ..., -0.0515,  0.0417, -0.0803],\n",
      "        [-0.0115,  0.0738, -0.0612,  ..., -0.0313, -0.0892, -0.0782]])\n",
      "43 Parameter containing:\n",
      "tensor([ 0.0051,  0.0659,  0.0035, -0.0844,  0.0162,  0.0133,  0.0951,  0.0335,\n",
      "         0.2595, -0.0881,  0.0254,  0.0201, -0.0527, -0.0052, -0.0009,  0.0430,\n",
      "         0.0314, -0.0351,  0.0250, -0.0557,  0.0153,  0.0385,  0.0528, -0.0043,\n",
      "        -0.0532,  0.0081,  0.0124, -0.0101, -0.0464, -0.0025, -0.0448, -0.0108,\n",
      "        -0.0022, -0.0103,  0.0669,  0.1021, -0.0097,  0.0599,  0.0368, -0.0397,\n",
      "         0.0288, -0.0363, -0.0977, -0.0547,  0.0354, -0.0020,  0.0085, -0.0266,\n",
      "        -0.0013,  0.0245, -0.0124,  0.0733, -0.0583, -0.0324,  0.0466,  0.0233,\n",
      "        -0.0516, -0.0722,  0.0057, -0.0668,  0.0405,  0.0143, -0.0092, -0.0042,\n",
      "         0.0089,  0.0707,  0.0087, -0.0007, -0.0827, -0.0831,  0.0132, -0.0471,\n",
      "         0.0104,  0.0312, -0.0096,  0.0165,  0.0505, -0.0100,  0.0588,  0.0416,\n",
      "        -0.0170, -0.0491,  0.0803, -0.0134,  0.0565, -0.0301, -0.0845, -0.0082,\n",
      "         0.0126, -0.0168,  0.0084,  0.0478,  0.0125, -0.0065, -0.0983,  0.0423,\n",
      "         0.3579,  0.0118,  0.0172,  0.0314,  0.0400, -0.0336, -0.0051,  0.0168,\n",
      "         0.0151, -0.0130,  0.0007, -0.0219,  0.0299, -0.0692, -0.1045, -0.0439,\n",
      "        -0.0191,  0.0138, -0.0331, -0.0361,  0.0388,  0.0140, -0.0662, -0.0163,\n",
      "        -0.0109,  0.0315,  0.0205, -0.0027, -0.0447, -0.0127,  0.0749,  0.0327])\n",
      "44 Parameter containing:\n",
      "tensor([0.8075, 0.8177, 0.7312, 0.7648, 0.8247, 0.8161, 0.7849, 0.8127, 0.8193,\n",
      "        0.8053, 0.7381, 0.8733, 0.7712, 0.8367, 0.8362, 0.8445, 0.7560, 0.7885,\n",
      "        0.8362, 0.7758, 0.7946, 0.8198, 0.7862, 0.8094, 0.8044, 0.7281, 0.7737,\n",
      "        0.8165, 0.7588, 0.8846, 0.8549, 0.9083, 0.8847, 0.8586, 0.8175, 0.8706,\n",
      "        0.8245, 0.8090, 0.7883, 0.8005, 0.8239, 0.8506, 0.8371, 0.8060, 0.8355,\n",
      "        0.9069, 0.8917, 0.7742, 0.8188, 0.8217, 0.8749, 0.8208, 0.8754, 0.8098,\n",
      "        0.7923, 0.8810, 0.9112, 0.8426, 0.8802, 0.8739, 0.9009, 0.8787, 0.9527,\n",
      "        0.8577, 0.9773, 0.9069, 0.9640, 0.8821, 0.9060, 0.9527, 1.0017, 0.9301,\n",
      "        0.9297, 0.9862, 0.9157, 0.9498, 0.9898, 0.9960, 1.0333, 0.9285, 0.9880,\n",
      "        0.9946, 0.9550, 0.9655, 0.9701, 1.0517, 0.9789, 1.0344, 0.9751, 1.0258,\n",
      "        1.0946, 1.0360, 0.9947, 0.9996, 0.9858, 1.0020, 0.9393, 1.0152, 1.0407,\n",
      "        0.9909, 0.9832, 1.0298, 1.0250, 1.0449, 1.0268, 1.0528, 0.9703, 0.9885,\n",
      "        0.9904, 0.9958, 0.8927, 0.9942, 1.0331, 1.0255, 1.0203, 1.0209, 0.9520,\n",
      "        0.9732, 1.0307, 0.9771, 1.0636, 1.0163, 1.0354, 0.9601, 1.0327, 0.9897,\n",
      "        1.0519, 0.9841])\n",
      "45 Parameter containing:\n",
      "tensor([-0.0828,  0.1111,  0.1473,  0.0697, -0.0730, -0.0565, -0.0766, -0.0175,\n",
      "         0.0904,  0.0871,  0.0466, -0.1111,  0.0636, -0.0629, -0.0360, -0.0554,\n",
      "        -0.0204,  0.0293,  0.0252,  0.1576,  0.0188, -0.0847, -0.1097, -0.0472,\n",
      "        -0.0152, -0.0792, -0.0344, -0.0094,  0.1674, -0.0743, -0.0447,  0.0687,\n",
      "         0.0309, -0.0129, -0.0469, -0.2130,  0.0482, -0.0128, -0.0025,  0.1283,\n",
      "        -0.0074,  0.0589,  0.2215,  0.1885, -0.1380, -0.1128,  0.0970, -0.0068,\n",
      "        -0.0678,  0.0205, -0.0742, -0.0735, -0.0474,  0.0512,  0.0077,  0.0511,\n",
      "         0.0052,  0.2176,  0.0167,  0.0804,  0.0657, -0.0101,  0.0884,  0.1141,\n",
      "         0.0685, -0.1110,  0.0800,  0.0711,  0.0688,  0.1454, -0.0260, -0.0295,\n",
      "         0.0291,  0.0446,  0.0681, -0.0624,  0.0059,  0.1443, -0.0202, -0.0525,\n",
      "        -0.0934,  0.1033, -0.1244, -0.0217, -0.0522,  0.1071,  0.1437,  0.0615,\n",
      "        -0.0091, -0.0175,  0.0050,  0.0776, -0.0877,  0.0106,  0.0340, -0.0232,\n",
      "        -0.1723, -0.0432, -0.0611,  0.0248, -0.0155,  0.0016, -0.0163, -0.0609,\n",
      "        -0.0745,  0.0307,  0.0146,  0.0341,  0.0195,  0.1218,  0.0787,  0.0221,\n",
      "        -0.0204, -0.0276,  0.0317,  0.1873,  0.0788, -0.0128,  0.0406,  0.0128,\n",
      "        -0.0470,  0.0111, -0.1549,  0.0172,  0.0779,  0.1291, -0.0922,  0.0051])\n",
      "46 Parameter containing:\n",
      "tensor([0.7713, 0.7049, 0.7050, 0.6862, 0.8809, 0.7489, 0.6296, 0.8337, 0.0932,\n",
      "        0.7287, 0.6598, 0.9767, 0.7174, 0.7299, 0.8841, 0.8878, 0.7916, 0.7655,\n",
      "        0.8700, 0.5782, 0.8438, 0.7670, 0.7025, 0.8439, 0.7938, 0.7782, 0.7873,\n",
      "        0.7831, 0.6102, 0.9038, 0.7063, 0.5915, 0.8740, 0.9842, 0.7041, 0.7408,\n",
      "        0.8022, 0.7099, 0.7324, 0.7715, 0.6588, 0.8500, 0.7568, 0.7285, 0.6790,\n",
      "        0.9042, 0.8525, 0.7696, 0.6815, 0.8681, 0.6568, 0.8602, 0.7173, 0.6545,\n",
      "        0.5716, 0.8773, 0.9471, 0.7641, 0.9043, 0.7949, 0.7332, 0.5904, 0.8683,\n",
      "        0.6419, 0.9307, 0.8709, 0.9152, 0.5172, 0.8126, 0.7940, 0.8864, 0.7441,\n",
      "        0.8912, 0.9302, 0.8916, 0.7608, 0.9797, 0.8329, 1.0985, 0.5178, 0.9026,\n",
      "        1.0123, 0.8754, 0.9616, 0.8811, 0.8713, 0.7754, 1.0618, 0.8709, 0.9135,\n",
      "        1.0579, 0.9140, 0.8649, 0.9497, 0.9365, 0.8492, 0.0537, 0.8972, 0.8181,\n",
      "        0.8268, 0.6931, 1.1114, 1.0135, 1.0357, 0.9568, 0.8861, 0.8762, 0.9592,\n",
      "        0.9344, 0.8238, 0.7338, 0.9349, 0.9905, 0.9429, 0.8919, 0.9195, 0.8347,\n",
      "        0.7834, 0.8512, 0.9160, 1.0529, 0.8771, 1.0027, 0.8782, 0.9912, 0.9009,\n",
      "        0.8944, 0.9637])\n",
      "47 Parameter containing:\n",
      "tensor([ 4.8278e-02, -5.4997e-02, -8.2647e-02, -4.2411e-02,  6.4297e-02,\n",
      "         4.4189e-02, -3.7453e-02,  3.0387e-02, -4.5758e-01,  2.2788e-02,\n",
      "         6.8777e-02,  7.2974e-02,  3.4493e-03,  1.2342e-01, -1.2462e-02,\n",
      "         7.9901e-02,  3.2921e-02,  3.5722e-02,  4.1263e-02,  9.8773e-03,\n",
      "         5.7176e-02,  5.4494e-03,  3.0899e-02,  2.9190e-02,  9.4877e-02,\n",
      "         2.7485e-02,  5.4078e-02, -1.7823e-02,  4.5884e-02,  8.4716e-02,\n",
      "         5.3281e-03,  7.6934e-02,  3.0161e-02,  2.7659e-02,  1.4393e-01,\n",
      "         1.3444e-01, -6.9674e-03, -9.5915e-02, -6.3680e-02, -5.8392e-02,\n",
      "         3.7554e-02, -4.2488e-02, -1.4418e-01, -2.1546e-02,  5.7774e-02,\n",
      "         5.8439e-02, -8.2538e-02,  6.2361e-02,  9.1984e-02,  2.8885e-03,\n",
      "         3.2804e-03,  7.6874e-02,  1.4862e-04, -9.6032e-02, -9.5234e-02,\n",
      "         2.2751e-02,  5.3792e-02, -8.3776e-02, -2.5693e-03,  1.9202e-03,\n",
      "        -4.4447e-02, -8.4111e-02, -1.5248e-02, -1.5706e-01, -7.0519e-02,\n",
      "         5.5627e-02,  4.8734e-03,  1.6895e-01, -1.0591e-02, -9.3110e-02,\n",
      "         1.0275e-01,  8.2102e-02,  5.5319e-02, -3.9653e-02, -4.1079e-02,\n",
      "         9.3964e-02,  6.4699e-03, -5.1076e-02,  1.5969e-02, -1.6283e-01,\n",
      "         7.4302e-02, -5.4370e-02,  7.0734e-02,  3.6339e-02,  1.0327e-03,\n",
      "        -6.7792e-02, -4.8773e-02,  1.0733e-02,  1.0478e-02, -1.2196e-02,\n",
      "         2.7883e-02, -6.2564e-02,  5.3396e-02,  5.0107e-03, -2.6952e-02,\n",
      "        -2.5013e-02, -2.9119e-01, -1.9887e-02,  6.4833e-02, -4.9622e-03,\n",
      "         1.7432e-02, -1.0815e-02,  6.2607e-02,  3.1899e-02,  9.9629e-02,\n",
      "        -7.0126e-02, -7.5892e-03,  1.8889e-02,  1.2465e-02, -2.5152e-02,\n",
      "        -3.5176e-03,  2.9130e-03,  1.7585e-02,  9.8852e-03,  6.6837e-03,\n",
      "        -1.3968e-01, -6.1894e-03,  4.5205e-02,  8.3782e-03, -3.8087e-03,\n",
      "         1.9211e-02,  2.8191e-02,  1.0135e-01,  4.0888e-02, -4.4699e-02,\n",
      "        -6.3545e-02,  3.9409e-02, -1.3397e-02])\n",
      "48 Parameter containing:\n",
      "tensor([[-0.0407,  0.0207,  0.0165,  ..., -0.0005, -0.0193,  0.0111],\n",
      "        [ 0.0125, -0.0141,  0.0486,  ..., -0.0147,  0.0345,  0.0171],\n",
      "        [-0.0285,  0.0255,  0.0258,  ...,  0.0138, -0.0011,  0.0082],\n",
      "        ...,\n",
      "        [ 0.0258,  0.0133,  0.0226,  ...,  0.0182,  0.0285, -0.0004],\n",
      "        [-0.0057,  0.0008,  0.0641,  ...,  0.0095, -0.0329,  0.0012],\n",
      "        [ 0.0206, -0.0356, -0.0262,  ..., -0.0297, -0.0163,  0.0094]],\n",
      "       requires_grad=True)\n",
      "49 Parameter containing:\n",
      "tensor([ 1.3547e-06, -1.0119e-02, -4.2426e-03,  ..., -3.4353e-02,\n",
      "        -1.6000e-02, -1.6972e-02], requires_grad=True)\n",
      "50 Parameter containing:\n",
      "tensor([[ 0.0586, -0.0421, -0.0464,  ..., -0.0089, -0.0749,  0.0065],\n",
      "        [-0.0322, -0.0293, -0.0017,  ..., -0.0485,  0.1043,  0.1069],\n",
      "        [ 0.0184,  0.0022, -0.0396,  ..., -0.0407, -0.0407, -0.0453],\n",
      "        ...,\n",
      "        [-0.0181, -0.0133, -0.0141,  ..., -0.0248, -0.0618,  0.0120],\n",
      "        [ 0.0409,  0.0084, -0.0535,  ..., -0.0606, -0.0570,  0.0249],\n",
      "        [ 0.0120,  0.0582,  0.0440,  ...,  0.0023, -0.0452, -0.0443]])\n",
      "51 Parameter containing:\n",
      "tensor([-0.0067,  0.0163, -0.0056,  ...,  0.0149, -0.0244,  0.0243])\n",
      "52 Parameter containing:\n",
      "tensor([[ 0.0663, -0.0420,  0.0038,  ..., -0.0383, -0.0166, -0.0159],\n",
      "        [ 0.0232, -0.0386,  0.0470,  ..., -0.0364, -0.0313,  0.0629],\n",
      "        [ 0.0136, -0.0415, -0.0031,  ..., -0.0423, -0.0273, -0.0087],\n",
      "        ...,\n",
      "        [ 0.0424,  0.0434, -0.0476,  ...,  0.0581,  0.0006,  0.0253],\n",
      "        [-0.0768, -0.0354,  0.0297,  ..., -0.0541, -0.0099, -0.0688],\n",
      "        [-0.0103, -0.0049, -0.0117,  ..., -0.0047, -0.0020, -0.0124]])\n",
      "53 Parameter containing:\n",
      "tensor([ 0.0329,  0.0231,  0.0297,  ..., -0.0029,  0.0231,  0.0021])\n",
      "54 Parameter containing:\n",
      "tensor([[ 0.0171, -0.0138, -0.0802,  ..., -0.0718, -0.0331,  0.0345],\n",
      "        [ 0.0799,  0.0788, -0.0256,  ..., -0.0692, -0.0224,  0.0949],\n",
      "        [ 0.0138,  0.0136,  0.0072,  ..., -0.0040, -0.0068,  0.0005],\n",
      "        ...,\n",
      "        [-0.0021,  0.0118, -0.0121,  ...,  0.0144,  0.0185, -0.0142],\n",
      "        [-0.0064, -0.0175, -0.0474,  ..., -0.0421, -0.0201, -0.0278],\n",
      "        [ 0.0163,  0.0366,  0.0094,  ...,  0.0219,  0.0195, -0.0062]])\n",
      "55 Parameter containing:\n",
      "tensor([-1.9720e-02,  2.8465e-02, -9.4338e-03, -2.7902e-02,  1.6120e-02,\n",
      "         5.3285e-03,  2.8228e-02, -1.5558e-02,  2.3215e-02, -8.8715e-03,\n",
      "        -2.6066e-02, -2.0039e-02, -2.5590e-02, -3.1520e-03,  2.4487e-02,\n",
      "         1.2831e-02, -3.6604e-03,  2.7202e-02,  2.1736e-02, -2.5182e-02,\n",
      "        -6.1068e-03,  1.1059e-02,  2.4595e-02,  6.5746e-03, -1.0878e-02,\n",
      "        -1.6729e-02,  2.1967e-02,  7.9203e-03, -1.9782e-02, -2.1079e-02,\n",
      "         1.8596e-02,  7.0124e-03,  4.1609e-03,  2.4655e-02, -2.3968e-02,\n",
      "        -2.5339e-02, -2.8154e-02,  4.6229e-03,  9.8492e-03,  2.9984e-02,\n",
      "         2.7974e-02, -1.6277e-02, -8.0944e-03,  1.8618e-02,  1.5284e-02,\n",
      "         1.3826e-02,  1.8186e-02,  2.7283e-02, -2.7174e-02,  5.9530e-03,\n",
      "        -1.1087e-02, -3.0480e-02, -1.0188e-02, -2.4077e-02, -1.1938e-03,\n",
      "         1.8270e-02,  1.3248e-02, -1.2326e-02, -2.4826e-02,  1.8759e-02,\n",
      "        -1.9254e-02,  3.8875e-03,  8.3767e-03, -1.2985e-02,  2.3070e-02,\n",
      "         9.3301e-03, -7.9086e-04,  1.1310e-02, -3.2523e-03,  2.4811e-02,\n",
      "         2.5821e-02,  1.1118e-02,  2.6091e-02,  2.1692e-02,  1.6547e-03,\n",
      "         2.1504e-03, -1.8467e-02, -2.6083e-02, -7.5690e-03, -3.6196e-03,\n",
      "         9.7684e-03, -7.6456e-03, -2.9970e-02, -1.8224e-02,  2.6474e-02,\n",
      "        -2.7414e-02,  6.5588e-03, -1.4388e-02,  4.0615e-03, -2.8890e-02,\n",
      "        -1.4509e-02,  7.7665e-03,  1.6176e-02, -1.2530e-02,  1.8855e-02,\n",
      "        -2.0024e-02, -2.0976e-02,  2.0987e-02,  2.5705e-02,  2.1310e-02,\n",
      "        -2.0925e-02,  2.3319e-02, -4.3326e-03,  1.4175e-02,  2.1760e-02,\n",
      "        -1.2466e-02, -2.2135e-02,  2.4488e-02, -3.0321e-02, -2.1127e-02,\n",
      "         2.7911e-03,  2.2203e-02, -9.9907e-03, -7.8486e-03, -3.6772e-03,\n",
      "         2.8668e-02,  1.9369e-02,  1.9921e-02, -2.8564e-03, -3.2605e-03,\n",
      "        -1.7137e-02,  3.0291e-02, -2.3410e-02,  2.8154e-02, -3.1674e-03,\n",
      "         8.7961e-04,  2.0643e-02, -2.7090e-02,  4.7018e-03, -1.3028e-02,\n",
      "         1.1192e-02, -3.9907e-03, -3.0698e-02, -1.9268e-02,  1.8892e-02,\n",
      "         1.2138e-02, -1.7251e-02,  1.6525e-02,  1.3806e-02, -7.3198e-03,\n",
      "         8.8979e-05,  2.2588e-02, -2.6419e-02, -1.1714e-02, -6.0689e-04,\n",
      "         1.8154e-02, -1.7234e-02,  2.6736e-02, -2.7671e-03, -2.0420e-02,\n",
      "         8.6739e-03, -4.7271e-03, -2.8624e-03,  7.5283e-03,  2.5124e-02,\n",
      "        -5.2106e-03,  2.5471e-02,  2.9273e-02, -1.6800e-02, -1.2566e-02,\n",
      "         7.8271e-03,  1.1362e-02,  1.0774e-02,  1.5860e-02,  6.3105e-03,\n",
      "        -1.4606e-02,  2.5667e-03,  2.6517e-02,  3.8578e-04, -1.3740e-02,\n",
      "         1.6882e-03, -2.3662e-02,  1.5679e-02,  1.0419e-02, -6.8595e-03,\n",
      "         2.4179e-02,  4.4839e-03,  2.3774e-02, -1.8527e-02,  2.1285e-02,\n",
      "        -2.5841e-02, -1.2366e-02, -2.6906e-02,  2.0484e-02, -1.0569e-02,\n",
      "         4.3345e-03,  1.0041e-02, -3.1620e-03, -3.9821e-03, -2.6514e-02,\n",
      "        -1.7524e-02,  1.6133e-02,  1.3109e-02,  1.3573e-02,  2.4867e-03,\n",
      "         2.8667e-02, -2.7457e-02, -5.7257e-03,  1.1151e-02, -3.0729e-02,\n",
      "         2.1387e-02, -6.9753e-03,  2.7955e-02, -3.0846e-02,  2.3825e-02,\n",
      "        -2.7134e-03, -9.5643e-03, -2.0054e-02,  4.1748e-03, -1.7255e-02,\n",
      "        -3.6498e-03,  1.6973e-03,  2.8682e-02, -2.6179e-02,  1.4620e-02,\n",
      "        -9.8101e-03, -5.8798e-03, -2.2916e-02, -1.4903e-02,  3.0621e-02,\n",
      "        -2.1609e-02, -2.8568e-03,  2.4916e-02,  1.5587e-02, -2.0509e-02,\n",
      "        -1.9371e-02, -1.5821e-02,  1.6149e-02,  1.9856e-02, -2.9412e-02,\n",
      "        -1.5759e-02,  1.9643e-02,  2.8487e-02,  2.8190e-02, -1.6899e-02,\n",
      "         4.7921e-03,  1.8001e-02, -1.8371e-02,  1.5061e-02,  2.7210e-02,\n",
      "         3.0366e-02, -2.0074e-03, -1.3822e-02,  1.4330e-02,  2.4125e-02,\n",
      "        -1.2183e-02,  2.7449e-03, -1.6958e-02, -1.5170e-02,  2.1757e-02,\n",
      "         2.3354e-02, -2.9819e-02, -2.8432e-02, -1.6247e-02,  2.6062e-02,\n",
      "        -9.0201e-03])\n",
      "56 Parameter containing:\n",
      "tensor([[ 0.0899, -0.0620,  0.0511,  ..., -0.0348, -0.0829, -0.0148],\n",
      "        [ 0.0125, -0.0005, -0.0378,  ..., -0.0438, -0.0180,  0.0026],\n",
      "        [ 0.0112,  0.0094, -0.0161,  ..., -0.0538,  0.0155, -0.0262],\n",
      "        ...,\n",
      "        [-0.0378,  0.0227,  0.0005,  ...,  0.0128,  0.0175,  0.0059],\n",
      "        [-0.0506, -0.0011, -0.0059,  ...,  0.0203,  0.0155,  0.0250],\n",
      "        [-0.0458, -0.0010,  0.0395,  ...,  0.0317,  0.0359,  0.0007]])\n",
      "57 Parameter containing:\n",
      "tensor([ 2.6046e-02, -2.2930e-03, -1.7771e-02, -1.5762e-02, -2.3783e-02,\n",
      "        -8.5612e-03,  1.9975e-02,  2.8229e-02,  2.3652e-02,  2.6296e-02,\n",
      "         2.8773e-02, -2.0123e-02, -1.6715e-05,  1.3973e-02,  1.4817e-02,\n",
      "         2.5540e-03,  2.6900e-02,  8.4033e-03,  7.5195e-03, -2.5219e-02,\n",
      "         2.2158e-02,  2.5230e-02, -1.9872e-02,  2.6809e-02,  1.6777e-02,\n",
      "         1.9622e-02, -2.6783e-02,  6.1583e-03,  2.2029e-02, -2.0342e-02,\n",
      "        -2.6335e-02, -1.5633e-02,  3.2491e-03,  2.4904e-02, -5.4319e-03,\n",
      "        -3.3788e-03, -2.1643e-02,  2.1350e-02,  6.9734e-03, -3.0841e-02,\n",
      "         1.9826e-03,  1.4666e-02, -1.4560e-02,  2.6667e-02,  2.9821e-03,\n",
      "         2.3680e-02, -1.0881e-02,  1.4312e-02, -2.6377e-02, -1.0164e-02,\n",
      "        -8.5682e-03,  3.1034e-02,  1.0881e-02, -2.4042e-03,  2.4598e-02,\n",
      "        -3.0504e-02, -2.3944e-02,  1.2117e-02, -2.4435e-02, -2.9484e-02,\n",
      "         9.6288e-04,  2.1802e-02,  7.3151e-03,  4.4404e-03, -2.2028e-03,\n",
      "         2.2204e-02, -7.8726e-03, -2.6573e-02,  3.0537e-02, -1.5629e-02,\n",
      "         4.1015e-03, -1.7314e-02, -1.5676e-02, -1.6758e-02, -7.0363e-03,\n",
      "         2.9334e-02, -2.2964e-02, -2.1046e-02,  8.0012e-03, -1.6492e-02,\n",
      "        -3.0905e-02, -2.6633e-02,  5.5926e-03, -6.3519e-03,  2.5121e-02,\n",
      "        -1.4675e-02, -2.5267e-03,  3.0390e-02, -2.9516e-02,  2.7802e-03,\n",
      "         2.4772e-02, -2.2938e-02,  1.4795e-02,  2.0899e-02,  3.7481e-03,\n",
      "        -3.1084e-02, -6.7402e-03,  8.6412e-03,  6.1798e-03, -3.1097e-02,\n",
      "        -1.5578e-02, -2.3045e-02,  1.1883e-02, -2.7070e-03,  2.8840e-02,\n",
      "        -2.3911e-02, -1.7389e-02, -1.1837e-03,  2.3350e-02, -1.2173e-02,\n",
      "         3.2733e-03, -1.2153e-02, -2.1892e-02, -2.3886e-02, -8.9242e-03,\n",
      "        -4.6110e-03,  5.2490e-03,  2.6387e-02,  2.0814e-02, -1.1050e-02,\n",
      "         2.6197e-04, -8.8088e-03,  6.1841e-03,  1.7047e-02, -2.1059e-02,\n",
      "         2.4827e-02, -2.7932e-02,  2.3179e-02,  5.8677e-03, -3.7097e-03,\n",
      "         1.1205e-03, -2.1936e-02,  5.9880e-03, -1.0117e-02, -1.2373e-02,\n",
      "        -1.2779e-02, -1.1871e-02,  2.5975e-02,  6.6802e-03,  1.7239e-02,\n",
      "        -2.6551e-02, -9.8927e-03, -7.4304e-03,  9.6733e-03,  2.9115e-02,\n",
      "        -7.9222e-03,  2.9984e-02,  9.5922e-03,  1.4430e-02,  1.8952e-02,\n",
      "         7.7897e-04,  2.7550e-02,  2.0640e-03,  1.8556e-03, -1.9904e-02,\n",
      "        -9.1987e-03, -9.0936e-03,  1.3878e-02, -4.8471e-03,  1.2047e-02,\n",
      "         1.4165e-02, -1.9449e-02,  1.5092e-02, -2.1135e-02, -2.8330e-02,\n",
      "         2.9752e-02, -2.0229e-02,  1.2854e-02,  1.5532e-02, -3.1055e-02,\n",
      "        -1.8451e-02,  2.4805e-02,  1.0145e-02,  2.1288e-02, -6.6765e-04,\n",
      "         1.5376e-02,  1.2455e-03, -2.8863e-02,  2.3564e-02, -1.4708e-03,\n",
      "        -5.6178e-03, -6.8924e-04,  2.4638e-02, -2.9729e-02, -2.3525e-02,\n",
      "        -2.5455e-02, -3.8969e-03,  4.4271e-03, -1.9301e-02,  1.7727e-02,\n",
      "        -2.8890e-02,  1.7231e-02,  9.2382e-03, -2.8979e-02,  2.7009e-02,\n",
      "         1.2663e-03, -2.0419e-02, -6.1454e-03, -1.4381e-02, -9.6770e-03,\n",
      "         1.1817e-02, -1.6307e-02,  2.1025e-02, -1.4723e-02,  1.0181e-02,\n",
      "        -1.1249e-02, -2.6596e-03,  2.2369e-03, -2.2062e-02,  1.4188e-02,\n",
      "         2.6106e-02,  1.6978e-02, -7.2244e-03,  1.1073e-03, -2.8295e-02,\n",
      "         6.5453e-03, -1.0839e-02,  1.7385e-02, -1.4049e-02, -3.8367e-03,\n",
      "        -1.9500e-02,  3.0272e-02, -2.2421e-02,  2.3515e-02, -9.9674e-03,\n",
      "         1.5935e-02,  2.6329e-02, -1.7242e-02, -2.6070e-02, -1.3657e-02,\n",
      "         3.0124e-02, -2.7937e-02,  3.0249e-02,  1.2829e-02,  1.7060e-03,\n",
      "         2.7931e-02,  1.0319e-02, -8.2610e-03, -3.0770e-02,  1.3324e-02,\n",
      "         1.8291e-02,  7.1099e-04, -1.0021e-02,  7.5036e-03,  2.2084e-02,\n",
      "        -2.8667e-02, -1.2854e-02,  2.4242e-02,  2.3046e-02, -2.3287e-02,\n",
      "        -9.5271e-03, -2.6203e-02,  2.9698e-02, -1.9170e-03, -6.6497e-03,\n",
      "        -2.1237e-02])\n",
      "58 Parameter containing:\n",
      "tensor([[ 0.0396,  0.0266,  0.0367,  ..., -0.0222, -0.0026,  0.0282],\n",
      "        [ 0.0142, -0.0014,  0.0325,  ...,  0.0086,  0.0264,  0.0186],\n",
      "        [-0.0015,  0.0371,  0.0323,  ..., -0.0132,  0.0319,  0.0397],\n",
      "        ...,\n",
      "        [ 0.0025, -0.0243, -0.0189,  ..., -0.0275,  0.0153,  0.0207],\n",
      "        [ 0.0115, -0.0167,  0.0005,  ..., -0.0037,  0.0324,  0.0408],\n",
      "        [-0.0130, -0.0283,  0.0425,  ...,  0.0017,  0.0333, -0.0178]])\n",
      "59 Parameter containing:\n",
      "tensor([-0.0098,  0.0193, -0.0102, -0.0017, -0.0039, -0.0063,  0.0071,  0.0232,\n",
      "        -0.0173, -0.0297, -0.0243,  0.0015, -0.0065, -0.0152, -0.0148, -0.0172,\n",
      "        -0.0321,  0.0155, -0.0076,  0.0155, -0.0270,  0.0202, -0.0266,  0.0001,\n",
      "         0.0166,  0.0096, -0.0283,  0.0032,  0.0313, -0.0026, -0.0026, -0.0230,\n",
      "         0.0071,  0.0067,  0.0046,  0.0188, -0.0328,  0.0131,  0.0104,  0.0238,\n",
      "        -0.0127,  0.0297, -0.0187,  0.0198, -0.0047, -0.0141,  0.0184, -0.0127,\n",
      "         0.0047,  0.0160, -0.0143, -0.0053, -0.0384, -0.0153, -0.0267, -0.0032,\n",
      "        -0.0137, -0.0055, -0.0203,  0.0371,  0.0363, -0.0030, -0.0224, -0.0080,\n",
      "         0.0131,  0.0054,  0.0414,  0.0027, -0.0308, -0.0204, -0.0036, -0.0199,\n",
      "        -0.0210, -0.0015, -0.0394,  0.0102, -0.0362,  0.0324, -0.0231,  0.0144,\n",
      "         0.0006, -0.0017,  0.0064, -0.0024, -0.0209,  0.0088,  0.0076, -0.0410,\n",
      "         0.0245,  0.0048,  0.0201, -0.0400, -0.0220,  0.0254,  0.0269, -0.0055,\n",
      "         0.0021, -0.0288, -0.0174,  0.0153,  0.0045, -0.0211, -0.0215,  0.0117,\n",
      "         0.0140,  0.0383, -0.0345, -0.0041,  0.0268,  0.0047,  0.0151, -0.0037,\n",
      "        -0.0101, -0.0121, -0.0001,  0.0251,  0.0279,  0.0346, -0.0004, -0.0177,\n",
      "        -0.0181,  0.0051,  0.0089, -0.0227,  0.0053,  0.0148, -0.0076,  0.0187,\n",
      "         0.0146, -0.0041, -0.0154, -0.0105,  0.0003, -0.0262, -0.0097,  0.0167,\n",
      "        -0.0065,  0.0214, -0.0251, -0.0093,  0.0256,  0.0312,  0.0296, -0.0188,\n",
      "        -0.0002, -0.0034, -0.0198, -0.0252,  0.0160, -0.0244, -0.0168,  0.0275,\n",
      "         0.0139, -0.0231,  0.0048,  0.0093, -0.0131,  0.0028, -0.0224, -0.0136,\n",
      "         0.0043, -0.0125,  0.0156, -0.0084, -0.0168, -0.0229,  0.0241, -0.0042,\n",
      "         0.0057, -0.0264, -0.0174, -0.0242,  0.0102, -0.0057, -0.0048, -0.0080,\n",
      "        -0.0262,  0.0096,  0.0029,  0.0268, -0.0277, -0.0103, -0.0094, -0.0165,\n",
      "        -0.0150,  0.0030,  0.0221, -0.0113, -0.0201, -0.0298, -0.0196,  0.0124,\n",
      "        -0.0126, -0.0192,  0.0130,  0.0334, -0.0003,  0.0222, -0.0008, -0.0083,\n",
      "        -0.0179,  0.0103,  0.0207,  0.0025, -0.0308, -0.0036, -0.0085, -0.0234,\n",
      "        -0.0201, -0.0152,  0.0038,  0.0015, -0.0236, -0.0294,  0.0108,  0.0258,\n",
      "         0.0089, -0.0123, -0.0098,  0.0223, -0.0214,  0.0142,  0.0168, -0.0066,\n",
      "         0.0284, -0.0176, -0.0036,  0.0003, -0.0176,  0.0177,  0.0003, -0.0048,\n",
      "        -0.0254, -0.0289, -0.0119,  0.0047, -0.0164, -0.0199, -0.0178, -0.0010,\n",
      "         0.0311,  0.0037,  0.0167,  0.0200,  0.0004, -0.0086,  0.0304,  0.0131,\n",
      "         0.0226, -0.0131,  0.0167, -0.0014, -0.0279,  0.0084,  0.0169, -0.0072])\n",
      "60 Parameter containing:\n",
      "tensor([[ 0.0179, -0.0372, -0.0115,  ..., -0.0212, -0.0345,  0.0252],\n",
      "        [-0.0643,  0.0282, -0.0291,  ...,  0.0241,  0.0296, -0.0290],\n",
      "        [ 0.0360,  0.0057,  0.0157,  ..., -0.0636, -0.0289,  0.0111],\n",
      "        ...,\n",
      "        [ 0.0319,  0.0881, -0.0355,  ...,  0.0207,  0.0433,  0.0347],\n",
      "        [-0.0244, -0.0275, -0.0115,  ..., -0.0050, -0.0353, -0.0328],\n",
      "        [ 0.0327,  0.0854, -0.0202,  ...,  0.0484, -0.0347,  0.0108]])\n",
      "61 Parameter containing:\n",
      "tensor([ 1.9111e-02, -6.5753e-03,  1.3032e-02, -1.2069e-02, -1.7643e-03,\n",
      "        -3.0879e-03,  3.2909e-03, -1.0415e-02, -7.0880e-03,  1.8357e-02,\n",
      "         9.5728e-03,  2.6801e-02, -1.4723e-02, -8.0293e-03, -1.0627e-02,\n",
      "        -1.0030e-02,  3.6092e-03,  1.2672e-04,  9.3501e-03,  1.0619e-02,\n",
      "        -4.4130e-03,  2.3898e-02,  1.8086e-02,  1.6078e-02,  1.9152e-03,\n",
      "         1.0157e-03, -7.2096e-03,  1.3457e-02,  4.2565e-03, -3.3596e-03,\n",
      "        -1.4531e-02,  1.1826e-02,  2.5066e-02, -1.0483e-02,  1.0617e-02,\n",
      "         3.0134e-02, -2.6968e-02,  1.2796e-02, -1.5907e-02,  1.6375e-02,\n",
      "         2.2193e-02, -2.5991e-02, -1.9801e-02,  1.0470e-02,  2.8865e-02,\n",
      "        -2.9571e-02, -2.8865e-03,  2.3913e-02,  9.5693e-03,  2.9951e-03,\n",
      "         1.6913e-02,  9.7395e-03,  2.0444e-02, -1.2625e-02, -1.2530e-03,\n",
      "        -2.2886e-02,  8.5641e-03, -3.6980e-03,  1.1823e-03,  4.1917e-02,\n",
      "        -2.2095e-03,  5.7236e-03,  7.9702e-03, -2.5631e-02, -5.4977e-04,\n",
      "         9.1705e-03,  1.6152e-02,  2.5387e-02, -5.3914e-03,  8.3076e-03,\n",
      "        -3.1883e-02, -9.3151e-03,  4.6793e-02, -1.6142e-02, -7.3871e-03,\n",
      "         2.8863e-02,  2.3207e-02,  1.7684e-02,  8.6101e-03,  5.3188e-03,\n",
      "         1.8633e-02, -4.4051e-02,  2.7519e-02, -8.3366e-03,  5.2551e-03,\n",
      "         8.5510e-03,  1.0504e-02,  3.0614e-02,  1.4699e-02, -1.3135e-02,\n",
      "         3.0691e-02, -6.9319e-03, -1.7307e-02,  9.3855e-03, -2.3791e-03,\n",
      "        -4.6571e-02, -3.3006e-02,  6.5688e-03,  7.0773e-03, -1.6882e-02,\n",
      "         2.0599e-03,  2.7767e-03,  3.1409e-02,  7.3207e-03,  1.8200e-03,\n",
      "        -2.7418e-02,  5.4725e-03, -5.7500e-03,  1.2071e-02,  3.8093e-02,\n",
      "        -1.0320e-02,  1.4937e-02,  6.9413e-03,  1.1827e-02,  3.7331e-02,\n",
      "        -2.7272e-02,  9.0136e-03, -2.4571e-02, -1.3487e-02, -2.1164e-02,\n",
      "         1.0446e-04, -4.6585e-03, -6.6599e-03,  2.4976e-03, -1.3952e-02,\n",
      "         2.9287e-02,  3.4006e-02, -2.4485e-02, -2.3153e-02, -4.7946e-02,\n",
      "        -2.9758e-02,  2.3946e-02,  4.1523e-03, -3.2822e-02,  4.5754e-02,\n",
      "        -3.4194e-02, -5.4770e-02,  4.2133e-02,  2.0844e-03, -5.2559e-03,\n",
      "         5.3779e-03,  1.6510e-02,  5.0080e-04, -2.1388e-02, -4.1534e-02,\n",
      "        -2.1821e-02, -3.5789e-02,  4.2359e-02, -4.7914e-02,  4.0722e-02,\n",
      "         9.4288e-04,  1.1951e-02,  1.0489e-02, -2.4600e-02, -2.6713e-02,\n",
      "         3.3510e-03,  3.5025e-02, -2.7307e-02, -3.7746e-02, -4.9882e-02,\n",
      "        -1.6632e-02,  2.3186e-03,  1.3104e-03, -3.9094e-03, -2.3620e-03,\n",
      "         3.4149e-02,  2.2787e-02, -1.8364e-02,  1.5415e-02, -3.0821e-02,\n",
      "         7.6573e-03, -2.8541e-02, -9.8365e-03,  8.8012e-05, -2.9835e-02,\n",
      "         6.6203e-03, -2.4997e-02,  2.5633e-02, -1.7824e-02, -2.3015e-02,\n",
      "        -2.8073e-02, -1.9064e-02,  7.2055e-03,  1.0874e-03,  8.2390e-03,\n",
      "         1.2561e-02,  3.2869e-02,  1.9444e-02, -4.1255e-04,  1.3460e-02,\n",
      "         1.7121e-02, -3.3627e-02, -9.0021e-03, -3.2069e-02,  2.0359e-02,\n",
      "         3.9153e-02,  3.6927e-02,  4.1471e-02,  3.3110e-03,  3.4497e-02,\n",
      "         1.1225e-02,  3.7435e-03, -4.2898e-02, -1.1746e-02, -3.9464e-03,\n",
      "         3.2079e-02, -2.0138e-02, -3.2037e-02, -3.0887e-03, -1.5895e-02,\n",
      "         2.6285e-02, -1.2002e-02,  2.2978e-03, -1.8992e-02, -1.3944e-02,\n",
      "        -1.6910e-03,  2.0136e-02,  3.3288e-02, -1.2228e-02,  1.3571e-02,\n",
      "        -2.7238e-03,  1.2876e-02,  1.9309e-02,  2.9890e-02,  3.0551e-03,\n",
      "        -7.7935e-03, -2.2071e-02,  7.5963e-03, -5.3202e-03, -1.1659e-02,\n",
      "         4.7099e-02, -4.9347e-02, -1.0523e-02,  4.3702e-02,  4.3998e-02,\n",
      "        -2.4714e-02, -5.3519e-02, -3.2062e-02,  9.8927e-03, -1.2814e-02,\n",
      "         2.9163e-02, -2.8518e-02,  4.9752e-02,  2.2559e-02, -4.0892e-02,\n",
      "        -1.8929e-02, -6.5153e-04,  5.0795e-02,  2.9312e-02,  5.1081e-04,\n",
      "        -2.9402e-03, -3.2449e-02, -4.7994e-03,  1.9787e-02,  7.9818e-03,\n",
      "         4.8186e-02])\n",
      "62 Parameter containing:\n",
      "tensor([[-1.7615e-02, -4.7475e-02, -2.2212e-02,  ...,  2.8942e-02,\n",
      "         -4.6888e-03, -2.0600e-02],\n",
      "        [-2.7037e-02, -1.1342e-02, -2.8673e-02,  ..., -7.4910e-05,\n",
      "          3.3849e-02,  4.7621e-02],\n",
      "        [ 2.3184e-02,  9.5056e-03,  9.4542e-03,  ..., -1.5796e-02,\n",
      "         -1.5674e-02, -2.0865e-02],\n",
      "        ...,\n",
      "        [ 3.1997e-02,  9.4483e-03, -3.2664e-02,  ..., -2.2670e-02,\n",
      "          1.4225e-02,  3.9147e-02],\n",
      "        [-1.8133e-02,  3.0218e-03, -4.9757e-02,  ...,  1.9631e-02,\n",
      "         -2.4435e-02,  1.2983e-02],\n",
      "        [ 8.3150e-03,  1.6982e-02,  1.5091e-02,  ...,  1.9968e-02,\n",
      "         -5.1021e-03, -7.5768e-03]])\n",
      "63 Parameter containing:\n",
      "tensor([-1.6625e-02,  9.7203e-03,  1.5005e-02, -1.6265e-02, -1.4022e-02,\n",
      "         1.7101e-02, -1.8119e-02, -2.9137e-02,  2.2008e-02, -2.1230e-02,\n",
      "        -1.0206e-02, -2.2262e-02, -2.7216e-02,  3.1308e-02,  2.6712e-02,\n",
      "        -3.9576e-04, -1.6368e-02,  5.3985e-03,  1.9328e-02, -2.3436e-02,\n",
      "         4.1669e-03, -7.0411e-04,  1.1337e-02, -2.9781e-02,  1.1676e-02,\n",
      "        -7.1727e-03, -1.9047e-02, -1.7537e-02, -2.4518e-02, -1.8772e-03,\n",
      "         4.9246e-03, -1.1440e-02,  3.1602e-02, -3.0608e-02, -3.6279e-03,\n",
      "         1.1101e-02,  1.0427e-02, -1.0514e-02, -9.1958e-03, -6.9121e-03,\n",
      "         6.4582e-03,  1.3039e-02,  7.8782e-03,  1.4018e-02, -8.9546e-03,\n",
      "         2.4664e-02, -7.4290e-03, -2.8372e-02,  2.8472e-03,  2.4343e-02,\n",
      "         2.9123e-02, -8.7308e-03,  3.7541e-03,  1.3734e-02, -2.0661e-02,\n",
      "        -3.0277e-02, -1.3908e-02, -6.6648e-03, -1.5239e-02, -2.2435e-02,\n",
      "        -9.0041e-03, -1.4163e-02,  2.3006e-02, -2.1041e-02,  2.0800e-02,\n",
      "         1.5429e-02, -1.1313e-02,  2.5343e-02, -1.4023e-02, -3.9634e-03,\n",
      "         2.0237e-02, -2.9398e-02,  2.3896e-02,  9.4610e-05, -1.1083e-02,\n",
      "         2.4051e-03, -2.8415e-02,  1.4006e-03,  8.6900e-03,  1.1490e-02,\n",
      "         1.5251e-02, -3.1595e-02,  8.5789e-04,  2.3390e-02,  2.9767e-02,\n",
      "         2.0459e-02,  2.6447e-02, -8.4002e-03, -1.0419e-02, -1.5415e-02,\n",
      "         1.5766e-02,  2.5030e-02, -1.7570e-02,  2.8875e-02,  1.4829e-02,\n",
      "        -1.4066e-02, -1.5992e-02, -2.8748e-02, -5.0094e-03,  1.5060e-02,\n",
      "        -3.8604e-03,  1.5029e-02, -2.5382e-02,  4.0841e-04, -9.9374e-03,\n",
      "        -3.1319e-02,  2.9714e-02,  9.2896e-03,  2.9545e-02,  7.6578e-03,\n",
      "         2.2633e-02, -1.2104e-02,  1.4333e-02, -1.8042e-02, -2.2952e-02,\n",
      "        -2.5335e-02,  1.9835e-02,  1.6557e-02, -1.5039e-02, -8.8048e-03,\n",
      "         3.2638e-02, -2.0592e-02, -1.7667e-02, -1.2670e-02, -2.2390e-02,\n",
      "         1.0666e-02, -2.8543e-02,  8.1443e-03, -9.1171e-03,  3.5363e-03,\n",
      "        -7.6041e-03,  2.2434e-02, -2.1427e-02, -1.7371e-02,  8.6422e-03,\n",
      "         2.6481e-02, -1.8319e-03, -7.1933e-03, -5.5129e-04,  1.7020e-03,\n",
      "        -2.2625e-02, -1.5129e-02, -1.2168e-02, -2.4637e-02,  6.8224e-03,\n",
      "        -6.9160e-03,  1.8571e-02, -8.5226e-03,  1.8852e-02,  1.5568e-02,\n",
      "        -1.0851e-02, -1.8174e-02,  2.8240e-02,  1.5233e-02,  2.2958e-02,\n",
      "        -1.3547e-02,  3.1336e-02, -1.4271e-02,  1.1784e-02, -2.1260e-02,\n",
      "        -1.7751e-03,  1.1780e-02, -1.3280e-02,  1.6328e-03,  6.0610e-03,\n",
      "        -1.1006e-02, -1.3625e-02,  5.7154e-04,  3.2921e-02, -2.4451e-02,\n",
      "        -3.8500e-03, -7.6733e-03,  2.5385e-02,  1.1172e-02,  1.7669e-02,\n",
      "         6.7676e-03,  2.6409e-02,  1.4194e-04,  9.3145e-03,  3.5156e-03,\n",
      "         2.4046e-02,  9.9749e-03, -2.8250e-02, -3.0142e-02, -1.1081e-02,\n",
      "         3.0159e-02, -3.9448e-04, -1.3742e-02, -3.1873e-02, -7.0317e-03,\n",
      "        -3.8334e-03,  1.7202e-02,  2.8114e-02,  3.3148e-02,  1.1842e-02,\n",
      "        -4.1735e-03, -1.8637e-02, -3.1510e-02, -2.1839e-02,  1.7699e-02,\n",
      "        -5.6399e-03, -5.2614e-03, -6.3007e-03, -4.8254e-04,  1.6187e-02,\n",
      "        -1.4106e-02, -2.4257e-02,  8.5760e-03, -2.1062e-02, -1.0710e-02,\n",
      "        -1.3711e-02,  2.3360e-02,  2.1989e-02,  1.1321e-03, -2.5735e-02,\n",
      "        -1.6416e-02,  6.8937e-03, -2.4291e-02,  2.1640e-02, -5.4726e-03,\n",
      "         1.2688e-02, -5.0493e-03, -7.7404e-03, -2.0641e-02, -1.6738e-02,\n",
      "         2.3107e-02,  4.8294e-03, -1.2720e-02, -2.5659e-02,  1.8739e-02,\n",
      "         2.3021e-02, -2.4746e-02, -1.5664e-02, -2.2226e-02, -2.4359e-02,\n",
      "        -1.8523e-02, -2.8255e-02,  1.5233e-02, -1.6037e-03, -8.5060e-03,\n",
      "        -6.6056e-03, -2.9270e-03,  1.9055e-02, -1.3846e-04,  2.6390e-02,\n",
      "         1.3568e-02, -5.5395e-03, -2.0338e-02,  2.9898e-02,  2.4411e-02,\n",
      "        -2.3771e-02,  3.0853e-02, -5.1629e-03, -4.8393e-03,  1.8056e-02,\n",
      "        -2.6472e-02])\n",
      "64 Parameter containing:\n",
      "tensor([[-0.0090, -0.0446, -0.0213,  ..., -0.0294, -0.0675, -0.0135],\n",
      "        [ 0.0205, -0.0246, -0.0029,  ...,  0.0216,  0.0362,  0.0288],\n",
      "        [ 0.0022,  0.0591,  0.0181,  ..., -0.0153,  0.0107, -0.0019],\n",
      "        ...,\n",
      "        [ 0.0290,  0.0263,  0.0245,  ..., -0.0236,  0.0098,  0.0375],\n",
      "        [ 0.0729,  0.0282,  0.0221,  ...,  0.0204,  0.0390, -0.0263],\n",
      "        [ 0.0339,  0.0164,  0.0123,  ...,  0.0289,  0.0215, -0.0164]])\n",
      "65 Parameter containing:\n",
      "tensor([-0.0017,  0.0311,  0.0229,  0.0205, -0.0249, -0.0323,  0.0379, -0.0100,\n",
      "         0.0099, -0.0136,  0.0092,  0.0111, -0.0208, -0.0002,  0.0249, -0.0258,\n",
      "         0.0017,  0.0107, -0.0082,  0.0203, -0.0209,  0.0078,  0.0148,  0.0406,\n",
      "         0.0428, -0.0215, -0.0008,  0.0025,  0.0062, -0.0203, -0.0131, -0.0184,\n",
      "        -0.0023,  0.0185, -0.0323,  0.0128, -0.0096,  0.0219, -0.0108,  0.0307,\n",
      "         0.0085,  0.0041, -0.0180, -0.0277,  0.0113,  0.0275,  0.0150,  0.0312,\n",
      "         0.0101,  0.0156,  0.0003,  0.0315,  0.0298, -0.0183, -0.0079,  0.0412,\n",
      "         0.0154,  0.0018,  0.0155, -0.0083,  0.0078,  0.0066, -0.0184, -0.0123,\n",
      "        -0.0143,  0.0099,  0.0346,  0.0163,  0.0249, -0.0054,  0.0088,  0.0129,\n",
      "         0.0005, -0.0264,  0.0155,  0.0175, -0.0018, -0.0214, -0.0305, -0.0192,\n",
      "         0.0185,  0.0119, -0.0229,  0.0055,  0.0302, -0.0386, -0.0167, -0.0209,\n",
      "         0.0417, -0.0072, -0.0141,  0.0149, -0.0326,  0.0426, -0.0084,  0.0216,\n",
      "        -0.0407,  0.0079,  0.0043,  0.0277, -0.0195, -0.0310,  0.0083,  0.0250,\n",
      "         0.0008,  0.0069, -0.0061, -0.0277, -0.0047, -0.0101, -0.0198,  0.0230,\n",
      "        -0.0362, -0.0011, -0.0151, -0.0042,  0.0350,  0.0143,  0.0156,  0.0273,\n",
      "        -0.0387, -0.0167,  0.0153, -0.0254, -0.0455,  0.0348,  0.0084,  0.0254,\n",
      "         0.0169,  0.0237,  0.0252, -0.0215,  0.0041, -0.0095, -0.0214, -0.0100,\n",
      "         0.0184, -0.0283, -0.0251, -0.0339, -0.0015,  0.0036, -0.0087,  0.0301,\n",
      "        -0.0287, -0.0211,  0.0229,  0.0409, -0.0290,  0.0111, -0.0229,  0.0137,\n",
      "         0.0075, -0.0097, -0.0047, -0.0027,  0.0185, -0.0101, -0.0061, -0.0194,\n",
      "        -0.0136, -0.0128,  0.0199, -0.0109, -0.0067,  0.0150, -0.0010, -0.0187,\n",
      "         0.0193,  0.0005,  0.0301, -0.0278, -0.0121,  0.0165,  0.0035, -0.0184,\n",
      "         0.0096, -0.0069,  0.0055,  0.0232, -0.0030, -0.0207,  0.0223, -0.0318,\n",
      "        -0.0017, -0.0245,  0.0259, -0.0084, -0.0358,  0.0064, -0.0266,  0.0001,\n",
      "        -0.0207, -0.0360,  0.0351, -0.0135,  0.0001,  0.0191,  0.0103, -0.0235,\n",
      "        -0.0155,  0.0204, -0.0303,  0.0240,  0.0104,  0.0146, -0.0301,  0.0160,\n",
      "         0.0056, -0.0013, -0.0134, -0.0162,  0.0200,  0.0025,  0.0088, -0.0273,\n",
      "         0.0298, -0.0056, -0.0280,  0.0189, -0.0124, -0.0001, -0.0087, -0.0154,\n",
      "         0.0122, -0.0129,  0.0177,  0.0322,  0.0131,  0.0188, -0.0225,  0.0004,\n",
      "         0.0254,  0.0273,  0.0020,  0.0207, -0.0171,  0.0191,  0.0136,  0.0418,\n",
      "        -0.0149, -0.0148,  0.0136,  0.0140, -0.0238, -0.0131, -0.0182, -0.0423,\n",
      "         0.0268,  0.0157, -0.0201, -0.0015,  0.0052, -0.0305,  0.0310, -0.0056])\n",
      "66 Parameter containing:\n",
      "tensor([[ 0.0122, -0.0478,  0.0543,  ..., -0.0474,  0.0030,  0.0164],\n",
      "        [ 0.0254,  0.0098, -0.0115,  ...,  0.0378,  0.0346, -0.0639],\n",
      "        [-0.0690, -0.0450, -0.0322,  ..., -0.0033, -0.0211,  0.0449],\n",
      "        ...,\n",
      "        [-0.0351, -0.0188, -0.0838,  ..., -0.0120,  0.0220, -0.0508],\n",
      "        [-0.0053,  0.0207,  0.0301,  ...,  0.0410,  0.0408, -0.0153],\n",
      "        [ 0.0352,  0.0589,  0.0402,  ...,  0.0280,  0.0415, -0.0046]])\n",
      "67 Parameter containing:\n",
      "tensor([ 0.0009, -0.0405,  0.0601, -0.0249,  0.0119, -0.0292,  0.0398, -0.0240,\n",
      "        -0.0377,  0.0448, -0.0245, -0.0014,  0.0258, -0.0444,  0.0187,  0.0582,\n",
      "         0.0309,  0.0286, -0.0309,  0.0100, -0.0511, -0.0629,  0.0140, -0.0485,\n",
      "         0.0397,  0.0578, -0.0073, -0.0404, -0.0039,  0.0405, -0.0397, -0.0111,\n",
      "        -0.0211,  0.0352, -0.0244,  0.0264,  0.0198,  0.0010, -0.0074,  0.0634,\n",
      "         0.0573, -0.0397, -0.0242,  0.0241, -0.0373,  0.0265,  0.0375,  0.0550,\n",
      "         0.0221, -0.0531,  0.0300,  0.0185, -0.0120,  0.0531, -0.0270, -0.0096,\n",
      "        -0.0201,  0.0106, -0.0289, -0.0378,  0.0230,  0.0152,  0.0132,  0.0361,\n",
      "        -0.0333,  0.0401, -0.0350,  0.0030, -0.0523, -0.0228,  0.0100, -0.0432,\n",
      "        -0.0460,  0.0032,  0.0531, -0.0496, -0.0369,  0.0348, -0.0094,  0.0240,\n",
      "        -0.0071, -0.0260,  0.0383,  0.0217,  0.0244,  0.0600,  0.0033,  0.0279,\n",
      "        -0.0325,  0.0278, -0.0300, -0.0365, -0.0511,  0.0233,  0.0124, -0.0007,\n",
      "        -0.0037,  0.0493,  0.0007,  0.0348,  0.0428,  0.0361,  0.0397,  0.0035,\n",
      "        -0.0554, -0.0412,  0.0023,  0.0170,  0.0350,  0.0211,  0.0093,  0.0398,\n",
      "         0.0361, -0.0151, -0.0400, -0.0274,  0.0396, -0.0238,  0.0544, -0.0542,\n",
      "         0.0523, -0.0021,  0.0166,  0.0596, -0.0547, -0.0245, -0.0375,  0.0345,\n",
      "        -0.0166, -0.0536,  0.0438, -0.0252, -0.0306,  0.0539,  0.0512,  0.0433,\n",
      "         0.0136,  0.0014, -0.0336,  0.0052, -0.0081, -0.0157, -0.0028,  0.0452,\n",
      "        -0.0466, -0.0297, -0.0093,  0.0154, -0.0475,  0.0356, -0.0432,  0.0439,\n",
      "         0.0027, -0.0032, -0.0009, -0.0368,  0.0253, -0.0276, -0.0302, -0.0148,\n",
      "         0.0085,  0.0482, -0.0256,  0.0076,  0.0219,  0.0148,  0.0298,  0.0496,\n",
      "         0.0238,  0.0427, -0.0325, -0.0022,  0.0098,  0.0009,  0.0336, -0.0050,\n",
      "         0.0338,  0.0162, -0.0442,  0.0246,  0.0602,  0.0558, -0.0400, -0.0071,\n",
      "         0.0290, -0.0222, -0.0342, -0.0070, -0.0455,  0.0584, -0.0556, -0.0304,\n",
      "         0.0471,  0.0571, -0.0541,  0.0094, -0.0270,  0.0068, -0.0210, -0.0183,\n",
      "        -0.0018, -0.0391,  0.0473, -0.0175,  0.0132,  0.0034,  0.0181, -0.0071,\n",
      "        -0.0531, -0.0164,  0.0131,  0.0406, -0.0289, -0.0105,  0.0521,  0.0632,\n",
      "        -0.0387, -0.0257, -0.0128, -0.0359,  0.0084, -0.0395,  0.0095, -0.0407,\n",
      "        -0.0174, -0.0507, -0.0295,  0.0053, -0.0495, -0.0491, -0.0100, -0.0164,\n",
      "         0.0485,  0.0659, -0.0021,  0.0137, -0.0084,  0.0358,  0.0403, -0.0062,\n",
      "        -0.0223, -0.0575,  0.0369, -0.0050, -0.0511,  0.0450,  0.0146,  0.0194,\n",
      "         0.0503, -0.0564, -0.0019, -0.0495, -0.0247,  0.0344, -0.0621, -0.0353])\n",
      "68 Parameter containing:\n",
      "tensor([[ 0.0343, -0.0725, -0.0343,  ..., -0.0392,  0.0154,  0.0368],\n",
      "        [-0.0433,  0.0538, -0.0053,  ..., -0.0171,  0.0491, -0.0035],\n",
      "        [ 0.0178, -0.0162, -0.0349,  ...,  0.0185,  0.0503, -0.0528],\n",
      "        ...,\n",
      "        [-0.0434,  0.0103, -0.0614,  ...,  0.0332,  0.0015,  0.0056],\n",
      "        [ 0.0839,  0.0163,  0.0078,  ..., -0.0531, -0.0266, -0.0354],\n",
      "        [-0.0349,  0.0088, -0.0707,  ..., -0.0755,  0.0421, -0.0391]])\n",
      "69 Parameter containing:\n",
      "tensor([ 0.0052, -0.0084,  0.0335, -0.0621, -0.0701,  0.0309,  0.0351, -0.0203,\n",
      "        -0.0366,  0.0478,  0.0326, -0.0066, -0.0153, -0.0273, -0.0195,  0.0470,\n",
      "        -0.0281,  0.0410, -0.0034,  0.0583, -0.0471, -0.0341, -0.0124, -0.0476,\n",
      "        -0.0135,  0.0511,  0.0373,  0.0417, -0.0074, -0.0124,  0.0439, -0.0522,\n",
      "         0.0650, -0.0003, -0.0439, -0.0256,  0.0184, -0.0553, -0.0397, -0.0125,\n",
      "        -0.0248, -0.0331, -0.0177, -0.0325, -0.0148, -0.0487,  0.0453, -0.0478,\n",
      "        -0.0632,  0.0618, -0.0036,  0.0199,  0.0553, -0.0077, -0.0454, -0.0471,\n",
      "        -0.0158,  0.0051,  0.0015,  0.0305,  0.0605, -0.0043, -0.0368, -0.0614,\n",
      "        -0.0242, -0.0111, -0.0359,  0.0504,  0.0312, -0.0070,  0.0517, -0.0234,\n",
      "         0.0596,  0.0067, -0.0303, -0.0049,  0.0649,  0.0617,  0.0384,  0.0063,\n",
      "        -0.0394,  0.0476,  0.0337, -0.0009, -0.0248,  0.0518, -0.0430, -0.0813,\n",
      "        -0.0354, -0.0335, -0.0446, -0.0269,  0.0339,  0.0367,  0.0283, -0.0100,\n",
      "        -0.0249,  0.0082, -0.0307, -0.0345, -0.0429, -0.0475,  0.0522,  0.0243,\n",
      "         0.0005, -0.0326, -0.0244, -0.0080, -0.0390,  0.0416,  0.0533, -0.0331,\n",
      "        -0.0135,  0.0055,  0.0104, -0.0032, -0.0118,  0.0620,  0.0119, -0.0242,\n",
      "         0.0487,  0.0107,  0.0062, -0.0198, -0.0101,  0.0217,  0.0538,  0.0425,\n",
      "        -0.0191, -0.0080, -0.0393,  0.0537, -0.0551,  0.0771, -0.0058, -0.0065,\n",
      "         0.0178, -0.0413, -0.0153,  0.0344, -0.0367, -0.0219,  0.0615,  0.0215,\n",
      "         0.0271, -0.0053,  0.0556, -0.0588,  0.0431,  0.0334, -0.0507,  0.0270,\n",
      "        -0.0245, -0.0242,  0.0338,  0.0031,  0.0345, -0.0258,  0.0051, -0.0274,\n",
      "         0.0593,  0.0058,  0.0477, -0.0042, -0.0043, -0.0365, -0.0556, -0.0123,\n",
      "         0.0038,  0.0751,  0.0662,  0.0486, -0.0439,  0.0174,  0.0014, -0.0035,\n",
      "        -0.0335, -0.0092,  0.0205, -0.0082, -0.0104, -0.0381, -0.0606, -0.0481,\n",
      "         0.0396, -0.0029,  0.0452, -0.0043, -0.0800,  0.0008,  0.0260,  0.0349,\n",
      "         0.0156,  0.0393,  0.0435,  0.0455, -0.0285, -0.0046, -0.0560,  0.0207,\n",
      "        -0.0248,  0.0552,  0.0371,  0.0191,  0.0272,  0.0244, -0.0564,  0.0560,\n",
      "        -0.0399, -0.0200,  0.0385,  0.0195,  0.0485, -0.0240,  0.0331, -0.0268,\n",
      "        -0.0139, -0.0594, -0.0527,  0.0607, -0.0112,  0.0316,  0.0594,  0.0664,\n",
      "         0.0508, -0.0332,  0.0314, -0.0248, -0.0653, -0.0311, -0.0608,  0.0187,\n",
      "        -0.0021,  0.0432,  0.0085,  0.0472, -0.0736,  0.0622,  0.0087, -0.0153,\n",
      "         0.0358,  0.0373, -0.0316,  0.0487, -0.0542, -0.0042,  0.0035, -0.0385,\n",
      "         0.0275, -0.0281,  0.0092, -0.0173,  0.0621, -0.0136,  0.0632,  0.0245])\n",
      "70 Parameter containing:\n",
      "tensor([1.])\n",
      "71 Parameter containing:\n",
      "tensor([1.])\n",
      "72 Parameter containing:\n",
      "tensor([[[ 0.1504, -0.0226,  0.0017,  ..., -0.2626,  0.2333, -0.3072],\n",
      "         [ 0.2261, -0.2705, -0.2361,  ..., -0.0997, -0.3045,  0.1108],\n",
      "         [-0.3092, -0.0737, -0.2638,  ...,  0.1381, -0.0763,  0.2017],\n",
      "         ...,\n",
      "         [ 0.0432, -0.0997, -0.1802,  ...,  0.2859,  0.1631, -0.0316],\n",
      "         [ 0.2759,  0.1042,  0.0112,  ...,  0.0612,  0.0738,  0.3558],\n",
      "         [ 0.1225, -0.0156, -0.2824,  ...,  0.0187, -0.2791,  0.2554]],\n",
      "\n",
      "        [[ 0.1862, -0.1198,  0.1984,  ...,  0.1553,  0.3329, -0.0749],\n",
      "         [-0.1970, -0.3862, -0.1798,  ..., -0.1403,  0.2744,  0.2201],\n",
      "         [-0.1854,  0.0501, -0.2062,  ..., -0.3251, -0.0795, -0.3275],\n",
      "         ...,\n",
      "         [ 0.1771, -0.2523,  0.1155,  ...,  0.0783, -0.1342,  0.3614],\n",
      "         [ 0.2528,  0.0089,  0.1744,  ...,  0.0510, -0.0953,  0.2016],\n",
      "         [-0.0627, -0.0928,  0.2565,  ...,  0.0403, -0.0231,  0.2364]],\n",
      "\n",
      "        [[ 0.2857, -0.0031,  0.1172,  ..., -0.0596,  0.2374,  0.1673],\n",
      "         [-0.0753,  0.2449,  0.2919,  ...,  0.1340, -0.1684,  0.0694],\n",
      "         [-0.0822,  0.3166, -0.2177,  ...,  0.0874, -0.1074,  0.2835],\n",
      "         ...,\n",
      "         [-0.1297, -0.1634, -0.2875,  ..., -0.1167,  0.1912, -0.1160],\n",
      "         [ 0.1064,  0.1360,  0.2147,  ..., -0.1080, -0.1351,  0.0879],\n",
      "         [ 0.1149, -0.1908,  0.1385,  ..., -0.0857,  0.2490, -0.0865]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0813, -0.0750,  0.0161,  ..., -0.0546, -0.2376, -0.1044],\n",
      "         [-0.0699, -0.2120,  0.2824,  ...,  0.2813,  0.1867, -0.1654],\n",
      "         [-0.1297, -0.2612,  0.1754,  ...,  0.3036, -0.1757, -0.1270],\n",
      "         ...,\n",
      "         [-0.1950, -0.2400, -0.0343,  ..., -0.1244, -0.0157,  0.1871],\n",
      "         [ 0.0390, -0.0744,  0.0671,  ...,  0.0867,  0.1975,  0.1415],\n",
      "         [ 0.0467, -0.0774,  0.1647,  ...,  0.2353,  0.0394, -0.2034]],\n",
      "\n",
      "        [[ 0.3020, -0.0963, -0.0305,  ..., -0.3186, -0.1992, -0.0809],\n",
      "         [-0.2412,  0.0739,  0.1001,  ...,  0.2416, -0.1400, -0.0998],\n",
      "         [-0.1246,  0.2222,  0.2900,  ...,  0.0038,  0.2678, -0.2172],\n",
      "         ...,\n",
      "         [ 0.1993,  0.2445, -0.0543,  ..., -0.0757, -0.2513,  0.2490],\n",
      "         [-0.1656, -0.2884,  0.2362,  ...,  0.0645,  0.1173,  0.0253],\n",
      "         [-0.2154, -0.0363,  0.3298,  ..., -0.2149, -0.0237, -0.1242]],\n",
      "\n",
      "        [[ 0.0849,  0.2145, -0.1080,  ...,  0.1049,  0.0243,  0.2847],\n",
      "         [-0.2073, -0.1233, -0.0846,  ..., -0.0438, -0.0696, -0.0296],\n",
      "         [-0.0350, -0.2639,  0.2422,  ...,  0.0273,  0.0612, -0.2350],\n",
      "         ...,\n",
      "         [ 0.1641,  0.0624,  0.2645,  ..., -0.1279,  0.0615,  0.1257],\n",
      "         [-0.2127, -0.0084, -0.1079,  ..., -0.1612, -0.1875,  0.1012],\n",
      "         [ 0.2470,  0.0792, -0.2373,  ..., -0.2219, -0.1136, -0.0124]]])\n",
      "73 Parameter containing:\n",
      "tensor([[[ 2.7554e-01, -9.7883e-02, -2.3105e-01,  ..., -2.9267e-01,\n",
      "          -2.1194e-01, -1.0616e-01],\n",
      "         [-3.0057e-01,  2.9116e-01, -3.1156e-01,  ...,  1.6161e-01,\n",
      "           1.4851e-01,  2.1906e-01],\n",
      "         [-2.5940e-01,  1.2835e-01, -3.0807e-01,  ...,  3.6667e-01,\n",
      "           1.8995e-01, -2.7900e-01],\n",
      "         ...,\n",
      "         [-1.4325e-01,  1.5572e-01, -2.0906e-02,  ...,  1.2149e-01,\n",
      "          -5.5228e-02,  1.9975e-01],\n",
      "         [ 1.5957e-01,  3.4277e-01,  2.3386e-01,  ..., -3.8315e-02,\n",
      "           9.1351e-02, -2.3694e-01],\n",
      "         [-1.7918e-01, -5.0876e-02, -4.3169e-02,  ...,  4.5817e-02,\n",
      "          -5.5785e-02,  1.1197e-01]],\n",
      "\n",
      "        [[-1.8153e-01,  2.8848e-01,  8.2090e-03,  ...,  2.1752e-01,\n",
      "          -2.4571e-01, -1.5850e-01],\n",
      "         [ 2.6841e-01, -1.1659e-02,  5.0263e-02,  ...,  3.1439e-01,\n",
      "           1.5632e-01, -1.4977e-01],\n",
      "         [ 3.7706e-02, -1.6711e-01, -2.1330e-01,  ..., -4.1421e-02,\n",
      "          -2.1707e-01, -2.3537e-01],\n",
      "         ...,\n",
      "         [-2.3811e-01,  4.6909e-03, -1.2131e-01,  ...,  2.3776e-01,\n",
      "          -8.7319e-02, -1.3248e-01],\n",
      "         [-1.5364e-01, -1.1150e-01, -2.2507e-01,  ..., -1.6994e-01,\n",
      "          -8.4476e-02, -1.1346e-01],\n",
      "         [ 2.5254e-01, -2.6074e-01, -1.1547e-01,  ...,  2.3325e-01,\n",
      "          -1.5703e-01, -2.7376e-01]],\n",
      "\n",
      "        [[ 3.2627e-01,  2.1860e-01,  6.5305e-02,  ...,  9.6176e-02,\n",
      "          -2.4392e-02, -1.2504e-01],\n",
      "         [ 1.6943e-01,  1.1423e-01, -2.9420e-01,  ...,  1.4071e-01,\n",
      "          -2.9777e-01, -1.3030e-01],\n",
      "         [ 1.7429e-01,  1.2240e-01,  1.7476e-01,  ..., -4.5029e-02,\n",
      "           1.5421e-01, -2.7836e-02],\n",
      "         ...,\n",
      "         [-2.9264e-01,  5.8831e-02, -1.0362e-01,  ..., -2.1322e-01,\n",
      "          -9.2630e-02, -1.4042e-01],\n",
      "         [ 4.8313e-02,  1.0506e-01,  1.9259e-01,  ..., -1.6534e-01,\n",
      "          -2.1472e-01,  3.7385e-04],\n",
      "         [-5.4945e-02,  4.8015e-02, -9.2896e-02,  ...,  3.1184e-01,\n",
      "           8.7513e-02, -1.0860e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.4077e-01, -3.3340e-01, -7.4987e-02,  ...,  1.9984e-01,\n",
      "          -2.7886e-01,  2.5243e-01],\n",
      "         [ 2.0898e-01, -1.7094e-01, -2.4922e-01,  ..., -1.4751e-01,\n",
      "          -2.9334e-01, -2.2610e-01],\n",
      "         [ 2.6760e-01, -2.1601e-01, -1.2057e-01,  ..., -3.4441e-01,\n",
      "           3.4733e-01, -3.6191e-01],\n",
      "         ...,\n",
      "         [-3.0455e-04, -9.0480e-03, -3.0820e-01,  ...,  1.9529e-02,\n",
      "          -3.5747e-02,  1.6249e-01],\n",
      "         [-2.6462e-01, -9.8576e-02,  2.2458e-01,  ...,  1.2289e-01,\n",
      "           2.3554e-01, -7.9393e-02],\n",
      "         [ 3.5282e-01, -1.3514e-01,  2.5883e-02,  ..., -1.8680e-03,\n",
      "           3.3134e-01,  7.3185e-02]],\n",
      "\n",
      "        [[-2.4579e-01, -2.1586e-01, -9.0789e-02,  ...,  1.3408e-01,\n",
      "          -2.3614e-01,  1.8570e-01],\n",
      "         [-2.3276e-01,  2.7216e-01, -1.3060e-02,  ...,  1.8279e-01,\n",
      "           1.0944e-01,  1.0101e-01],\n",
      "         [-2.6040e-01, -1.7508e-01, -1.1444e-01,  ...,  1.9388e-01,\n",
      "           2.1115e-01, -9.0381e-02],\n",
      "         ...,\n",
      "         [ 5.9111e-02, -2.8530e-01, -1.6251e-02,  ..., -6.5112e-02,\n",
      "          -2.3222e-01, -2.1906e-01],\n",
      "         [-1.3599e-01, -1.2088e-01, -3.1296e-01,  ...,  1.5053e-01,\n",
      "          -4.6807e-02, -1.1674e-01],\n",
      "         [ 3.1990e-01, -7.2580e-02, -1.5515e-01,  ..., -3.5648e-02,\n",
      "           1.6034e-01,  7.2798e-02]],\n",
      "\n",
      "        [[ 9.2442e-02, -3.4310e-01,  1.1031e-01,  ...,  2.1618e-01,\n",
      "          -4.2010e-02,  3.7008e-01],\n",
      "         [ 8.0871e-03, -2.9349e-01, -3.6082e-02,  ...,  1.4894e-01,\n",
      "           2.7237e-01, -2.7954e-01],\n",
      "         [ 1.5684e-01, -5.3837e-02, -3.1250e-01,  ...,  3.0132e-01,\n",
      "          -4.7357e-02,  3.8393e-02],\n",
      "         ...,\n",
      "         [ 3.0095e-01, -1.1348e-01,  2.0642e-01,  ...,  1.7867e-01,\n",
      "           1.8809e-01, -9.6106e-02],\n",
      "         [ 2.8023e-02,  2.0617e-01,  6.3565e-02,  ..., -1.4353e-01,\n",
      "          -2.8272e-01, -4.6226e-02],\n",
      "         [-2.4642e-01,  5.9845e-02,  1.9929e-01,  ..., -5.7851e-02,\n",
      "          -2.7996e-01, -2.7373e-01]]])\n",
      "74 Parameter containing:\n",
      "tensor([[[-0.2675,  0.1103,  0.2221,  ..., -0.0177, -0.0808, -0.1043],\n",
      "         [ 0.1200,  0.1696, -0.1719,  ..., -0.2440, -0.1567,  0.1943],\n",
      "         [-0.1847,  0.0984,  0.1861,  ...,  0.0033,  0.2209, -0.2644],\n",
      "         ...,\n",
      "         [ 0.2209,  0.2306,  0.2490,  ...,  0.1965,  0.0083,  0.0911],\n",
      "         [ 0.1513, -0.1684,  0.1768,  ..., -0.0050,  0.0660,  0.2391],\n",
      "         [ 0.0968, -0.2990, -0.1052,  ...,  0.2613,  0.0459, -0.2600]],\n",
      "\n",
      "        [[ 0.0800,  0.0520,  0.1625,  ...,  0.1393, -0.2805,  0.1440],\n",
      "         [-0.0922,  0.1230,  0.1178,  ...,  0.2428,  0.0562,  0.0974],\n",
      "         [ 0.2481, -0.1686,  0.2992,  ...,  0.0153,  0.0292,  0.2450],\n",
      "         ...,\n",
      "         [-0.0450,  0.1193,  0.2110,  ..., -0.0514,  0.2093, -0.0679],\n",
      "         [ 0.1620, -0.1128, -0.1094,  ...,  0.2678,  0.1379, -0.2391],\n",
      "         [ 0.0737,  0.1498, -0.1189,  ...,  0.0614,  0.2007,  0.1487]],\n",
      "\n",
      "        [[ 0.0894,  0.0229, -0.2553,  ..., -0.2287,  0.0699,  0.1632],\n",
      "         [-0.0902,  0.2249,  0.1687,  ...,  0.2199, -0.2464, -0.1761],\n",
      "         [ 0.0300, -0.1861, -0.1426,  ..., -0.2100, -0.0071, -0.0078],\n",
      "         ...,\n",
      "         [ 0.2423, -0.2155,  0.2214,  ..., -0.1657,  0.0562, -0.1266],\n",
      "         [-0.0546, -0.2356,  0.0930,  ...,  0.0099, -0.1778,  0.2361],\n",
      "         [-0.2739,  0.1863, -0.0224,  ...,  0.0071, -0.1986, -0.2395]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2318, -0.2594,  0.1589,  ..., -0.1189, -0.2012,  0.0921],\n",
      "         [-0.0379, -0.1044,  0.2647,  ..., -0.0842,  0.0376,  0.1192],\n",
      "         [ 0.0546, -0.2815, -0.1535,  ..., -0.2993,  0.0149,  0.1938],\n",
      "         ...,\n",
      "         [ 0.2137,  0.2932,  0.2795,  ..., -0.0609, -0.1848, -0.2126],\n",
      "         [ 0.0869, -0.0480, -0.3012,  ..., -0.2073,  0.0182, -0.2269],\n",
      "         [-0.0687, -0.2836,  0.0003,  ..., -0.0045,  0.2482,  0.2210]],\n",
      "\n",
      "        [[-0.2895, -0.0093, -0.2712,  ...,  0.1435, -0.0556,  0.2472],\n",
      "         [ 0.1875,  0.0169,  0.1581,  ...,  0.0445, -0.0156,  0.2603],\n",
      "         [ 0.1479, -0.1874,  0.0033,  ..., -0.0604, -0.0141,  0.2383],\n",
      "         ...,\n",
      "         [ 0.1016,  0.1812,  0.0065,  ...,  0.1626,  0.2716,  0.1162],\n",
      "         [-0.0933,  0.1990, -0.2513,  ..., -0.2623, -0.1380,  0.0800],\n",
      "         [-0.2305,  0.0735,  0.2240,  ...,  0.0479,  0.1080, -0.0860]],\n",
      "\n",
      "        [[-0.0309,  0.2535,  0.0527,  ...,  0.1408,  0.1660,  0.1517],\n",
      "         [ 0.2661,  0.0115, -0.1882,  ...,  0.1496,  0.0899, -0.2175],\n",
      "         [ 0.0306,  0.2248,  0.0707,  ...,  0.2748, -0.2782,  0.2730],\n",
      "         ...,\n",
      "         [-0.2051,  0.1986, -0.1308,  ...,  0.0647, -0.0368,  0.1090],\n",
      "         [-0.0509,  0.1893,  0.0632,  ..., -0.2931,  0.0965,  0.2484],\n",
      "         [-0.1603,  0.1762, -0.1378,  ..., -0.2698, -0.2878, -0.1941]]])\n",
      "75 Parameter containing:\n",
      "tensor([[[ 0.0937,  0.0345,  0.1077,  ...,  0.0773,  0.2618, -0.0947],\n",
      "         [ 0.1950,  0.3094, -0.2806,  ..., -0.0678, -0.1899,  0.2606],\n",
      "         [ 0.0174, -0.1859,  0.1988,  ..., -0.2538, -0.1210, -0.2067],\n",
      "         ...,\n",
      "         [-0.1276, -0.0325,  0.1533,  ..., -0.1896,  0.1102,  0.3078],\n",
      "         [-0.2147, -0.0200,  0.2683,  ...,  0.2624, -0.2561, -0.2270],\n",
      "         [ 0.1955,  0.0333,  0.1884,  ..., -0.1503,  0.1793,  0.0177]],\n",
      "\n",
      "        [[-0.2892,  0.1759, -0.0921,  ...,  0.2642,  0.2154,  0.0063],\n",
      "         [-0.2245, -0.2115,  0.2338,  ...,  0.0255,  0.2496,  0.2805],\n",
      "         [ 0.1454,  0.1530, -0.0673,  ..., -0.1072,  0.1312, -0.1560],\n",
      "         ...,\n",
      "         [-0.1465, -0.2919,  0.0121,  ...,  0.0418, -0.1654,  0.3055],\n",
      "         [-0.0403,  0.0185, -0.2663,  ...,  0.3050,  0.1411,  0.1267],\n",
      "         [ 0.1034, -0.1759,  0.0094,  ..., -0.0937, -0.2114, -0.2270]],\n",
      "\n",
      "        [[-0.2422,  0.1889, -0.2324,  ..., -0.0622, -0.1688,  0.1495],\n",
      "         [-0.1762, -0.0872, -0.1565,  ..., -0.0635, -0.1723, -0.0311],\n",
      "         [-0.0793, -0.0952,  0.1783,  ..., -0.0386, -0.0555, -0.2471],\n",
      "         ...,\n",
      "         [-0.0508,  0.0467,  0.0637,  ..., -0.2139, -0.1921,  0.2053],\n",
      "         [-0.2297, -0.2617,  0.1292,  ..., -0.2601,  0.1138, -0.2425],\n",
      "         [ 0.2720,  0.0975,  0.0086,  ..., -0.1557,  0.2231,  0.2027]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1113,  0.0075, -0.1483,  ...,  0.1078, -0.2293,  0.1035],\n",
      "         [ 0.0717, -0.0203, -0.0586,  ...,  0.1657,  0.2304, -0.0090],\n",
      "         [ 0.0102, -0.0688, -0.3058,  ...,  0.2610, -0.0649, -0.1285],\n",
      "         ...,\n",
      "         [-0.0883,  0.2261, -0.2234,  ..., -0.1744, -0.2065, -0.1630],\n",
      "         [-0.1958, -0.2415,  0.1563,  ..., -0.2540,  0.2895, -0.2277],\n",
      "         [-0.0780, -0.0589,  0.1792,  ..., -0.0542, -0.2693,  0.0501]],\n",
      "\n",
      "        [[ 0.2108, -0.1087, -0.0026,  ..., -0.1936,  0.1342,  0.2651],\n",
      "         [-0.0174, -0.1476,  0.2171,  ...,  0.2588, -0.2961,  0.2587],\n",
      "         [-0.2444,  0.1554,  0.2251,  ...,  0.2321, -0.1108,  0.0044],\n",
      "         ...,\n",
      "         [ 0.1527,  0.1574,  0.1922,  ..., -0.1293,  0.0716, -0.0201],\n",
      "         [ 0.0372,  0.0806,  0.0100,  ...,  0.2233, -0.1504,  0.1204],\n",
      "         [ 0.0115, -0.2942, -0.0226,  ..., -0.0075,  0.2007, -0.3106]],\n",
      "\n",
      "        [[ 0.0189,  0.0397,  0.2057,  ..., -0.0915, -0.0392,  0.0484],\n",
      "         [ 0.0388,  0.1354,  0.0583,  ...,  0.2234, -0.2118,  0.1270],\n",
      "         [ 0.2164, -0.2869, -0.3052,  ...,  0.1367,  0.3044,  0.1657],\n",
      "         ...,\n",
      "         [-0.0940, -0.1266, -0.0897,  ...,  0.1287,  0.0817,  0.2540],\n",
      "         [-0.2484, -0.0260,  0.1621,  ...,  0.0918, -0.2314, -0.1740],\n",
      "         [-0.1159, -0.0169, -0.2296,  ...,  0.0991, -0.1051, -0.2214]]])\n",
      "76 Parameter containing:\n",
      "tensor([[[-0.0892,  0.1465,  0.1829,  ...,  0.2251, -0.1884, -0.2495],\n",
      "         [ 0.1450, -0.1278, -0.2928,  ..., -0.2439,  0.1665,  0.2512],\n",
      "         [ 0.2205,  0.0689,  0.1932,  ...,  0.1089, -0.1278,  0.0949],\n",
      "         ...,\n",
      "         [-0.1229, -0.2904, -0.1521,  ..., -0.0029,  0.1664,  0.1016],\n",
      "         [-0.0603, -0.0521,  0.1864,  ...,  0.1364,  0.0789, -0.2689],\n",
      "         [-0.1473,  0.1089, -0.2106,  ...,  0.0357,  0.2535,  0.0568]],\n",
      "\n",
      "        [[-0.0057, -0.0729, -0.2892,  ..., -0.0377,  0.2142, -0.2226],\n",
      "         [ 0.2464, -0.2498, -0.1174,  ..., -0.2826, -0.0535, -0.0175],\n",
      "         [ 0.1642,  0.2653,  0.0755,  ...,  0.1339,  0.1221,  0.1997],\n",
      "         ...,\n",
      "         [ 0.2227,  0.1281,  0.2698,  ...,  0.1579, -0.1159, -0.3093],\n",
      "         [-0.0808,  0.1626, -0.0676,  ..., -0.1643, -0.0889, -0.1843],\n",
      "         [ 0.1125, -0.1805,  0.0282,  ...,  0.0045,  0.2511, -0.1594]],\n",
      "\n",
      "        [[ 0.2385, -0.1328, -0.2039,  ...,  0.1942, -0.2994, -0.2171],\n",
      "         [ 0.1127,  0.0915,  0.2250,  ..., -0.2239, -0.0128,  0.2668],\n",
      "         [ 0.1786,  0.1721,  0.2425,  ..., -0.3113, -0.1591, -0.1862],\n",
      "         ...,\n",
      "         [ 0.1653, -0.3108, -0.2520,  ...,  0.1700, -0.1292, -0.1940],\n",
      "         [-0.2600,  0.2194, -0.1952,  ..., -0.2366, -0.1258, -0.2600],\n",
      "         [ 0.1808, -0.1726,  0.0596,  ..., -0.0869, -0.2773,  0.1575]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1701,  0.0182, -0.0392,  ..., -0.0090, -0.2245, -0.2575],\n",
      "         [ 0.2444,  0.2015,  0.1479,  ..., -0.2397,  0.2317, -0.1659],\n",
      "         [-0.0046,  0.1537,  0.2419,  ..., -0.0466,  0.3068, -0.2187],\n",
      "         ...,\n",
      "         [-0.2328, -0.1712,  0.2864,  ...,  0.0305, -0.2386,  0.1502],\n",
      "         [ 0.2719,  0.2398,  0.0489,  ..., -0.2329, -0.2642,  0.0273],\n",
      "         [-0.1695,  0.2327, -0.2175,  ...,  0.2483, -0.2772,  0.1326]],\n",
      "\n",
      "        [[-0.2910, -0.2582, -0.2689,  ..., -0.0585,  0.2954,  0.2875],\n",
      "         [ 0.1993, -0.1586, -0.2957,  ..., -0.1921,  0.1522,  0.1071],\n",
      "         [-0.1418, -0.1501,  0.0282,  ..., -0.0107,  0.0857,  0.0910],\n",
      "         ...,\n",
      "         [ 0.1642,  0.2733, -0.1741,  ..., -0.0286, -0.0615,  0.0881],\n",
      "         [ 0.0938, -0.0983,  0.2709,  ...,  0.0563,  0.0472,  0.1891],\n",
      "         [-0.0816, -0.0797, -0.2183,  ..., -0.2384,  0.0796,  0.2575]],\n",
      "\n",
      "        [[-0.1212, -0.2578,  0.2768,  ...,  0.1926, -0.2832,  0.0635],\n",
      "         [-0.0695, -0.1452, -0.1704,  ..., -0.0607,  0.0527,  0.1731],\n",
      "         [-0.0628,  0.2672,  0.1422,  ..., -0.1133,  0.0769, -0.1355],\n",
      "         ...,\n",
      "         [-0.2623, -0.1671,  0.2185,  ...,  0.0165, -0.0297,  0.1140],\n",
      "         [ 0.2725, -0.0049,  0.0922,  ...,  0.1894, -0.0619, -0.0044],\n",
      "         [ 0.0160, -0.0816, -0.2890,  ..., -0.0594,  0.1597, -0.0796]]])\n",
      "77 Parameter containing:\n",
      "tensor([[[-0.2823,  0.1988,  0.1119,  ...,  0.0269,  0.0992, -0.2675],\n",
      "         [ 0.0725, -0.2051,  0.1324,  ..., -0.1818,  0.2529, -0.0347],\n",
      "         [-0.1438,  0.0420, -0.0838,  ...,  0.2112,  0.1965,  0.0205],\n",
      "         ...,\n",
      "         [-0.2318, -0.2046, -0.0276,  ..., -0.1248, -0.2672, -0.0585],\n",
      "         [ 0.1144,  0.0903,  0.0308,  ...,  0.0601, -0.2071,  0.2068],\n",
      "         [-0.1647,  0.2050,  0.2242,  ...,  0.0629,  0.2355, -0.1400]],\n",
      "\n",
      "        [[ 0.2200,  0.2228,  0.1134,  ..., -0.2076,  0.2778, -0.0777],\n",
      "         [-0.0886, -0.2811,  0.0010,  ..., -0.2924,  0.1309, -0.1265],\n",
      "         [-0.1236, -0.1506,  0.1243,  ..., -0.0853,  0.2206,  0.0501],\n",
      "         ...,\n",
      "         [ 0.2131, -0.2840,  0.2832,  ..., -0.1933,  0.0467,  0.2835],\n",
      "         [-0.0959, -0.2071, -0.2637,  ...,  0.2794,  0.1086,  0.1528],\n",
      "         [ 0.2286, -0.0757,  0.0936,  ...,  0.1826, -0.2443, -0.0117]],\n",
      "\n",
      "        [[ 0.3142, -0.1451, -0.0299,  ..., -0.0610,  0.1045,  0.2581],\n",
      "         [-0.0443,  0.0564, -0.2829,  ..., -0.0008,  0.2566, -0.1570],\n",
      "         [-0.0345, -0.2718, -0.0426,  ..., -0.0955, -0.2533,  0.2729],\n",
      "         ...,\n",
      "         [-0.1024, -0.1895, -0.2159,  ..., -0.2106,  0.0802, -0.1202],\n",
      "         [ 0.2622, -0.1204,  0.0783,  ...,  0.0998,  0.1770, -0.3153],\n",
      "         [ 0.2789, -0.2519,  0.1294,  ...,  0.1114,  0.0463,  0.2269]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.1443,  0.0528, -0.2505,  ...,  0.2226, -0.1362, -0.1506],\n",
      "         [ 0.2056,  0.0131,  0.0260,  ...,  0.0586,  0.1121, -0.2565],\n",
      "         [ 0.0289,  0.2249, -0.1484,  ..., -0.2445, -0.2740,  0.3023],\n",
      "         ...,\n",
      "         [-0.2113,  0.1991, -0.0407,  ..., -0.1508, -0.1172,  0.2689],\n",
      "         [ 0.1725,  0.2105, -0.0628,  ..., -0.1574, -0.0684, -0.1917],\n",
      "         [-0.2813, -0.0606,  0.1938,  ...,  0.0969, -0.2230, -0.0304]],\n",
      "\n",
      "        [[ 0.1647, -0.1608,  0.2479,  ...,  0.1248, -0.1625,  0.3030],\n",
      "         [-0.0321, -0.3080,  0.2342,  ...,  0.3007,  0.1178, -0.2307],\n",
      "         [ 0.0365, -0.0985, -0.1172,  ...,  0.1844,  0.1907, -0.0979],\n",
      "         ...,\n",
      "         [-0.0174, -0.0250,  0.2204,  ...,  0.0696, -0.1566,  0.1099],\n",
      "         [-0.2895, -0.1048,  0.2794,  ..., -0.0427,  0.2360, -0.2293],\n",
      "         [-0.2546,  0.0059,  0.2777,  ..., -0.1403,  0.1835, -0.1937]],\n",
      "\n",
      "        [[-0.2114, -0.1378,  0.0177,  ..., -0.0031, -0.2431,  0.0690],\n",
      "         [ 0.0534,  0.0810,  0.1017,  ..., -0.2342, -0.1496,  0.1931],\n",
      "         [-0.2738, -0.0076, -0.2741,  ...,  0.0368, -0.1228,  0.0317],\n",
      "         ...,\n",
      "         [-0.0531, -0.2757, -0.0432,  ..., -0.1682, -0.2080, -0.2234],\n",
      "         [ 0.2024, -0.1896,  0.0760,  ..., -0.0239, -0.1289,  0.0896],\n",
      "         [-0.0761,  0.2681,  0.1842,  ..., -0.2928, -0.2935,  0.0718]]])\n",
      "78 Parameter containing:\n",
      "tensor([[[-0.0647, -0.0671,  0.1857,  ...,  0.1909,  0.1837,  0.2869],\n",
      "         [-0.1673, -0.0952,  0.0692,  ...,  0.0684,  0.1047,  0.1218],\n",
      "         [-0.0919, -0.0649,  0.0207,  ...,  0.0673, -0.2341, -0.0654],\n",
      "         ...,\n",
      "         [ 0.1546,  0.2414,  0.2612,  ...,  0.0891, -0.1163, -0.0009],\n",
      "         [ 0.1716,  0.1429, -0.0485,  ..., -0.2140, -0.0454, -0.2639],\n",
      "         [-0.1576, -0.0801,  0.2181,  ..., -0.2062,  0.1071,  0.1231]],\n",
      "\n",
      "        [[ 0.1297,  0.2019, -0.0148,  ..., -0.1218,  0.2210, -0.1742],\n",
      "         [-0.1128, -0.1295,  0.1827,  ...,  0.2694, -0.1699,  0.1741],\n",
      "         [ 0.2869, -0.2378, -0.1863,  ...,  0.2957,  0.2822, -0.1602],\n",
      "         ...,\n",
      "         [-0.2690,  0.0566, -0.2468,  ...,  0.0992,  0.1791,  0.1399],\n",
      "         [-0.3155,  0.2008, -0.0731,  ...,  0.0997,  0.2908, -0.1495],\n",
      "         [-0.1930,  0.2599, -0.0107,  ...,  0.0285,  0.1439, -0.2520]],\n",
      "\n",
      "        [[ 0.0217, -0.0345, -0.1864,  ...,  0.0606,  0.1991,  0.2892],\n",
      "         [ 0.2527, -0.1152,  0.1246,  ...,  0.1602, -0.0134, -0.1541],\n",
      "         [ 0.1715,  0.1609, -0.1159,  ...,  0.1491,  0.0935,  0.0679],\n",
      "         ...,\n",
      "         [ 0.1559,  0.1169, -0.2906,  ...,  0.2013,  0.2464, -0.2589],\n",
      "         [ 0.0368,  0.2385, -0.0464,  ...,  0.0545,  0.1439, -0.2269],\n",
      "         [-0.0752,  0.1029, -0.1301,  ..., -0.1850, -0.2084, -0.2444]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0959,  0.2239, -0.0923,  ...,  0.1983,  0.2578,  0.2738],\n",
      "         [-0.0221,  0.2655,  0.2607,  ...,  0.1404, -0.1807, -0.1671],\n",
      "         [-0.0741,  0.0623,  0.1501,  ...,  0.0886,  0.3004,  0.0780],\n",
      "         ...,\n",
      "         [ 0.1040,  0.0408,  0.0045,  ..., -0.0851, -0.2596, -0.2577],\n",
      "         [-0.2678, -0.1304,  0.0763,  ...,  0.1986,  0.1445,  0.2159],\n",
      "         [-0.1833, -0.2583,  0.2280,  ..., -0.1876,  0.1818,  0.0630]],\n",
      "\n",
      "        [[ 0.0240, -0.0445,  0.0067,  ...,  0.1766,  0.1093, -0.0604],\n",
      "         [ 0.0421,  0.1263, -0.0422,  ..., -0.2173,  0.0861, -0.1464],\n",
      "         [ 0.2243,  0.1113,  0.2569,  ..., -0.2876, -0.1659, -0.1137],\n",
      "         ...,\n",
      "         [-0.1024,  0.1054,  0.2857,  ...,  0.1057,  0.1770, -0.1446],\n",
      "         [ 0.2273,  0.2231, -0.0462,  ..., -0.2023,  0.2721,  0.1386],\n",
      "         [ 0.1372,  0.2516,  0.1495,  ..., -0.1877,  0.0521, -0.2703]],\n",
      "\n",
      "        [[-0.2906,  0.1369,  0.0495,  ...,  0.2357, -0.2766, -0.1131],\n",
      "         [-0.2392,  0.0337, -0.2260,  ...,  0.2941,  0.2653,  0.2930],\n",
      "         [ 0.0964, -0.1455,  0.1806,  ..., -0.1224,  0.1299,  0.1799],\n",
      "         ...,\n",
      "         [ 0.2015, -0.2252, -0.1957,  ...,  0.1937,  0.2117, -0.1267],\n",
      "         [ 0.1212,  0.0782,  0.2708,  ...,  0.2494,  0.0167, -0.0446],\n",
      "         [-0.2516, -0.2932, -0.2352,  ...,  0.3285,  0.0748, -0.1187]]])\n",
      "79 Parameter containing:\n",
      "tensor([[[ 0.2327, -0.2515, -0.2751,  ..., -0.1298,  0.1987, -0.0825],\n",
      "         [ 0.0335, -0.1030, -0.1451,  ..., -0.1764,  0.0960, -0.0629],\n",
      "         [-0.1044, -0.1311, -0.3187,  ...,  0.0609,  0.1430, -0.1034],\n",
      "         ...,\n",
      "         [ 0.0973,  0.0398,  0.1668,  ..., -0.0839, -0.2742, -0.2347],\n",
      "         [-0.3016, -0.0056, -0.2437,  ...,  0.2248,  0.1478,  0.2444],\n",
      "         [ 0.1723,  0.1727,  0.0768,  ..., -0.0635,  0.0584,  0.0098]],\n",
      "\n",
      "        [[ 0.2324,  0.2424, -0.1073,  ..., -0.2053, -0.0580, -0.0046],\n",
      "         [-0.1837, -0.0144,  0.1214,  ..., -0.0915, -0.1108,  0.2938],\n",
      "         [ 0.1354, -0.0809, -0.1538,  ..., -0.2447,  0.2357,  0.0235],\n",
      "         ...,\n",
      "         [ 0.2401, -0.2494, -0.0269,  ...,  0.2913,  0.0941,  0.1489],\n",
      "         [-0.0594, -0.0493, -0.0937,  ...,  0.1967,  0.1386,  0.1252],\n",
      "         [ 0.2344, -0.1385, -0.2894,  ..., -0.0590, -0.0365,  0.0453]],\n",
      "\n",
      "        [[ 0.0916,  0.2254,  0.2867,  ...,  0.1836, -0.2647, -0.0229],\n",
      "         [-0.1363,  0.0474, -0.0099,  ...,  0.0481, -0.2216, -0.0150],\n",
      "         [ 0.1248,  0.2266, -0.2399,  ...,  0.2722, -0.2196, -0.0527],\n",
      "         ...,\n",
      "         [ 0.0788,  0.2935,  0.0107,  ...,  0.1446, -0.3036, -0.0379],\n",
      "         [-0.0643,  0.1726, -0.1701,  ..., -0.2836, -0.1458,  0.0180],\n",
      "         [ 0.2217, -0.0877, -0.1881,  ..., -0.2116,  0.2012,  0.1637]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2780,  0.2278, -0.2058,  ..., -0.1216, -0.0576, -0.2036],\n",
      "         [-0.0200, -0.1611,  0.3075,  ..., -0.2512, -0.0316, -0.0941],\n",
      "         [-0.1956, -0.2498, -0.2627,  ..., -0.1479,  0.2137, -0.3238],\n",
      "         ...,\n",
      "         [-0.2730, -0.0274, -0.1905,  ...,  0.0230, -0.0243,  0.2434],\n",
      "         [-0.1858,  0.0039, -0.0906,  ..., -0.2381,  0.1705, -0.2152],\n",
      "         [-0.1832, -0.0392, -0.0442,  ..., -0.2640,  0.2503, -0.1482]],\n",
      "\n",
      "        [[ 0.2213, -0.1363, -0.2709,  ..., -0.1307, -0.0415,  0.1748],\n",
      "         [ 0.1779, -0.2401, -0.1257,  ..., -0.1654,  0.1983, -0.2835],\n",
      "         [ 0.2393,  0.0052, -0.0112,  ..., -0.0724,  0.0224,  0.2711],\n",
      "         ...,\n",
      "         [ 0.2503,  0.3117, -0.2038,  ..., -0.1263, -0.1128, -0.1371],\n",
      "         [-0.1490, -0.3029,  0.0056,  ..., -0.2340,  0.0384, -0.0756],\n",
      "         [ 0.0238,  0.1037,  0.1043,  ...,  0.2509,  0.0177,  0.0774]],\n",
      "\n",
      "        [[-0.2436, -0.2106, -0.2556,  ...,  0.3010, -0.2604,  0.0543],\n",
      "         [ 0.2483, -0.0875,  0.1114,  ..., -0.1326, -0.0506,  0.2455],\n",
      "         [ 0.1280, -0.0187, -0.2809,  ...,  0.0204,  0.2070,  0.2844],\n",
      "         ...,\n",
      "         [ 0.2933,  0.0044, -0.2137,  ...,  0.0251,  0.0350, -0.0221],\n",
      "         [ 0.2308, -0.2166, -0.1263,  ..., -0.0900, -0.2921, -0.2069],\n",
      "         [ 0.2787,  0.1146, -0.0979,  ..., -0.1606,  0.0742,  0.3107]]])\n",
      "80 Parameter containing:\n",
      "tensor([1.0744, 1.0529, 1.0287, 1.0872, 1.0026, 1.0101, 1.0500, 1.0292])\n",
      "81 Parameter containing:\n",
      "tensor([1.1163, 1.0204, 1.0233, 1.0280, 1.0435, 1.1034, 1.0645, 1.0506])\n",
      "82 Parameter containing:\n",
      "tensor([0.9975, 0.9975, 0.9975, 0.9975, 0.9975, 0.9975, 0.9975, 0.9975])\n",
      "83 Parameter containing:\n",
      "tensor([0.9965, 0.9950, 1.0058, 0.9816, 1.0052, 0.9742, 0.9893, 1.0083])\n",
      "84 Parameter containing:\n",
      "tensor([[-0.1592, -0.1084,  0.1780,  ...,  0.0032,  0.0318, -0.0364],\n",
      "        [ 0.1544,  0.1429, -0.1995,  ..., -0.0691, -0.0203,  0.0285],\n",
      "        [ 0.1569,  0.1463, -0.1124,  ...,  0.0056, -0.0560,  0.1071],\n",
      "        ...,\n",
      "        [-0.0613, -0.0060, -0.0210,  ...,  0.1056,  0.0541, -0.0975],\n",
      "        [-0.0520, -0.0445,  0.0200,  ...,  0.0826, -0.0157, -0.0448],\n",
      "        [ 0.0521,  0.0105, -0.0275,  ..., -0.0291, -0.0402, -0.0594]],\n",
      "       requires_grad=True)\n",
      "85 Parameter containing:\n",
      "tensor([-0.0591, -0.0287,  0.0421,  0.0278, -0.0287, -0.0603,  0.0340, -0.0046,\n",
      "        -0.0247, -0.0432, -0.0502, -0.0390, -0.0471, -0.0390, -0.0227,  0.0122,\n",
      "         0.0460,  0.0474, -0.0251, -0.0096, -0.0041,  0.0594,  0.0012, -0.0073,\n",
      "        -0.0392, -0.0619,  0.0213, -0.0264,  0.0473, -0.0595,  0.0211, -0.0505,\n",
      "        -0.0106, -0.0187,  0.0028, -0.0119, -0.0475, -0.0063,  0.0027,  0.0247,\n",
      "         0.0577,  0.0246,  0.0409,  0.0513, -0.0247,  0.0123, -0.0032,  0.0419,\n",
      "        -0.0266, -0.0452, -0.0285,  0.0258, -0.0570,  0.0076, -0.0167, -0.0106,\n",
      "        -0.0160, -0.0270,  0.0481, -0.0613, -0.0602, -0.0592, -0.0610,  0.0260,\n",
      "         0.0333, -0.0362, -0.0434,  0.0478,  0.0518, -0.0517,  0.0409, -0.0023,\n",
      "        -0.0074,  0.0577,  0.0536, -0.0413,  0.0316,  0.0510, -0.0456,  0.0184,\n",
      "        -0.0499, -0.0489, -0.0291,  0.0054, -0.0357, -0.0617,  0.0189,  0.0031,\n",
      "         0.0036, -0.0007, -0.0417,  0.0335,  0.0387, -0.0165, -0.0597, -0.0050,\n",
      "         0.0368,  0.0310,  0.0313, -0.0458,  0.0523,  0.0321, -0.0504, -0.0101,\n",
      "        -0.0504, -0.0082,  0.0607, -0.0068,  0.0220, -0.0169,  0.0226,  0.0079,\n",
      "         0.0341, -0.0438,  0.0140,  0.0108,  0.0285,  0.0399, -0.0475, -0.0044,\n",
      "         0.0125,  0.0420, -0.0454,  0.0175, -0.0074, -0.0209,  0.0101,  0.0176],\n",
      "       requires_grad=True)\n",
      "86 Parameter containing:\n",
      "tensor([[ 0.0316,  0.0583, -0.0070,  ..., -0.0328,  0.0269,  0.0420],\n",
      "        [-0.0282, -0.0064,  0.0228,  ..., -0.0131,  0.0405,  0.0259],\n",
      "        [-0.0632,  0.0141, -0.0136,  ..., -0.0472, -0.0249, -0.0896],\n",
      "        ...,\n",
      "        [-0.0870, -0.0245,  0.0009,  ..., -0.0086,  0.0546, -0.0536],\n",
      "        [-0.0416,  0.0526, -0.0336,  ..., -0.0403, -0.0439,  0.0004],\n",
      "        [ 0.0565,  0.0089, -0.0121,  ...,  0.0255,  0.0195, -0.0304]],\n",
      "       requires_grad=True)\n",
      "87 Parameter containing:\n",
      "tensor([ 0.0485, -0.0113,  0.0206, -0.0103,  0.0245, -0.0486, -0.0579,  0.0118,\n",
      "         0.0097, -0.0474, -0.0373,  0.0154, -0.0299,  0.0063, -0.0617, -0.0384,\n",
      "        -0.0077,  0.0409,  0.0437, -0.0497,  0.0444,  0.0209, -0.0428, -0.0522,\n",
      "        -0.0159,  0.0516,  0.0558, -0.0440, -0.0396,  0.0124,  0.0475,  0.0449,\n",
      "         0.0613,  0.0138, -0.0447,  0.0177, -0.0543, -0.0446, -0.0180,  0.0615,\n",
      "         0.0354,  0.0342,  0.0408, -0.0109, -0.0512, -0.0366,  0.0518, -0.0170,\n",
      "        -0.0464,  0.0606, -0.0469, -0.0061, -0.0477, -0.0156,  0.0555, -0.0147,\n",
      "        -0.0522, -0.0017,  0.0322,  0.0204,  0.0238,  0.0083, -0.0020, -0.0430,\n",
      "         0.0124,  0.0159, -0.0003,  0.0274, -0.0371, -0.0508,  0.0376, -0.0455,\n",
      "        -0.0618, -0.0294, -0.0212,  0.0340,  0.0205,  0.0457, -0.0433, -0.0330,\n",
      "         0.0375, -0.0067,  0.0494, -0.0339,  0.0186,  0.0178, -0.0401, -0.0494,\n",
      "        -0.0552, -0.0125, -0.0048, -0.0034,  0.0146, -0.0405, -0.0422, -0.0092,\n",
      "        -0.0166, -0.0169, -0.0345, -0.0446, -0.0455,  0.0082, -0.0594,  0.0028,\n",
      "         0.0074, -0.0321, -0.0118, -0.0460,  0.0293, -0.0156, -0.0310, -0.0100,\n",
      "        -0.0454, -0.0229, -0.0427, -0.0589,  0.0038, -0.0572, -0.0435, -0.0580,\n",
      "        -0.0308,  0.0018, -0.0489, -0.0374, -0.0299, -0.0481,  0.0285, -0.0453],\n",
      "       requires_grad=True)\n",
      "88 Parameter containing:\n",
      "tensor([[-0.0484,  0.0231, -0.0696,  ..., -0.0131, -0.0039,  0.0124],\n",
      "        [ 0.0239,  0.0817, -0.0791,  ..., -0.0539, -0.0390,  0.0291],\n",
      "        [ 0.0586,  0.0490, -0.0413,  ...,  0.0487, -0.0030,  0.0293],\n",
      "        ...,\n",
      "        [ 0.0530,  0.0386, -0.0647,  ...,  0.0452,  0.0295, -0.0309],\n",
      "        [-0.0062,  0.0308, -0.0235,  ...,  0.0395,  0.0323,  0.0246],\n",
      "        [ 0.0665, -0.0028,  0.0345,  ..., -0.0332, -0.0743,  0.0737]],\n",
      "       requires_grad=True)\n",
      "89 Parameter containing:\n",
      "tensor([ 1.8777e-02, -1.5801e-03, -8.8835e-04,  5.7659e-02, -4.7663e-03,\n",
      "        -2.6561e-02,  1.1431e-02,  1.9356e-03, -1.5525e-03,  4.6726e-02,\n",
      "         2.0639e-03, -3.5796e-02,  2.0654e-02, -4.6040e-03, -2.0460e-02,\n",
      "        -5.1741e-03, -6.5258e-02,  8.7601e-03, -7.2111e-02, -3.9572e-02,\n",
      "         3.0697e-02,  2.5783e-02, -2.2033e-02,  4.1602e-02, -6.6316e-02,\n",
      "         8.4771e-03,  6.8919e-02,  7.0120e-02, -2.1084e-02, -8.4025e-03,\n",
      "        -5.4098e-02,  1.0875e-03, -8.4368e-03, -2.5068e-03,  2.6515e-02,\n",
      "        -5.1638e-02, -3.5011e-02,  1.6534e-02, -2.7974e-02, -2.0533e-02,\n",
      "         3.9549e-02,  4.6133e-02, -1.2083e-02, -4.4033e-02, -1.1675e-02,\n",
      "        -4.8277e-02, -2.0410e-02, -1.7261e-02, -3.5560e-02,  2.7277e-02,\n",
      "        -2.7343e-02, -5.5543e-02, -2.2322e-02,  1.0997e-02,  7.1514e-02,\n",
      "        -2.5499e-02, -1.4819e-02, -4.2874e-02,  1.3429e-02,  6.0943e-02,\n",
      "        -7.7186e-02, -9.0327e-03, -2.1362e-02,  3.5282e-02, -4.6018e-02,\n",
      "         3.6986e-02,  6.1420e-02, -2.0760e-02,  6.3208e-02, -2.9884e-02,\n",
      "         3.2357e-02,  5.1163e-02,  6.7313e-02, -4.3402e-02,  1.5536e-02,\n",
      "         3.4556e-02, -3.4951e-02, -5.3587e-02,  6.8152e-02, -5.1834e-02,\n",
      "        -2.6688e-02, -6.4931e-02,  4.4283e-03,  3.1573e-02, -4.2487e-02,\n",
      "         7.5101e-02, -3.2939e-02,  5.5193e-02,  1.4219e-02, -4.8217e-02,\n",
      "        -1.2459e-02, -1.0369e-03,  6.3561e-02,  5.2622e-03,  4.3058e-02,\n",
      "         3.8404e-02, -1.0450e-02,  4.1449e-02, -1.9689e-02, -5.2052e-05,\n",
      "        -2.8929e-02, -2.2746e-03, -7.2189e-04, -5.4692e-02, -3.6398e-03,\n",
      "         3.3191e-02,  4.9831e-02, -5.4418e-02, -5.7220e-02, -1.6533e-02,\n",
      "         2.7071e-02, -4.5935e-02,  3.4721e-02, -6.9366e-02, -4.4663e-02,\n",
      "        -4.0006e-02,  2.7135e-02,  1.7475e-03, -5.5838e-02, -9.4639e-03,\n",
      "         3.1103e-02, -1.2797e-02, -2.6857e-02,  4.2520e-02, -3.5160e-02,\n",
      "         2.8349e-02, -7.7470e-03,  7.8906e-02], requires_grad=True)\n",
      "90 Parameter containing:\n",
      "tensor([[ 0.0603, -0.0167, -0.0294,  ...,  0.0384,  0.0779, -0.0017],\n",
      "        [ 0.0220, -0.0426,  0.0445,  ..., -0.0193,  0.0937, -0.0332],\n",
      "        [ 0.0789,  0.0009, -0.0537,  ..., -0.0018,  0.0488,  0.0885],\n",
      "        ...,\n",
      "        [ 0.0467, -0.0663, -0.0182,  ..., -0.0014,  0.0031, -0.0693],\n",
      "        [ 0.0174,  0.0496, -0.0704,  ..., -0.1039,  0.0352,  0.0722],\n",
      "        [ 0.0270,  0.0747, -0.0087,  ...,  0.0527,  0.0244, -0.0239]],\n",
      "       requires_grad=True)\n",
      "91 Parameter containing:\n",
      "tensor([-0.0639,  0.0255,  0.0246, -0.0130, -0.0314,  0.0374, -0.0113,  0.0327,\n",
      "         0.0395, -0.0020, -0.0171,  0.0058,  0.0314,  0.0547, -0.0257,  0.0265,\n",
      "         0.0009, -0.0195, -0.0082, -0.0411,  0.0110,  0.0005,  0.0244, -0.0042,\n",
      "         0.0309, -0.0112,  0.0833,  0.0017,  0.0093,  0.0351,  0.0003,  0.0495,\n",
      "        -0.0888, -0.0163,  0.0192,  0.0884, -0.0422,  0.0153,  0.0214,  0.0597,\n",
      "        -0.0091,  0.0543, -0.0819, -0.0303,  0.0013,  0.0289, -0.0566, -0.0693,\n",
      "         0.0161, -0.0373,  0.0127, -0.0630,  0.0018,  0.0059,  0.0156,  0.0488,\n",
      "        -0.0053, -0.0208, -0.0470, -0.0082, -0.0318,  0.0360, -0.0283,  0.0177,\n",
      "        -0.0106, -0.0469,  0.0673,  0.0522,  0.0045, -0.0607,  0.0737, -0.0279,\n",
      "        -0.0318,  0.0273, -0.0785, -0.0857,  0.0212,  0.0653,  0.0420,  0.0438,\n",
      "        -0.0213,  0.0438, -0.0926, -0.0003, -0.0244,  0.0461, -0.0537, -0.0427,\n",
      "        -0.0548,  0.0175, -0.0202, -0.0679,  0.0385,  0.0104,  0.0104,  0.0379,\n",
      "        -0.0211,  0.0074,  0.0055, -0.0362,  0.0278,  0.0048, -0.0084,  0.0663,\n",
      "        -0.0590,  0.0113,  0.0433, -0.0344,  0.0057,  0.0421,  0.0625,  0.0521,\n",
      "        -0.0560,  0.0499, -0.0434, -0.0593, -0.0224,  0.0063,  0.0016, -0.0428,\n",
      "        -0.0526, -0.0460, -0.0245,  0.0056, -0.0034, -0.0241,  0.0627,  0.0434],\n",
      "       requires_grad=True)\n",
      "92 Parameter containing:\n",
      "tensor([[ 0.0096, -0.0870,  0.0061,  ..., -0.0460,  0.0525, -0.0111],\n",
      "        [-0.0002, -0.0503,  0.0664,  ..., -0.0188, -0.0527,  0.0099],\n",
      "        [ 0.0213,  0.0117, -0.0673,  ...,  0.0655,  0.0109,  0.0529],\n",
      "        ...,\n",
      "        [ 0.0815,  0.0907, -0.0108,  ..., -0.0766, -0.0398,  0.0256],\n",
      "        [ 0.0347,  0.0166, -0.0201,  ..., -0.0424, -0.0039,  0.0464],\n",
      "        [ 0.0313,  0.0247, -0.0349,  ...,  0.0517, -0.0485, -0.0041]],\n",
      "       requires_grad=True)\n",
      "93 Parameter containing:\n",
      "tensor([ 0.0183, -0.0733,  0.0502,  0.0327, -0.0020, -0.0028, -0.0706,  0.0264,\n",
      "         0.0364,  0.0289, -0.0416, -0.0494, -0.0074,  0.0207,  0.0180,  0.0456,\n",
      "         0.0455, -0.0145,  0.0111, -0.0340, -0.0098,  0.0031,  0.0069,  0.0360,\n",
      "        -0.0389,  0.0119, -0.0033,  0.0022, -0.0446,  0.0675, -0.0278, -0.0299,\n",
      "         0.0120,  0.0265,  0.0342, -0.0665,  0.0298,  0.0184, -0.0392,  0.0213,\n",
      "         0.0447,  0.0260, -0.0541, -0.0112, -0.0881,  0.0189,  0.0306,  0.0051,\n",
      "        -0.0449, -0.0139, -0.0313,  0.0158,  0.0214, -0.0214,  0.0332,  0.0043,\n",
      "        -0.0189,  0.0156, -0.0614, -0.0213,  0.0338,  0.0049,  0.0137,  0.0577,\n",
      "         0.0599, -0.0192,  0.0283,  0.0380,  0.0311, -0.0584, -0.0612, -0.0389,\n",
      "         0.0568,  0.0375,  0.0400, -0.0267,  0.0578, -0.0047, -0.0408,  0.0203,\n",
      "        -0.0200, -0.0503, -0.0244,  0.0372,  0.0635, -0.0119,  0.0440, -0.0240,\n",
      "         0.0760,  0.0522,  0.0360, -0.0551,  0.0459, -0.0430, -0.0590, -0.0253,\n",
      "        -0.0424,  0.0550,  0.0358, -0.0412,  0.0625, -0.0241,  0.0170, -0.0029,\n",
      "         0.0156, -0.0305,  0.0668,  0.0305,  0.0651,  0.0490,  0.0174,  0.0107,\n",
      "         0.0308, -0.0655, -0.0779,  0.0635,  0.0292,  0.0230, -0.0628, -0.0212,\n",
      "        -0.0224,  0.0302,  0.0099,  0.0261,  0.0047,  0.0363,  0.0712, -0.0732],\n",
      "       requires_grad=True)\n",
      "94 Parameter containing:\n",
      "tensor([[-0.0252,  0.0266, -0.0152,  ..., -0.0109, -0.0792, -0.0233],\n",
      "        [-0.0048,  0.0201,  0.0402,  ...,  0.0440,  0.0665, -0.0119],\n",
      "        [-0.0035,  0.0855,  0.0435,  ..., -0.0486,  0.0302,  0.0035],\n",
      "        ...,\n",
      "        [-0.0140,  0.0576,  0.0270,  ...,  0.0003, -0.0367,  0.0350],\n",
      "        [ 0.0352,  0.0495, -0.0363,  ..., -0.0643, -0.0384, -0.0437],\n",
      "        [-0.0112,  0.0416, -0.0710,  ..., -0.0382,  0.0395, -0.0484]],\n",
      "       requires_grad=True)\n",
      "95 Parameter containing:\n",
      "tensor([ 0.0270, -0.0200, -0.0569,  0.0626, -0.0034,  0.0037,  0.0686,  0.0703,\n",
      "        -0.0369, -0.0254,  0.0735, -0.0518,  0.0624,  0.0180,  0.0534,  0.0355,\n",
      "        -0.0228, -0.0224,  0.0118,  0.0313,  0.0252, -0.0012, -0.0656, -0.0241,\n",
      "        -0.0029, -0.0558, -0.0118, -0.0447, -0.0187,  0.0567, -0.0529, -0.0054,\n",
      "        -0.0582,  0.0218, -0.0642, -0.0371,  0.0270, -0.0481,  0.0397, -0.0086,\n",
      "        -0.0567, -0.0160,  0.0665, -0.0441, -0.0242,  0.0494,  0.0345,  0.0541,\n",
      "        -0.0007, -0.0411,  0.0016, -0.0362,  0.0537,  0.0441, -0.0606, -0.0446,\n",
      "        -0.0135,  0.0343,  0.0855,  0.0611,  0.0384, -0.0011, -0.0199, -0.0474,\n",
      "         0.0356, -0.0008, -0.0285, -0.0665,  0.0133, -0.0744,  0.0176, -0.0571,\n",
      "        -0.0268,  0.0210,  0.0426, -0.0175, -0.0055, -0.0560,  0.0331, -0.0366,\n",
      "         0.0369, -0.0646,  0.0158,  0.0373, -0.0081,  0.0143,  0.0542,  0.0274,\n",
      "         0.0459,  0.0131, -0.0365,  0.0705,  0.0008, -0.0311,  0.0008, -0.0326,\n",
      "         0.0259,  0.0120, -0.0210,  0.0191,  0.0023, -0.0331, -0.0338,  0.0260,\n",
      "        -0.0350,  0.0312,  0.0023,  0.0422, -0.0310,  0.0479, -0.0481, -0.0246,\n",
      "         0.0577,  0.0377,  0.0066,  0.0622,  0.0383, -0.0293, -0.0344, -0.0421,\n",
      "        -0.0491,  0.0157, -0.0687,  0.0486,  0.0456, -0.0587, -0.0051, -0.0042],\n",
      "       requires_grad=True)\n",
      "96 Parameter containing:\n",
      "tensor([[-0.0026,  0.0533,  0.0401,  ...,  0.0270, -0.0460,  0.0498],\n",
      "        [ 0.0295, -0.0927,  0.0491,  ..., -0.0389, -0.0815, -0.0507],\n",
      "        [-0.0701,  0.0778, -0.0327,  ...,  0.0550,  0.0151,  0.0476],\n",
      "        ...,\n",
      "        [ 0.0230,  0.0391, -0.0496,  ...,  0.0998,  0.0277,  0.0129],\n",
      "        [ 0.0411,  0.0453,  0.0865,  ...,  0.0791,  0.0714,  0.1129],\n",
      "        [ 0.0778,  0.0490,  0.0542,  ..., -0.0648,  0.0163, -0.0351]],\n",
      "       requires_grad=True)\n",
      "97 Parameter containing:\n",
      "tensor([-0.0498,  0.0116,  0.0530,  0.0446,  0.0680, -0.0738, -0.0510,  0.0318,\n",
      "         0.0702,  0.0329,  0.0093, -0.0673, -0.0543, -0.0214,  0.0226,  0.0906,\n",
      "        -0.0602,  0.0049,  0.0216,  0.0622,  0.0353, -0.0260,  0.0182,  0.0626,\n",
      "         0.0809, -0.0272,  0.0532, -0.0743, -0.0152, -0.0402,  0.0618, -0.0659,\n",
      "         0.0807,  0.1130, -0.0051, -0.0554,  0.0580, -0.0733, -0.0389,  0.0686,\n",
      "         0.0533, -0.0552,  0.0159,  0.0573,  0.0301, -0.0404,  0.0526,  0.0145,\n",
      "        -0.0489,  0.0468,  0.0384,  0.0665,  0.0605, -0.0165, -0.0269, -0.0332,\n",
      "         0.0154, -0.0204,  0.0416, -0.0540,  0.0461,  0.0251, -0.0547,  0.0769,\n",
      "         0.0378, -0.0409, -0.0258, -0.0750, -0.0331,  0.0649,  0.0506,  0.0286,\n",
      "         0.0367,  0.0744, -0.0307, -0.0308, -0.0719,  0.0533,  0.0811, -0.0573,\n",
      "        -0.0806, -0.0773,  0.0796, -0.0134, -0.0970, -0.0015,  0.0210, -0.0602,\n",
      "        -0.0253,  0.0512, -0.0556, -0.0062,  0.0350,  0.0216,  0.0367, -0.0084,\n",
      "         0.0528, -0.0217, -0.0156, -0.0132, -0.0049,  0.0687,  0.0290, -0.0713,\n",
      "        -0.0393, -0.0788, -0.0538,  0.0068, -0.0442,  0.0746, -0.0096, -0.0655,\n",
      "         0.0038, -0.0310, -0.0088, -0.0523, -0.0444,  0.0181, -0.0895,  0.0604,\n",
      "         0.0040, -0.0303,  0.0347, -0.0507, -0.0170,  0.0187, -0.0280,  0.0127],\n",
      "       requires_grad=True)\n",
      "98 Parameter containing:\n",
      "tensor([[ 0.0455,  0.0973,  0.0697,  ...,  0.0093,  0.0143,  0.0144],\n",
      "        [ 0.0602, -0.0046, -0.0929,  ...,  0.0419,  0.0099,  0.0394],\n",
      "        [-0.0907, -0.0753,  0.0024,  ..., -0.0594, -0.0577, -0.0976],\n",
      "        ...,\n",
      "        [ 0.0223, -0.0065,  0.0005,  ...,  0.0008,  0.0446, -0.0819],\n",
      "        [-0.0065, -0.0349, -0.0533,  ..., -0.1001,  0.0048, -0.0043],\n",
      "        [ 0.0384, -0.0673, -0.0443,  ...,  0.0495,  0.0734, -0.0008]],\n",
      "       requires_grad=True)\n",
      "99 Parameter containing:\n",
      "tensor([ 0.0299,  0.0429, -0.0274,  0.0237, -0.0484,  0.0654, -0.0265, -0.0260,\n",
      "        -0.0666, -0.0102, -0.0236,  0.0208, -0.0438,  0.0407, -0.0041,  0.0263,\n",
      "        -0.0424, -0.0557,  0.0488,  0.0848, -0.0004, -0.0388, -0.0011,  0.0041,\n",
      "        -0.0325, -0.0637, -0.0745, -0.0816, -0.0084, -0.0153,  0.0474,  0.0638,\n",
      "        -0.0345, -0.0777,  0.0647, -0.0840, -0.0463, -0.0265, -0.0891, -0.0177,\n",
      "         0.0540,  0.0538,  0.0666,  0.0166,  0.0747, -0.0666, -0.0626, -0.0489,\n",
      "        -0.0452,  0.0644, -0.0235,  0.0454, -0.0942,  0.0440,  0.0153, -0.0733,\n",
      "         0.0781,  0.0290, -0.0111,  0.0616, -0.0561,  0.0415, -0.0712, -0.0093,\n",
      "         0.0266,  0.0822, -0.0500, -0.0148, -0.0608,  0.0361, -0.0094,  0.0367,\n",
      "         0.0113,  0.0303,  0.0681,  0.0663, -0.0334,  0.0411, -0.0116, -0.0098,\n",
      "        -0.0549,  0.0005,  0.0756, -0.0774, -0.0414,  0.0370, -0.0192,  0.0436,\n",
      "        -0.0043,  0.0702, -0.0681,  0.0147, -0.0122,  0.0303, -0.0686, -0.0162,\n",
      "         0.0050,  0.0386, -0.0796, -0.0713,  0.0264,  0.0230,  0.0705,  0.0265,\n",
      "         0.0137,  0.0895, -0.0027,  0.0566,  0.0055, -0.0441,  0.0645, -0.0383,\n",
      "        -0.0224,  0.0021, -0.0788,  0.0870, -0.0544, -0.0557,  0.0478,  0.0490,\n",
      "         0.0139, -0.0596, -0.0900, -0.0216, -0.0610, -0.0787, -0.0574, -0.0521],\n",
      "       requires_grad=True)\n",
      "100 Parameter containing:\n",
      "tensor([1.], requires_grad=True)\n",
      "101 Parameter containing:\n",
      "tensor([1.], requires_grad=True)\n",
      "102 Parameter containing:\n",
      "tensor([[[-0.0843,  0.4643, -0.0751,  ...,  0.1097, -0.0431,  0.2927],\n",
      "         [-0.2446, -0.0307, -0.3560,  ...,  0.3387,  0.1062, -0.0847],\n",
      "         [-0.4140, -0.0282,  0.1438,  ...,  0.0873,  0.4483,  0.0815],\n",
      "         ...,\n",
      "         [-0.0301,  0.0874,  0.0663,  ..., -0.1969, -0.4622,  0.4226],\n",
      "         [-0.0271,  0.1322,  0.1969,  ..., -0.5388, -0.4086,  0.3791],\n",
      "         [-0.4877,  0.1953, -0.1251,  ...,  0.4228,  0.4262, -0.3417]],\n",
      "\n",
      "        [[-0.3552,  0.0144, -0.4228,  ..., -0.3957, -0.0786, -0.2069],\n",
      "         [-0.1840,  0.3233, -0.0397,  ..., -0.1444, -0.0496,  0.1154],\n",
      "         [ 0.1753, -0.4371, -0.2008,  ..., -0.1637, -0.4539,  0.2678],\n",
      "         ...,\n",
      "         [ 0.3901,  0.0644, -0.1453,  ..., -0.0078, -0.1721,  0.2125],\n",
      "         [-0.2865, -0.3003, -0.0803,  ..., -0.0785,  0.0849, -0.3571],\n",
      "         [-0.4543,  0.2351,  0.1510,  ..., -0.5213, -0.2180, -0.4249]],\n",
      "\n",
      "        [[ 0.5015,  0.1914, -0.5504,  ...,  0.4326, -0.3585,  0.4504],\n",
      "         [-0.3045, -0.0982,  0.2750,  ..., -0.0634, -0.2067, -0.4560],\n",
      "         [-0.4866, -0.1366,  0.4213,  ...,  0.1410,  0.0899,  0.2574],\n",
      "         ...,\n",
      "         [ 0.0674, -0.1488,  0.5004,  ..., -0.2251, -0.2042,  0.2703],\n",
      "         [ 0.2890, -0.1774, -0.2920,  ...,  0.0974, -0.2449, -0.1420],\n",
      "         [-0.1337, -0.2944, -0.3628,  ...,  0.2479, -0.2881,  0.1582]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2392,  0.0589, -0.3881,  ...,  0.3451, -0.2780,  0.0465],\n",
      "         [ 0.1062, -0.0440,  0.0475,  ..., -0.3451,  0.1187,  0.0957],\n",
      "         [-0.4198,  0.3523, -0.3144,  ..., -0.3067, -0.3140,  0.3816],\n",
      "         ...,\n",
      "         [-0.3485, -0.2851, -0.0652,  ..., -0.3453,  0.3252,  0.1624],\n",
      "         [-0.2591,  0.4174, -0.3007,  ...,  0.4445,  0.4071,  0.1551],\n",
      "         [-0.1692, -0.1470,  0.3560,  ..., -0.3343,  0.3744, -0.2562]],\n",
      "\n",
      "        [[ 0.2369,  0.1935,  0.4442,  ..., -0.0641, -0.3021,  0.1927],\n",
      "         [-0.3095,  0.1309, -0.4126,  ...,  0.0710, -0.1217,  0.3678],\n",
      "         [ 0.0229,  0.4367,  0.1562,  ..., -0.1443, -0.1783, -0.2034],\n",
      "         ...,\n",
      "         [ 0.2471, -0.3944, -0.1395,  ...,  0.0016,  0.2254,  0.2685],\n",
      "         [ 0.2585, -0.1005, -0.3712,  ..., -0.3416, -0.3330,  0.4163],\n",
      "         [ 0.0648, -0.1941,  0.3420,  ..., -0.3062, -0.1851,  0.1855]],\n",
      "\n",
      "        [[ 0.0452, -0.3886,  0.0284,  ..., -0.0199, -0.2684,  0.1825],\n",
      "         [ 0.1366,  0.3437, -0.5042,  ...,  0.3747,  0.4538,  0.3626],\n",
      "         [ 0.3122,  0.4817, -0.1994,  ..., -0.3311,  0.1838,  0.0245],\n",
      "         ...,\n",
      "         [-0.0441, -0.1472, -0.1653,  ...,  0.0471, -0.4196, -0.1325],\n",
      "         [ 0.2884, -0.2769, -0.2029,  ..., -0.2808, -0.0840,  0.1436],\n",
      "         [-0.4234,  0.0941,  0.2599,  ...,  0.0840, -0.1528, -0.2154]]],\n",
      "       requires_grad=True)\n",
      "103 Parameter containing:\n",
      "tensor([[[ 0.0992, -0.2826,  0.0846,  ...,  0.2954, -0.3199,  0.3780],\n",
      "         [ 0.2550, -0.2747,  0.2342,  ...,  0.2211, -0.2282,  0.0102],\n",
      "         [-0.0334,  0.3660, -0.1247,  ...,  0.0735,  0.3157, -0.1370],\n",
      "         ...,\n",
      "         [ 0.0736, -0.1789, -0.1092,  ...,  0.0703, -0.3850,  0.2469],\n",
      "         [-0.0039, -0.1111,  0.1410,  ...,  0.0233,  0.0568,  0.0931],\n",
      "         [-0.3027, -0.2364, -0.3572,  ...,  0.0693,  0.1300,  0.2316]],\n",
      "\n",
      "        [[ 0.0255,  0.1288,  0.0739,  ..., -0.1289, -0.2099, -0.0088],\n",
      "         [ 0.3682,  0.2846, -0.2564,  ...,  0.0497, -0.0328,  0.0149],\n",
      "         [ 0.2215,  0.0896,  0.2399,  ...,  0.0664,  0.2027, -0.3124],\n",
      "         ...,\n",
      "         [ 0.0251,  0.1847, -0.3758,  ..., -0.2321, -0.3061, -0.0357],\n",
      "         [-0.2478,  0.3317,  0.2022,  ..., -0.0294, -0.2344,  0.0869],\n",
      "         [ 0.4038, -0.2989, -0.2784,  ...,  0.1517, -0.0058, -0.0520]],\n",
      "\n",
      "        [[-0.3302, -0.2895, -0.3206,  ...,  0.2850,  0.2834,  0.1073],\n",
      "         [-0.0095,  0.2840,  0.3032,  ..., -0.3800,  0.2202,  0.0017],\n",
      "         [-0.1989,  0.0747, -0.0365,  ...,  0.3477, -0.3919, -0.0555],\n",
      "         ...,\n",
      "         [ 0.3458, -0.4071,  0.2397,  ..., -0.1278,  0.0177,  0.1937],\n",
      "         [ 0.1137, -0.1906,  0.2426,  ..., -0.3650, -0.2503, -0.1466],\n",
      "         [ 0.1661,  0.2314,  0.2841,  ..., -0.3466, -0.4005,  0.1652]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.3792,  0.1170,  0.2317,  ..., -0.2423, -0.2356, -0.0980],\n",
      "         [ 0.0951,  0.2467,  0.4478,  ...,  0.0214,  0.3132,  0.3208],\n",
      "         [ 0.4235,  0.0358,  0.1595,  ..., -0.0896,  0.3741, -0.2503],\n",
      "         ...,\n",
      "         [-0.4175,  0.0782, -0.0103,  ..., -0.1113,  0.2312,  0.1736],\n",
      "         [ 0.1226, -0.1472, -0.1345,  ..., -0.2919,  0.3704, -0.0801],\n",
      "         [-0.2409, -0.1963,  0.1264,  ...,  0.4102,  0.3462,  0.1327]],\n",
      "\n",
      "        [[ 0.4850, -0.0126,  0.3509,  ..., -0.2629,  0.3252, -0.3869],\n",
      "         [-0.4757,  0.0283, -0.2355,  ...,  0.4716,  0.2618, -0.0075],\n",
      "         [ 0.1521, -0.3301, -0.3410,  ..., -0.0096,  0.0775,  0.2506],\n",
      "         ...,\n",
      "         [ 0.0152,  0.1621,  0.2793,  ..., -0.2670,  0.1724, -0.0377],\n",
      "         [-0.3984,  0.2698,  0.1354,  ...,  0.2913,  0.3715,  0.1603],\n",
      "         [-0.0212, -0.1988,  0.4114,  ..., -0.3759, -0.0197, -0.3807]],\n",
      "\n",
      "        [[-0.3967,  0.0240, -0.1323,  ...,  0.0953, -0.0841,  0.0511],\n",
      "         [ 0.3894, -0.2896, -0.0792,  ..., -0.3963,  0.3668,  0.0213],\n",
      "         [-0.0953,  0.0585,  0.1384,  ..., -0.1624,  0.3313, -0.1556],\n",
      "         ...,\n",
      "         [ 0.0947,  0.0263, -0.2726,  ..., -0.1725,  0.2620,  0.2259],\n",
      "         [ 0.1320,  0.3732, -0.2861,  ...,  0.0409,  0.0393, -0.3137],\n",
      "         [-0.2257, -0.1215, -0.0342,  ...,  0.3960,  0.2774,  0.3617]]],\n",
      "       requires_grad=True)\n",
      "104 Parameter containing:\n",
      "tensor([[[ 0.2860, -0.0686, -0.0436,  ...,  0.3064, -0.3287, -0.2393],\n",
      "         [ 0.3830, -0.2983, -0.2740,  ..., -0.2040, -0.4327,  0.1205],\n",
      "         [-0.0806,  0.2374, -0.1447,  ...,  0.2649,  0.0610, -0.0021],\n",
      "         ...,\n",
      "         [ 0.2853, -0.1549, -0.3770,  ..., -0.1147, -0.2729,  0.3805],\n",
      "         [-0.3455, -0.2308,  0.2315,  ..., -0.2724,  0.0976, -0.4435],\n",
      "         [ 0.0987, -0.0534, -0.4576,  ..., -0.3433, -0.1973,  0.1509]],\n",
      "\n",
      "        [[-0.2747, -0.2403, -0.0773,  ...,  0.3959, -0.4365, -0.3591],\n",
      "         [ 0.3012, -0.3940, -0.1382,  ..., -0.1559, -0.2865,  0.0202],\n",
      "         [ 0.1702, -0.0686, -0.3981,  ..., -0.2726, -0.2973,  0.2614],\n",
      "         ...,\n",
      "         [ 0.0086,  0.0699,  0.3949,  ..., -0.0481,  0.1923, -0.0764],\n",
      "         [-0.2622,  0.0806, -0.1042,  ..., -0.3405, -0.3587,  0.3107],\n",
      "         [ 0.0497, -0.2693,  0.2229,  ...,  0.3840, -0.4139,  0.3087]],\n",
      "\n",
      "        [[-0.3064, -0.1614,  0.4172,  ...,  0.1324,  0.2542,  0.0840],\n",
      "         [ 0.2801,  0.3633,  0.1321,  ...,  0.3677, -0.1916,  0.4500],\n",
      "         [ 0.4173, -0.4513,  0.2288,  ..., -0.0539,  0.1615,  0.3165],\n",
      "         ...,\n",
      "         [-0.2002,  0.3533, -0.3145,  ...,  0.3419, -0.1688,  0.1561],\n",
      "         [ 0.0794,  0.2327, -0.3146,  ...,  0.2093,  0.0316,  0.2625],\n",
      "         [-0.1472,  0.0830, -0.3970,  ...,  0.0174,  0.1325,  0.1069]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.2234, -0.1869,  0.2408,  ...,  0.0044, -0.0715, -0.3758],\n",
      "         [ 0.1860, -0.2714, -0.1855,  ...,  0.0788, -0.3159,  0.4003],\n",
      "         [ 0.2336, -0.0091,  0.3038,  ...,  0.3885,  0.1154, -0.1806],\n",
      "         ...,\n",
      "         [-0.2578, -0.0981, -0.3957,  ..., -0.3087, -0.1725, -0.3896],\n",
      "         [ 0.3990,  0.0649,  0.3320,  ...,  0.1566, -0.2207, -0.1356],\n",
      "         [ 0.1414, -0.2268,  0.1498,  ...,  0.3797,  0.3231,  0.4237]],\n",
      "\n",
      "        [[-0.0973,  0.0796, -0.3332,  ...,  0.0079, -0.0086, -0.3580],\n",
      "         [-0.3058,  0.3156, -0.1922,  ...,  0.1366, -0.4562, -0.2571],\n",
      "         [ 0.0512, -0.0372, -0.0974,  ..., -0.3543,  0.3712,  0.3280],\n",
      "         ...,\n",
      "         [ 0.1762, -0.2938,  0.2452,  ...,  0.0220,  0.3032, -0.4087],\n",
      "         [-0.3802, -0.3724,  0.4202,  ..., -0.4143, -0.3148, -0.1998],\n",
      "         [ 0.3682, -0.0463,  0.0301,  ..., -0.2072, -0.0096, -0.1899]],\n",
      "\n",
      "        [[ 0.1166,  0.1015,  0.2966,  ..., -0.2482,  0.4182,  0.0910],\n",
      "         [ 0.3727, -0.0947, -0.4121,  ...,  0.0150,  0.4140, -0.2074],\n",
      "         [-0.0069, -0.1893,  0.2951,  ..., -0.3824,  0.0784, -0.0987],\n",
      "         ...,\n",
      "         [ 0.2933, -0.2585,  0.2587,  ..., -0.0376, -0.1271,  0.1817],\n",
      "         [-0.2690, -0.2326, -0.4221,  ...,  0.0635,  0.3776, -0.1114],\n",
      "         [ 0.2187, -0.2167,  0.0967,  ..., -0.1018, -0.0728, -0.3510]]],\n",
      "       requires_grad=True)\n",
      "105 Parameter containing:\n",
      "tensor([[[ 1.3941e-01, -1.2221e-01,  3.0798e-01,  ...,  1.2223e-01,\n",
      "           1.1630e-01,  1.9237e-01],\n",
      "         [ 1.8434e-01,  3.3082e-01, -4.9038e-02,  ...,  4.1042e-01,\n",
      "           1.5008e-01,  4.7298e-02],\n",
      "         [-2.4909e-01, -1.0315e-01,  1.5596e-01,  ...,  1.7947e-01,\n",
      "           3.8583e-01, -6.2448e-03],\n",
      "         ...,\n",
      "         [-3.8366e-01, -2.2454e-01, -5.2002e-02,  ..., -8.2345e-02,\n",
      "           2.3184e-01,  2.7459e-01],\n",
      "         [-4.3063e-01,  9.9223e-02,  3.5448e-01,  ..., -7.8390e-02,\n",
      "          -3.4319e-01,  1.2196e-01],\n",
      "         [-3.4540e-01,  1.4081e-01,  8.8284e-03,  ..., -1.3257e-01,\n",
      "          -3.3839e-01, -9.6972e-02]],\n",
      "\n",
      "        [[ 3.3351e-01, -2.2895e-01, -1.3300e-01,  ...,  3.2220e-01,\n",
      "           3.4700e-01,  1.9487e-02],\n",
      "         [-9.5101e-02, -2.4054e-01, -2.1540e-01,  ...,  2.8182e-02,\n",
      "          -1.6540e-03,  1.9932e-01],\n",
      "         [-1.3690e-01, -3.4223e-01,  6.3831e-02,  ...,  2.9004e-01,\n",
      "          -4.3833e-01,  8.0475e-02],\n",
      "         ...,\n",
      "         [ 2.3890e-01,  1.9809e-01,  2.5463e-01,  ..., -2.1041e-01,\n",
      "           2.1654e-01, -2.1447e-01],\n",
      "         [ 2.4081e-01,  3.7216e-01,  2.2301e-01,  ...,  1.5180e-01,\n",
      "           1.5088e-01,  3.6006e-01],\n",
      "         [-7.6531e-02, -3.4516e-01, -1.9608e-01,  ..., -2.9262e-01,\n",
      "          -1.5834e-01, -9.7545e-02]],\n",
      "\n",
      "        [[-4.2492e-02, -1.5852e-01, -3.4523e-01,  ..., -2.7887e-02,\n",
      "           2.2500e-01,  1.6206e-01],\n",
      "         [ 3.5791e-01,  2.6927e-01,  1.8004e-01,  ..., -3.4849e-01,\n",
      "           9.2355e-02, -5.0381e-02],\n",
      "         [-2.3575e-01, -2.2444e-01, -1.7056e-01,  ...,  3.6217e-01,\n",
      "          -3.8761e-01, -3.3074e-01],\n",
      "         ...,\n",
      "         [-2.9969e-02, -1.8782e-01, -4.4831e-01,  ...,  2.8944e-01,\n",
      "          -2.4115e-01,  2.4914e-01],\n",
      "         [ 1.8617e-01, -8.0084e-02,  1.8103e-01,  ..., -2.3597e-02,\n",
      "           5.3788e-02, -1.7307e-02],\n",
      "         [ 2.6487e-01,  3.5494e-01,  7.8061e-02,  ..., -2.7460e-01,\n",
      "          -4.0254e-02,  1.2881e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.1439e-01, -2.7157e-01, -1.1073e-01,  ...,  2.9458e-01,\n",
      "          -3.8756e-02, -3.9208e-01],\n",
      "         [ 1.1677e-01,  3.2648e-01,  1.5164e-01,  ...,  8.2182e-02,\n",
      "           3.7012e-01, -2.5352e-01],\n",
      "         [-3.5642e-01,  4.4136e-02,  2.1386e-02,  ..., -1.2505e-01,\n",
      "          -3.0044e-01,  1.1924e-01],\n",
      "         ...,\n",
      "         [ 2.1827e-01,  1.4142e-01, -2.1639e-01,  ..., -2.2696e-01,\n",
      "          -1.5355e-01, -3.2107e-01],\n",
      "         [ 3.0970e-01,  1.2247e-01,  4.4944e-02,  ..., -2.5132e-01,\n",
      "           5.6124e-03, -5.3343e-02],\n",
      "         [-3.8392e-01, -4.9311e-02, -1.0202e-01,  ...,  2.2320e-01,\n",
      "           1.4744e-01,  9.6296e-02]],\n",
      "\n",
      "        [[-2.3111e-01,  3.7989e-01, -4.0136e-01,  ..., -1.2756e-02,\n",
      "          -1.9559e-01,  2.7509e-01],\n",
      "         [-4.4185e-01,  1.8565e-01,  2.3812e-01,  ...,  4.1034e-01,\n",
      "           4.1716e-01,  3.7899e-01],\n",
      "         [ 3.3398e-01,  1.6143e-01,  2.6748e-01,  ...,  4.5689e-01,\n",
      "          -2.4026e-01,  2.0372e-01],\n",
      "         ...,\n",
      "         [ 1.9830e-01,  2.8933e-01,  3.4324e-01,  ...,  1.0655e-01,\n",
      "          -2.8677e-02,  2.3600e-01],\n",
      "         [ 4.6448e-02, -4.1021e-01, -4.0801e-04,  ..., -2.7695e-01,\n",
      "          -1.6111e-02,  2.0419e-01],\n",
      "         [-1.2824e-01,  3.5934e-01,  3.7294e-01,  ...,  4.5089e-02,\n",
      "          -3.9350e-01, -2.6458e-01]],\n",
      "\n",
      "        [[-3.2830e-01, -3.0586e-01, -1.7434e-01,  ...,  3.0211e-03,\n",
      "           1.4812e-01,  1.6465e-01],\n",
      "         [-1.6722e-01, -4.2335e-02, -2.7219e-01,  ..., -1.0336e-01,\n",
      "           7.6970e-02,  3.0490e-01],\n",
      "         [-2.8468e-01, -1.0184e-01, -2.5674e-01,  ..., -3.5476e-01,\n",
      "           4.0333e-02,  3.5054e-01],\n",
      "         ...,\n",
      "         [-3.5006e-01, -9.1313e-02, -4.2035e-02,  ..., -1.5918e-04,\n",
      "           2.9987e-01,  2.1956e-01],\n",
      "         [ 2.3798e-01, -1.7310e-01,  1.7374e-01,  ...,  2.4516e-01,\n",
      "          -3.6780e-01, -3.0990e-02],\n",
      "         [-2.4764e-01, -1.9323e-01,  7.5077e-02,  ..., -3.2981e-01,\n",
      "           2.6916e-01,  1.2196e-01]]], requires_grad=True)\n",
      "106 Parameter containing:\n",
      "tensor([[[-0.0893, -0.2019,  0.0195,  ..., -0.2634,  0.1260,  0.2716],\n",
      "         [-0.2384,  0.1989,  0.0791,  ..., -0.2238, -0.2844, -0.0772],\n",
      "         [ 0.3028, -0.2413, -0.0917,  ...,  0.1894,  0.4203, -0.0469],\n",
      "         ...,\n",
      "         [ 0.2783,  0.0083,  0.3445,  ..., -0.1084, -0.2841,  0.2401],\n",
      "         [-0.3033, -0.2581,  0.1520,  ..., -0.3229,  0.0320, -0.2086],\n",
      "         [-0.0992,  0.1087,  0.2025,  ...,  0.0257, -0.1646, -0.3813]],\n",
      "\n",
      "        [[-0.0554,  0.2641,  0.4365,  ..., -0.0372, -0.4450,  0.2337],\n",
      "         [-0.0680,  0.0787, -0.3912,  ..., -0.2563,  0.4420, -0.0795],\n",
      "         [ 0.4019,  0.1331,  0.1736,  ...,  0.2007, -0.2193, -0.2858],\n",
      "         ...,\n",
      "         [ 0.1734,  0.3043,  0.1884,  ..., -0.1386,  0.1433,  0.2565],\n",
      "         [ 0.2319,  0.4428,  0.3614,  ...,  0.3527, -0.3008, -0.2056],\n",
      "         [ 0.2451, -0.0166,  0.3209,  ..., -0.1486, -0.2651,  0.4294]],\n",
      "\n",
      "        [[-0.1073, -0.2497,  0.0100,  ..., -0.1458,  0.1779,  0.2381],\n",
      "         [ 0.2315, -0.4022,  0.1592,  ..., -0.2101,  0.2568, -0.2854],\n",
      "         [ 0.3109, -0.1160,  0.0069,  ...,  0.3894,  0.0316, -0.0313],\n",
      "         ...,\n",
      "         [ 0.3448, -0.1257,  0.3185,  ...,  0.1698,  0.2327, -0.3052],\n",
      "         [ 0.1533, -0.3410, -0.3079,  ...,  0.0411, -0.2047, -0.0270],\n",
      "         [-0.2367, -0.0495,  0.3329,  ...,  0.3083, -0.2312, -0.2700]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.3230,  0.1193,  0.2809,  ...,  0.3940, -0.3949,  0.4260],\n",
      "         [ 0.4635, -0.1225,  0.0258,  ...,  0.4758, -0.0593, -0.1889],\n",
      "         [-0.2179, -0.1145,  0.0597,  ...,  0.2579,  0.0162, -0.1065],\n",
      "         ...,\n",
      "         [ 0.1977,  0.2570, -0.3196,  ..., -0.2060, -0.4318, -0.2637],\n",
      "         [ 0.1156, -0.4530, -0.0963,  ..., -0.3702,  0.3651, -0.4817],\n",
      "         [-0.0897, -0.1878,  0.2418,  ...,  0.2555, -0.4174,  0.3184]],\n",
      "\n",
      "        [[-0.2961,  0.4476, -0.3019,  ..., -0.0862,  0.0172, -0.0088],\n",
      "         [-0.2622,  0.0397, -0.4016,  ...,  0.0265, -0.0278, -0.3484],\n",
      "         [-0.4162, -0.0052, -0.0935,  ...,  0.1928, -0.2632,  0.3613],\n",
      "         ...,\n",
      "         [ 0.0588,  0.2097, -0.2040,  ..., -0.1235,  0.3623, -0.1459],\n",
      "         [ 0.2063, -0.1983, -0.3834,  ...,  0.1817, -0.3371, -0.1368],\n",
      "         [ 0.2393, -0.1217,  0.1543,  ...,  0.1294, -0.3363, -0.1158]],\n",
      "\n",
      "        [[ 0.2431, -0.4200, -0.3369,  ..., -0.0262,  0.1974,  0.0978],\n",
      "         [ 0.1306, -0.1123, -0.2138,  ...,  0.1093,  0.1162, -0.1250],\n",
      "         [ 0.2794, -0.4086,  0.1675,  ...,  0.3960, -0.2790, -0.3195],\n",
      "         ...,\n",
      "         [-0.0960,  0.4194, -0.3793,  ...,  0.3458, -0.0076,  0.3306],\n",
      "         [-0.2586,  0.1242, -0.2869,  ..., -0.1304, -0.1585, -0.0338],\n",
      "         [-0.1836,  0.0458, -0.1368,  ..., -0.0368,  0.1932, -0.2803]]],\n",
      "       requires_grad=True)\n",
      "107 Parameter containing:\n",
      "tensor([[[-0.2690,  0.1537,  0.3143,  ..., -0.3202, -0.1551, -0.1937],\n",
      "         [ 0.1471,  0.0249, -0.3852,  ..., -0.3442,  0.2914,  0.0332],\n",
      "         [-0.2579,  0.3321,  0.2092,  ...,  0.3052, -0.4200, -0.1412],\n",
      "         ...,\n",
      "         [-0.0802,  0.2121, -0.1633,  ..., -0.0678,  0.2190, -0.1159],\n",
      "         [-0.3087,  0.0971,  0.1640,  ..., -0.3689, -0.2317, -0.4241],\n",
      "         [-0.2009, -0.1381,  0.1495,  ...,  0.3964, -0.1904, -0.1221]],\n",
      "\n",
      "        [[-0.0152, -0.3012,  0.1806,  ...,  0.0216,  0.4029, -0.1109],\n",
      "         [ 0.1796, -0.1225,  0.3099,  ...,  0.3680,  0.4532,  0.2404],\n",
      "         [ 0.3566,  0.0562, -0.2519,  ...,  0.4631,  0.3733, -0.2759],\n",
      "         ...,\n",
      "         [ 0.1131, -0.4118, -0.1409,  ..., -0.2623, -0.2067,  0.1405],\n",
      "         [-0.3925,  0.1246, -0.1941,  ..., -0.3363,  0.2721,  0.4004],\n",
      "         [ 0.0318, -0.2181, -0.0431,  ..., -0.1507,  0.1838, -0.3459]],\n",
      "\n",
      "        [[-0.3627,  0.2154,  0.3686,  ...,  0.1996, -0.3809,  0.0280],\n",
      "         [-0.0615,  0.3385, -0.3283,  ..., -0.2800,  0.0374,  0.2504],\n",
      "         [ 0.2104, -0.2228,  0.1803,  ...,  0.3840, -0.1580,  0.3967],\n",
      "         ...,\n",
      "         [-0.2632,  0.4329,  0.1160,  ..., -0.3305,  0.1162,  0.1666],\n",
      "         [ 0.0590,  0.1978,  0.2440,  ..., -0.3518, -0.0091, -0.2495],\n",
      "         [ 0.0197,  0.2706, -0.1512,  ..., -0.3357, -0.3187, -0.2314]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1644,  0.0367, -0.3136,  ..., -0.0005, -0.0875,  0.1554],\n",
      "         [-0.0429, -0.1307, -0.4340,  ..., -0.1123, -0.0180,  0.0756],\n",
      "         [ 0.1092,  0.2270, -0.2925,  ...,  0.1372, -0.3168, -0.0762],\n",
      "         ...,\n",
      "         [-0.2753, -0.1495, -0.0855,  ..., -0.2456, -0.2993, -0.1460],\n",
      "         [ 0.0573,  0.1559, -0.1028,  ...,  0.2783,  0.4194,  0.0855],\n",
      "         [ 0.2290, -0.2512,  0.0341,  ..., -0.1116,  0.3327,  0.3041]],\n",
      "\n",
      "        [[-0.3211, -0.0454,  0.4526,  ..., -0.0154,  0.0477, -0.1911],\n",
      "         [ 0.3785, -0.0860, -0.2313,  ...,  0.3314, -0.0326,  0.2735],\n",
      "         [-0.4126,  0.2238,  0.1159,  ...,  0.2928,  0.2811, -0.2977],\n",
      "         ...,\n",
      "         [-0.2056,  0.1029, -0.0356,  ...,  0.0948, -0.0257,  0.2521],\n",
      "         [-0.3858,  0.1251, -0.2730,  ...,  0.0581, -0.4005, -0.4385],\n",
      "         [-0.1148, -0.2779, -0.1001,  ..., -0.1964,  0.2284,  0.0986]],\n",
      "\n",
      "        [[ 0.1442,  0.0332, -0.1651,  ..., -0.4046,  0.0276,  0.3749],\n",
      "         [-0.3791,  0.1499,  0.2105,  ..., -0.2727, -0.3386, -0.3627],\n",
      "         [ 0.0676, -0.4152, -0.1227,  ..., -0.3214, -0.2420, -0.1985],\n",
      "         ...,\n",
      "         [ 0.3311, -0.1752,  0.0569,  ..., -0.0161,  0.3854,  0.1684],\n",
      "         [-0.2599, -0.2465,  0.0980,  ...,  0.1718,  0.2939,  0.0361],\n",
      "         [-0.2011,  0.0815,  0.0116,  ...,  0.0563,  0.4399, -0.4076]]],\n",
      "       requires_grad=True)\n",
      "108 Parameter containing:\n",
      "tensor([[[ 0.1765, -0.3203,  0.3718,  ..., -0.3023, -0.2052, -0.1451],\n",
      "         [-0.1601, -0.2989,  0.1829,  ..., -0.0569, -0.0977, -0.0092],\n",
      "         [-0.3180,  0.3981, -0.0383,  ..., -0.3105,  0.3837, -0.2414],\n",
      "         ...,\n",
      "         [-0.4437, -0.2160, -0.3655,  ...,  0.4026, -0.1291, -0.0505],\n",
      "         [ 0.2845, -0.1210,  0.0943,  ...,  0.2294, -0.3672, -0.2721],\n",
      "         [ 0.0635, -0.1483,  0.1990,  ...,  0.3299,  0.2293,  0.0828]],\n",
      "\n",
      "        [[ 0.3163,  0.0428, -0.0191,  ...,  0.3812,  0.1682, -0.4165],\n",
      "         [-0.4532, -0.3715,  0.1332,  ...,  0.0863, -0.3837,  0.2628],\n",
      "         [ 0.3738, -0.4194, -0.0564,  ...,  0.3388, -0.0015, -0.0188],\n",
      "         ...,\n",
      "         [ 0.0575, -0.1297,  0.1302,  ..., -0.0210, -0.1595, -0.1015],\n",
      "         [-0.2913, -0.1032, -0.0348,  ...,  0.2640, -0.2259,  0.2301],\n",
      "         [ 0.1158, -0.2284,  0.2822,  ..., -0.3484,  0.2560,  0.0271]],\n",
      "\n",
      "        [[ 0.0100, -0.4397, -0.1509,  ...,  0.3773, -0.0124,  0.2085],\n",
      "         [ 0.3421,  0.0723, -0.3317,  ..., -0.3856, -0.2011,  0.2831],\n",
      "         [-0.3771, -0.0668,  0.0162,  ..., -0.0107, -0.2478, -0.4138],\n",
      "         ...,\n",
      "         [ 0.2213, -0.2924,  0.0584,  ...,  0.0387, -0.2940,  0.1948],\n",
      "         [-0.0762, -0.2686,  0.3560,  ...,  0.3407,  0.0957, -0.4391],\n",
      "         [-0.0055,  0.3437,  0.1512,  ...,  0.2269, -0.2826,  0.0703]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0054, -0.3076, -0.2730,  ...,  0.0518,  0.1660, -0.0707],\n",
      "         [-0.2141,  0.0176, -0.3288,  ..., -0.0170, -0.1209,  0.3869],\n",
      "         [ 0.2161, -0.3970,  0.3305,  ...,  0.2362, -0.3733, -0.0465],\n",
      "         ...,\n",
      "         [ 0.3670,  0.3260,  0.4081,  ..., -0.3835, -0.3264,  0.0443],\n",
      "         [-0.0370, -0.2564,  0.2320,  ...,  0.1379, -0.2417,  0.3282],\n",
      "         [-0.4129, -0.4154, -0.2815,  ...,  0.2727, -0.2827, -0.4261]],\n",
      "\n",
      "        [[-0.3871, -0.2674, -0.0119,  ...,  0.4282,  0.1282, -0.1502],\n",
      "         [ 0.2012,  0.3147, -0.0299,  ..., -0.2681, -0.3085, -0.3199],\n",
      "         [ 0.4340, -0.3969,  0.4352,  ..., -0.2029,  0.3120, -0.4299],\n",
      "         ...,\n",
      "         [-0.1389, -0.1014, -0.1327,  ...,  0.1734, -0.4237,  0.0442],\n",
      "         [-0.1523, -0.0090, -0.3084,  ...,  0.1231,  0.0227,  0.2621],\n",
      "         [ 0.3472, -0.1270,  0.3408,  ..., -0.2119,  0.0548, -0.3060]],\n",
      "\n",
      "        [[ 0.1144,  0.1164, -0.3596,  ...,  0.2290, -0.0482, -0.1227],\n",
      "         [ 0.0388,  0.2767,  0.1299,  ..., -0.2465,  0.0347,  0.3372],\n",
      "         [-0.3270, -0.2110,  0.1430,  ..., -0.2776,  0.0015,  0.1589],\n",
      "         ...,\n",
      "         [ 0.1789,  0.4581, -0.3507,  ..., -0.0556,  0.3266,  0.1795],\n",
      "         [ 0.3552, -0.1797, -0.3505,  ..., -0.0059,  0.3955, -0.4357],\n",
      "         [ 0.2010, -0.0823, -0.2978,  ..., -0.0951,  0.0412, -0.3594]]],\n",
      "       requires_grad=True)\n",
      "109 Parameter containing:\n",
      "tensor([[[-0.3716, -0.1947,  0.2265,  ...,  0.2832, -0.3319,  0.1946],\n",
      "         [ 0.2299, -0.1801, -0.2764,  ..., -0.1356, -0.1924,  0.1764],\n",
      "         [-0.0198, -0.1928, -0.2369,  ...,  0.3480,  0.1325,  0.2862],\n",
      "         ...,\n",
      "         [-0.2108,  0.3675, -0.3108,  ..., -0.3952,  0.2031, -0.2656],\n",
      "         [ 0.3280, -0.3862, -0.1505,  ..., -0.1427,  0.2218, -0.1174],\n",
      "         [ 0.0351, -0.2325,  0.3784,  ..., -0.0045,  0.0595,  0.1928]],\n",
      "\n",
      "        [[-0.0928, -0.2727,  0.3677,  ...,  0.4275,  0.3495,  0.0185],\n",
      "         [ 0.4014, -0.3855, -0.4450,  ..., -0.3361, -0.2642, -0.3088],\n",
      "         [-0.3890,  0.1829,  0.0760,  ..., -0.2434,  0.2792, -0.3242],\n",
      "         ...,\n",
      "         [ 0.1553,  0.0089, -0.3500,  ..., -0.1973, -0.1627,  0.2399],\n",
      "         [ 0.2677, -0.1593, -0.2683,  ...,  0.2951, -0.3500, -0.3087],\n",
      "         [-0.0808, -0.0372, -0.2686,  ..., -0.0276, -0.3206,  0.1977]],\n",
      "\n",
      "        [[-0.3584,  0.3879, -0.4024,  ...,  0.2157,  0.3350, -0.2188],\n",
      "         [-0.2816,  0.0728,  0.3460,  ..., -0.4646, -0.1881, -0.1955],\n",
      "         [ 0.3527, -0.3636,  0.2130,  ..., -0.1249,  0.2526,  0.4342],\n",
      "         ...,\n",
      "         [-0.0726, -0.0471, -0.1458,  ...,  0.1541,  0.3859, -0.2671],\n",
      "         [ 0.2804, -0.3404,  0.0916,  ...,  0.0570, -0.1779,  0.0901],\n",
      "         [ 0.4103,  0.1955, -0.3610,  ..., -0.3636,  0.0515, -0.3177]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0695,  0.0546,  0.3275,  ...,  0.3612, -0.0049,  0.3051],\n",
      "         [ 0.1198,  0.0732,  0.2433,  ..., -0.1379, -0.4162,  0.2941],\n",
      "         [ 0.3566,  0.0605, -0.2089,  ..., -0.4027, -0.2114, -0.3478],\n",
      "         ...,\n",
      "         [ 0.2793, -0.2473, -0.4290,  ...,  0.4468, -0.0424,  0.0137],\n",
      "         [ 0.1270, -0.0161,  0.0735,  ...,  0.0242,  0.3764, -0.3388],\n",
      "         [ 0.1151,  0.1860, -0.1912,  ...,  0.0801, -0.3053,  0.3147]],\n",
      "\n",
      "        [[ 0.1896, -0.3677,  0.2397,  ...,  0.0392, -0.3639,  0.3814],\n",
      "         [ 0.3804, -0.0700, -0.2270,  ..., -0.3466, -0.0749, -0.0013],\n",
      "         [ 0.1109, -0.1957,  0.0484,  ..., -0.3981,  0.0662, -0.0455],\n",
      "         ...,\n",
      "         [ 0.1102,  0.0709,  0.4260,  ...,  0.0236, -0.3813,  0.0215],\n",
      "         [-0.1143, -0.1826, -0.2183,  ..., -0.1623,  0.3427,  0.3792],\n",
      "         [-0.0960, -0.2357, -0.2637,  ...,  0.3177,  0.3196, -0.2089]],\n",
      "\n",
      "        [[-0.1289, -0.4243,  0.2318,  ..., -0.3261,  0.0370,  0.0859],\n",
      "         [ 0.3386, -0.2143, -0.2568,  ...,  0.3838, -0.3859, -0.3503],\n",
      "         [ 0.2879, -0.3720,  0.0874,  ...,  0.3603, -0.4282, -0.3449],\n",
      "         ...,\n",
      "         [-0.0082,  0.1602,  0.1683,  ..., -0.0670, -0.0515,  0.3345],\n",
      "         [-0.0809,  0.0914,  0.3328,  ..., -0.1019, -0.2086, -0.0513],\n",
      "         [ 0.0936, -0.3868,  0.0274,  ...,  0.4089, -0.3787, -0.2833]]],\n",
      "       requires_grad=True)\n",
      "110 Parameter containing:\n",
      "tensor([1.1612, 1.1043, 1.1411, 1.1406, 1.0682, 1.0494, 1.0196, 1.0565],\n",
      "       requires_grad=True)\n",
      "111 Parameter containing:\n",
      "tensor([1.0052, 0.9985, 0.9742, 1.0180, 1.0028, 0.9727, 1.0523, 0.9891],\n",
      "       requires_grad=True)\n",
      "112 Parameter containing:\n",
      "tensor([1.0119, 0.9968, 1.0519, 1.0482, 0.9793, 0.9846, 0.9699, 1.0241],\n",
      "       requires_grad=True)\n",
      "113 Parameter containing:\n",
      "tensor([0.9763, 0.9395, 0.9719, 0.9802, 0.9929, 0.9817, 0.9740, 0.9570],\n",
      "       requires_grad=True)\n",
      "114 Parameter containing:\n",
      "tensor([[ 0.0145,  0.0255, -0.0021,  ...,  0.0096,  0.0085, -0.0115],\n",
      "        [ 0.0254,  0.0085,  0.0350,  ..., -0.0035, -0.0032,  0.0159],\n",
      "        [-0.0045,  0.0178, -0.0177,  ...,  0.0026, -0.0165, -0.0106],\n",
      "        ...,\n",
      "        [ 0.0089,  0.0236, -0.0040,  ..., -0.0337, -0.0101, -0.0273],\n",
      "        [-0.0267,  0.0043, -0.0011,  ...,  0.0029, -0.0015,  0.0129],\n",
      "        [-0.0065, -0.0286,  0.0100,  ...,  0.0158,  0.0127,  0.0017]],\n",
      "       requires_grad=True)\n",
      "115 Parameter containing:\n",
      "tensor([ 0.0163,  0.0254, -0.0255,  ...,  0.0199,  0.0059,  0.0111],\n",
      "       requires_grad=True)\n",
      "116 Parameter containing:\n",
      "tensor([[ 0.0066, -0.0079,  0.0126,  ..., -0.0120,  0.0100,  0.0023],\n",
      "        [ 0.0329,  0.0293, -0.0267,  ...,  0.0043, -0.0237, -0.0197],\n",
      "        [ 0.0104,  0.0092, -0.0060,  ...,  0.0005, -0.0362,  0.0026],\n",
      "        ...,\n",
      "        [ 0.0262, -0.0234,  0.0261,  ...,  0.0088, -0.0136, -0.0130],\n",
      "        [-0.0132, -0.0172,  0.0131,  ...,  0.0166, -0.0030, -0.0157],\n",
      "        [ 0.0192, -0.0144,  0.0180,  ..., -0.0094,  0.0067, -0.0233]],\n",
      "       requires_grad=True)\n",
      "117 Parameter containing:\n",
      "tensor([-0.0236, -0.0186, -0.0110,  ...,  0.0216,  0.0086,  0.0073],\n",
      "       requires_grad=True)\n",
      "118 Parameter containing:\n",
      "tensor([[-1.6531e-02, -5.1278e-03,  1.9403e-02,  ..., -5.8332e-04,\n",
      "          6.1383e-03,  9.6923e-03],\n",
      "        [-1.7239e-02, -9.0800e-03,  1.5160e-02,  ..., -1.3081e-02,\n",
      "          1.9483e-02, -2.8751e-05],\n",
      "        [-1.2663e-02,  1.7842e-02, -6.5995e-03,  ..., -1.7280e-02,\n",
      "         -1.1817e-02, -9.9743e-03],\n",
      "        ...,\n",
      "        [ 1.1022e-02, -5.3606e-03, -1.3504e-02,  ...,  7.7420e-03,\n",
      "         -4.6165e-03,  1.3220e-03],\n",
      "        [ 7.0907e-03, -1.5673e-02,  1.3700e-02,  ...,  1.5850e-02,\n",
      "          1.7533e-02, -2.1086e-02],\n",
      "        [-2.0222e-02, -2.0790e-02, -5.2959e-03,  ...,  1.1897e-03,\n",
      "          2.2234e-02,  8.4793e-04]], requires_grad=True)\n",
      "119 Parameter containing:\n",
      "tensor([-0.0129, -0.0076, -0.0207,  ...,  0.0223, -0.0154,  0.0129],\n",
      "       requires_grad=True)\n",
      "120 Parameter containing:\n",
      "tensor([[-0.0159, -0.0239, -0.0272,  ..., -0.0272, -0.0311,  0.0301],\n",
      "        [-0.0169,  0.0122, -0.0243,  ..., -0.0016, -0.0036,  0.0295],\n",
      "        [-0.0061,  0.0077,  0.0126,  ..., -0.0161, -0.0092, -0.0296],\n",
      "        ...,\n",
      "        [ 0.0274,  0.0102, -0.0292,  ..., -0.0123,  0.0158,  0.0342],\n",
      "        [ 0.0066,  0.0365,  0.0266,  ..., -0.0214, -0.0071,  0.0181],\n",
      "        [-0.0137, -0.0315,  0.0259,  ..., -0.0082, -0.0228, -0.0234]],\n",
      "       requires_grad=True)\n",
      "121 Parameter containing:\n",
      "tensor([ 2.9207e-02, -1.9648e-02,  8.3806e-03, -1.7310e-02,  4.2732e-03,\n",
      "         4.8038e-03,  1.4423e-02, -7.1857e-03, -2.5582e-02, -1.9810e-02,\n",
      "        -2.7170e-02,  1.8060e-02, -1.2938e-04,  2.3184e-03,  6.3595e-03,\n",
      "         1.2840e-02, -1.9432e-02,  1.7825e-02,  3.1903e-02, -1.3491e-02,\n",
      "         1.6502e-02,  6.6373e-04,  2.5132e-02,  1.0274e-03, -6.4896e-03,\n",
      "        -2.0359e-02, -2.2819e-02,  1.7013e-02, -2.9641e-03, -8.9666e-03,\n",
      "         1.6692e-02, -1.6068e-03, -2.0570e-02, -2.1414e-02, -2.3541e-02,\n",
      "         1.0462e-02,  8.7214e-03, -1.0073e-02, -1.9467e-02, -4.4155e-03,\n",
      "         1.1985e-02, -1.3180e-02, -8.3649e-03, -2.0979e-02,  2.8733e-02,\n",
      "         6.1402e-03, -1.4008e-03, -2.2357e-02, -2.6169e-02,  7.0917e-03,\n",
      "         7.1303e-03,  1.1038e-02,  2.7985e-02,  3.0835e-02,  2.9604e-03,\n",
      "         2.3531e-02, -1.6671e-02,  3.3118e-03, -1.9383e-02, -1.0891e-02,\n",
      "        -8.5704e-03,  1.1233e-02,  4.4443e-03,  7.2477e-07, -2.2720e-02,\n",
      "         1.0368e-02,  2.9092e-03, -1.0633e-02, -2.8164e-02,  8.3323e-03,\n",
      "         2.0992e-02,  5.0124e-03, -6.0658e-03,  2.9387e-03,  5.7398e-03,\n",
      "        -2.3940e-02, -2.6759e-02,  2.1371e-02,  3.3944e-02, -2.7394e-02,\n",
      "        -2.3907e-02, -1.7994e-02,  1.1542e-02, -1.0013e-02, -1.8656e-02,\n",
      "        -1.4116e-02, -1.8166e-02,  1.2119e-02, -1.0850e-02,  2.3954e-02,\n",
      "        -2.6122e-02, -1.3742e-02, -2.4073e-02,  7.0672e-03, -1.0651e-02,\n",
      "         3.1929e-02,  1.0640e-02, -2.9249e-02, -3.0611e-03,  1.0123e-02,\n",
      "        -1.6211e-03, -1.2194e-02,  4.7731e-03, -2.5248e-02,  1.6279e-03,\n",
      "         3.0397e-02,  2.1544e-02,  1.4005e-02,  3.0790e-02, -5.1738e-03,\n",
      "        -2.3622e-02, -3.0285e-02, -1.3734e-02,  1.3903e-02,  3.9916e-03,\n",
      "        -1.8574e-02,  2.3281e-02,  1.8617e-02,  2.2652e-02,  1.2668e-02,\n",
      "        -2.3906e-02, -1.9842e-02, -1.3911e-02,  2.9167e-02,  2.8774e-02,\n",
      "         2.9508e-02,  7.2017e-03, -2.1430e-02], requires_grad=True)\n",
      "122 Parameter containing:\n",
      "tensor([[-0.0737, -0.0170,  0.0892,  0.0947, -0.1033, -0.0311,  0.0867,  0.0673,\n",
      "          0.0571, -0.0957, -0.0735, -0.0374, -0.0823,  0.0892,  0.0548, -0.0137,\n",
      "          0.0727, -0.0374, -0.0257, -0.0535, -0.0721,  0.0474,  0.0496,  0.0404,\n",
      "         -0.0315, -0.0884, -0.0867, -0.0924, -0.0416,  0.0460,  0.0440, -0.0316,\n",
      "         -0.0245, -0.0760,  0.0204,  0.0867,  0.0263, -0.0348, -0.0148, -0.0723,\n",
      "          0.1007,  0.0506,  0.0159,  0.0410, -0.0221,  0.0692,  0.0307, -0.0702,\n",
      "         -0.0892,  0.1021,  0.0956,  0.0871,  0.0503,  0.0307, -0.0894, -0.0523,\n",
      "          0.0315, -0.0414, -0.0863,  0.0266,  0.0240,  0.0179, -0.0559,  0.0799,\n",
      "         -0.0705, -0.0434, -0.0137, -0.0428, -0.0366, -0.0859, -0.0713, -0.0301,\n",
      "          0.0569, -0.0368, -0.0469,  0.0649, -0.0985, -0.0353,  0.0414, -0.0331,\n",
      "         -0.0310, -0.0202,  0.0816,  0.0200,  0.0625,  0.0834,  0.0910, -0.0704,\n",
      "          0.0455, -0.0490, -0.0465, -0.0873, -0.0392,  0.0249,  0.0711,  0.0527,\n",
      "         -0.0686, -0.0834,  0.0661,  0.0784, -0.0298, -0.0287, -0.0578,  0.0461,\n",
      "          0.0304,  0.0280, -0.0582,  0.0561,  0.0152,  0.0180, -0.0359, -0.1045,\n",
      "          0.0526,  0.0216,  0.0508, -0.0429, -0.0912, -0.0887,  0.0728, -0.0845,\n",
      "         -0.0765,  0.0651,  0.0585,  0.0934,  0.0378, -0.0529, -0.0735,  0.0341]],\n",
      "       requires_grad=True)\n",
      "123 Parameter containing:\n",
      "tensor([-0.0006], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i, param in enumerate(Her.parameters()):\n",
    "    print(i,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c998a3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(Her.state_dict(),'HerGraph1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c82a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpyg",
   "language": "python",
   "name": "newpyg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
